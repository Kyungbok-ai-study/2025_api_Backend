#!/usr/bin/env python3
"""
ì§€ì‹ ì¶”ì  ë° ì¢…í•© AI ë¶„ì„ ì‹œìŠ¤í…œ
DKT + LSTM + DeepSeek í†µí•© ë¶„ì„
"""

import asyncio
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime
import json
import numpy as np

logger = logging.getLogger(__name__)

class KnowledgeTracer:
    """ì§€ì‹ ì¶”ì  ë° ì¢…í•© AI ë¶„ì„ ì‹œìŠ¤í…œ"""
    
    def __init__(self, model_dir: str = "models/"):
        self.model_dir = model_dir
        
        # ë„ë©”ì¸ ë§¤í•‘
        self.domain_mapping = {
            'í•´ë¶€í•™': 'anatomy',
            'ìƒë¦¬í•™': 'physiology', 
            'ìš´ë™í•™': 'kinesiology',
            'ì¹˜ë£Œí•™': 'therapy',
            'í‰ê°€í•™': 'assessment'
        }
        
        # ë‚˜ì¤‘ì— import (ìˆœí™˜ ì°¸ì¡° ë°©ì§€)
        self.dkt_model = None
        self.learning_analyzer = None
        self.deepseek_service = None
        
        self._initialize_models()
    
    def _initialize_models(self):
        """ëª¨ë¸ ì´ˆê¸°í™” (ì§€ì—° ë¡œë”©)"""
        try:
            from .dkt_model import DKTModel, DKTTrainer, DataPreprocessor
            from .learning_analyzer import LearningAnalyzer
            from ..services.deepseek_service import DeepSeekService
            
            self.dkt_model = DKTModel()
            self.dkt_trainer = DKTTrainer(self.dkt_model)
            self.data_preprocessor = DataPreprocessor()
            self.learning_analyzer = LearningAnalyzer(self.model_dir)
            self.deepseek_service = DeepSeekService()
            
            self._load_models()
            logger.info("AI ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.warning(f"AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    async def analyze_student_performance(
        self, 
        user_id: int,
        test_responses: List[Dict],
        test_session: Dict
    ) -> Dict[str, Any]:
        """í•™ìƒ ì„±ê³¼ ì¢…í•© ë¶„ì„"""
        
        logger.info(f"ğŸ§  AI ë¶„ì„ ì‹œì‘: user_id={user_id}, responses={len(test_responses)}")
        
        try:
            # ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš° ëŒ€ì•ˆ ë¶„ì„
            if not self.dkt_model or not self.learning_analyzer:
                logger.warning("AI ëª¨ë¸ ë¯¸ì´ˆê¸°í™”, í†µê³„ì  ë¶„ì„ ì‚¬ìš©")
                return self._get_statistical_analysis(test_responses)
            
            # 1. DKT ë¶„ì„ (ì§€ì‹ ì¶”ì )
            dkt_analysis = await self._perform_dkt_analysis(test_responses)
            
            # 2. LSTM í•™ìŠµ íŒ¨í„´ ë¶„ì„
            pattern_analysis = self.learning_analyzer.analyze_learning_session(test_responses)
            
            # 3. DeepSeek ì¢…í•© ë¶„ì„
            deepseek_analysis = await self._perform_deepseek_analysis(
                test_responses, dkt_analysis, pattern_analysis, test_session
            )
            
            # 4. í†µí•© ë¶„ì„ ê²°ê³¼ ìƒì„±
            integrated_analysis = self._integrate_ai_analyses(
                dkt_analysis, pattern_analysis, deepseek_analysis
            )
            
            logger.info(f"âœ… AI ë¶„ì„ ì™„ë£Œ: user_id={user_id}")
            return integrated_analysis
            
        except Exception as e:
            logger.error(f"âŒ AI ë¶„ì„ ì‹¤íŒ¨: user_id={user_id}, error={str(e)}")
            return self._get_fallback_analysis(test_responses)
    
    async def _perform_dkt_analysis(self, test_responses: List[Dict]) -> Dict[str, Any]:
        """DKT ëª¨ë¸ ë¶„ì„"""
        
        try:
            if len(test_responses) < 2:
                return self._get_default_dkt_analysis()
            
            # ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„
            sequence = self.data_preprocessor.prepare_sequence(test_responses)
            
            # DKT ì˜ˆì¸¡
            predictions = self.dkt_model.predict_next_performance(sequence)
            
            # ê°œë…ë³„ ìˆ™ë ¨ë„ ë¶„ì„
            concept_mastery = predictions['concept_mastery']
            
            # í•™ìŠµ ì§„í–‰ë„ ê³„ì‚°
            learning_progress = self._calculate_learning_progress(test_responses, concept_mastery)
            
            return {
                'concept_mastery': concept_mastery,
                'learning_progress': learning_progress,
                'knowledge_state': {
                    'overall_mastery': float(np.mean(list(concept_mastery.values()))),
                    'confidence_score': predictions['confidence_score'],
                    'difficulty_prediction': predictions['overall_difficulty'],
                    'time_estimation': predictions['estimated_time']
                },
                'domain_predictions': self._generate_domain_predictions(concept_mastery),
                'learning_trajectory': self._analyze_learning_trajectory(test_responses)
            }
            
        except Exception as e:
            logger.error(f"DKT ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return self._get_default_dkt_analysis()
    
    def _calculate_learning_progress(
        self, 
        responses: List[Dict], 
        concept_mastery: Dict[str, float]
    ) -> Dict[str, Any]:
        """í•™ìŠµ ì§„í–‰ë„ ê³„ì‚°"""
        
        # ì‹œê°„ë³„ ì •ë‹µë¥  ë³€í™”
        time_intervals = max(1, len(responses) // 3)
            
        accuracy_over_time = []
        for i in range(0, len(responses), time_intervals):
            interval_responses = responses[i:i+time_intervals]
            if interval_responses:
                accuracy = sum(r.get('is_correct', False) for r in interval_responses) / len(interval_responses)
                accuracy_over_time.append(accuracy)
        
        # í•™ìŠµ ê³¡ì„  ê¸°ìš¸ê¸°
        if len(accuracy_over_time) > 1:
            learning_slope = (accuracy_over_time[-1] - accuracy_over_time[0]) / (len(accuracy_over_time) - 1)
        else:
            learning_slope = 0.0
        
        # ê°œë…ë³„ ì§„í–‰ë„
        domain_progress = {}
        for domain_kr, domain_en in self.domain_mapping.items():
            domain_responses = [r for r in responses if r.get('domain') == domain_kr]
            if domain_responses:
                domain_accuracy = sum(r.get('is_correct', False) for r in domain_responses) / len(domain_responses)
                mastery_score = concept_mastery.get(domain_en, 0.5)
                
                # ì§„í–‰ë„ = (í˜„ì¬ ì •í™•ë„ + ì˜ˆì¸¡ ìˆ™ë ¨ë„) / 2
                progress = (domain_accuracy + mastery_score) / 2
                domain_progress[domain_kr] = {
                    'current_accuracy': domain_accuracy,
                    'predicted_mastery': mastery_score,
                    'progress_score': progress,
                    'question_count': len(domain_responses)
                }
        
        overall_progress = float(np.mean([dp['progress_score'] for dp in domain_progress.values()])) if domain_progress else 0.5
        
        return {
            'accuracy_trend': accuracy_over_time,
            'learning_slope': learning_slope,
            'improvement_rate': max(0, learning_slope),
            'domain_progress': domain_progress,
            'overall_progress': overall_progress
        }
    
    def _generate_domain_predictions(self, concept_mastery: Dict[str, float]) -> Dict[str, Any]:
        """ë„ë©”ì¸ë³„ ì˜ˆì¸¡ ìƒì„±"""
        
        predictions = {}
        
        for domain_kr, domain_en in self.domain_mapping.items():
            mastery = concept_mastery.get(domain_en, 0.5)
            
            # ìˆ™ë ¨ë„ ë ˆë²¨ ê²°ì •
            if mastery >= 0.8:
                level = "ìš°ìˆ˜"
                next_action = "ì‹¬í™” ë¬¸ì œ ë„ì „"
            elif mastery >= 0.6:
                level = "ì–‘í˜¸"
                next_action = "ì—°ìŠµ ë¬¸ì œ í’€ì´"
            elif mastery >= 0.4:
                level = "ë³´í†µ"
                next_action = "ê¸°ì´ˆ ê°œë… ë³µìŠµ"
            else:
                level = "ë¶€ì¡±"
                next_action = "ê¸°ë³¸ ì´ë¡  í•™ìŠµ"
            
            predictions[domain_kr] = {
                'mastery_score': mastery,
                'level': level,
                'next_action': next_action,
                'confidence': min(mastery * 1.2, 1.0)  # ì‹ ë¢°ë„
            }
        
        return predictions
    
    def _analyze_learning_trajectory(self, responses: List[Dict]) -> Dict[str, Any]:
        """í•™ìŠµ ê¶¤ì  ë¶„ì„"""
        
        if len(responses) < 5:
            return {'status': 'insufficient_data'}
        
        # ì •ë‹µë¥  ë³€í™” íŒ¨í„´
        accuracy_sequence = [float(r.get('is_correct', False)) for r in responses]
        
        # ì´ë™ í‰ê·  ê³„ì‚° (window=5)
        window_size = min(5, len(accuracy_sequence))
        moving_avg = []
        for i in range(len(accuracy_sequence) - window_size + 1):
            avg = np.mean(accuracy_sequence[i:i+window_size])
            moving_avg.append(avg)
        
        # í•™ìŠµ ë‹¨ê³„ ë¶„ë¥˜
        if len(moving_avg) > 2:
            initial_phase = np.mean(moving_avg[:max(1, len(moving_avg)//3)])
            final_phase = np.mean(moving_avg[-max(1, len(moving_avg)//3):])
            
            if final_phase > initial_phase + 0.2:
                trajectory_type = "ìƒìŠ¹í˜•"
                trajectory_desc = "í•™ìŠµì´ ì§€ì†ì ìœ¼ë¡œ í–¥ìƒë˜ê³  ìˆìŠµë‹ˆë‹¤"
            elif initial_phase > final_phase + 0.2:
                trajectory_type = "í•˜ë½í˜•"
                trajectory_desc = "ì§‘ì¤‘ë ¥ ì €í•˜ë‚˜ í”¼ë¡œê°€ ì˜ì‹¬ë©ë‹ˆë‹¤"
            else:
                trajectory_type = "ì•ˆì •í˜•"
                trajectory_desc = "ì¼ì •í•œ ìˆ˜ì¤€ì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤"
        else:
            trajectory_type = "íŒë‹¨ë¶ˆê°€"
            trajectory_desc = "ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"
        
        return {
            'trajectory_type': trajectory_type,
            'description': trajectory_desc,
            'accuracy_sequence': accuracy_sequence,
            'moving_average': moving_avg,
            'initial_performance': float(np.mean(accuracy_sequence[:3])),
            'final_performance': float(np.mean(accuracy_sequence[-3:])),
            'volatility': float(np.std(accuracy_sequence))
        }
    
    async def _perform_deepseek_analysis(
        self,
        test_responses: List[Dict],
        dkt_analysis: Dict[str, Any],
        pattern_analysis: Dict[str, Any],
        test_session: Dict
    ) -> Dict[str, Any]:
        """DeepSeek AI ì¢…í•© ë¶„ì„"""
        
        try:
            # DeepSeek ì„œë¹„ìŠ¤ê°€ ì—†ìœ¼ë©´ ë¡œì»¬ ë¶„ì„
            if not self.deepseek_service:
                return self._generate_local_analysis(dkt_analysis, pattern_analysis)
            
            # ë¶„ì„ ë°ì´í„° ì¤€ë¹„
            analysis_data = self._prepare_comprehensive_data(
                test_responses, dkt_analysis, pattern_analysis, test_session
            )
            
            # DeepSeek ë¶„ì„ ìš”ì²­
            deepseek_result = await self.deepseek_service.chat_completion(
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼ ì „ë¬¸ êµìœ¡ ë¶„ì„ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": analysis_data}
                ],
                temperature=0.3
            )
            
            if deepseek_result.get("success"):
                content = deepseek_result.get('content', '')
                
                return {
                    'status': 'success',
                    'analysis_summary': content,
                    'insights': self._extract_insights_from_deepseek(content),
                    'recommendations': self._extract_recommendations_from_deepseek(content),
                    'generated_at': datetime.now().isoformat()
                }
            else:
                logger.warning("DeepSeek ë¶„ì„ ì‹¤íŒ¨, ë¡œì»¬ ë¶„ì„ ì‚¬ìš©")
                return self._generate_local_analysis(dkt_analysis, pattern_analysis)
                
        except Exception as e:
            logger.error(f"DeepSeek ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return self._generate_local_analysis(dkt_analysis, pattern_analysis)
    
    def _prepare_comprehensive_data(
        self,
        responses: List[Dict],
        dkt_analysis: Dict[str, Any],
        pattern_analysis: Dict[str, Any],
        test_session: Dict
    ) -> str:
        """ì¢…í•© ë¶„ì„ìš© ë°ì´í„° ì¤€ë¹„ (ì‹¤ì œ ì§„ë‹¨ í…ŒìŠ¤íŠ¸ ê¸°ë°˜)"""
        
        # ê¸°ë³¸ í†µê³„
        total_questions = len(responses)
        correct_answers = sum(r.get('is_correct', False) for r in responses)
        accuracy_rate = correct_answers / total_questions if total_questions > 0 else 0
        
        # í‰ê·  ì‘ë‹µ ì‹œê°„ (ë§¤ìš° ì¤‘ìš”!)
        avg_response_time = np.mean([r.get('time_spent', 2) for r in responses]) if responses else 2.0
        total_time = sum([r.get('time_spent', 2) for r in responses]) if responses else 60
        
        # ì§„ë‹¨ í…ŒìŠ¤íŠ¸ ë„ë©”ì¸ë³„ ì„±ê³¼ (ì‹¤ì œ êµ¬ì„± ë°˜ì˜)
        domain_stats = {}
        domain_mapping = {
            'ê·¼ê³¨ê²©ê³„': ['ê·¼ê³¨ê²©ê³„', 'ê·¼ê³¨ê²©ê³„/ì†Œì•„/ë…¸ì¸'],
            'ì‹ ê²½ê³„': ['ì‹ ê²½ê³„', 'ì‹ ê²½ê³„/ë‡Œì‹ ê²½', 'ì‹ ê²½ê³„/ì‹ ê²½ê³¼í•™ ê¸°ë³¸', 'ì‹ ê²½ê³„/ê·¼ê³¨ê²©ê³„'],
            'ì‹¬íê³„': ['ì‹¬í'],
            'ê¸°íƒ€/ê¸°ì´ˆì˜í•™': ['ê¸°íƒ€', 'ê¸°íƒ€ (ìƒë¬¼í•™ì  ê¸°ë³¸ ê°œë…)', 'ê¸°íƒ€(ëˆˆì˜ êµ¬ì¡°ì™€ ê¸°ëŠ¥)', 'ê¸°íƒ€ (ìƒë¦¬í•™/ì˜í•™êµìœ¡)']
        }
        
        for main_domain, sub_domains in domain_mapping.items():
            domain_responses = [r for r in responses if any(sub in r.get('domain', '') for sub in sub_domains)]
            if domain_responses:
                domain_accuracy = sum(r.get('is_correct', False) for r in domain_responses) / len(domain_responses)
                domain_time = np.mean([r.get('time_spent', 2) for r in domain_responses])
                domain_stats[main_domain] = {
                    'accuracy': domain_accuracy,
                    'avg_time': domain_time,
                    'question_count': len(domain_responses)
                }
        
        # 1ë¶„ ë¯¸ë§Œ í’€ì´ íŒ¨í„´ ë¶„ì„
        time_analysis_str = ""
        if total_time < 60:
            time_analysis_str = f"""
âš ï¸  **ë§¤ìš° ë¹ ë¥¸ ì‘ë‹µ íŒ¨í„´ ê°ì§€** âš ï¸
- ì´ ì†Œìš”ì‹œê°„: {total_time:.0f}ì´ˆ (1ë¶„ ë¯¸ë§Œ)
- ë¬¸í•­ë‹¹ í‰ê· : {avg_response_time:.1f}ì´ˆ
- ì •ìƒ í’€ì´ì‹œê°„: ë¬¸í•­ë‹¹ 60-120ì´ˆ

ì´ëŠ” ë‹¤ìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤:
1. ë¬¸ì œë¥¼ ì¶©ë¶„íˆ ì½ì§€ ì•Šê³  ì¶”ì¸¡ìœ¼ë¡œ ë‹µí•¨
2. ë¬¼ë¦¬ì¹˜ë£Œí•™ ê¸°ì´ˆ ì§€ì‹ì´ ë§¤ìš° ë¶€ì¡±í•¨  
3. í•™ìŠµì— ëŒ€í•œ ì§„ì§€í•œ ì ‘ê·¼ì´ ë¶€ì¡±í•¨
4. ì²´ê³„ì  í•™ìŠµì´ ì‹œê¸‰íˆ í•„ìš”í•¨
"""
        elif avg_response_time < 30:
            time_analysis_str = f"""
âš ï¸ **ì„±ê¸‰í•œ ì‘ë‹µ íŒ¨í„´**
- ë¬¸í•­ë‹¹ í‰ê· : {avg_response_time:.1f}ì´ˆ
- ê¶Œì¥ ì‹œê°„: 60-120ì´ˆ/ë¬¸í•­

ë¹ ë¥¸ ì¶”ì¸¡ë³´ë‹¤ëŠ” ì‹ ì¤‘í•œ ì‚¬ê³ ê°€ í•„ìš”í•©ë‹ˆë‹¤.
"""
        
        # í•™ìŠµ íŒ¨í„´ ì •ë³´
        learning_style = pattern_analysis.get('learning_style', {})
        cognitive_metrics = pattern_analysis.get('cognitive_metrics', {})
        time_analysis = pattern_analysis.get('time_analysis', {})
        
        # ë¶„ì„ ìš”ì²­ ì‘ì„±
        analysis_request = f"""
ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼ ì§„ë‹¨í…ŒìŠ¤íŠ¸ ì‹¬ì¸µ ë¶„ì„ ìš”ì²­

## ğŸ“Š ê¸°ë³¸ ì„±ê³¼ ì •ë³´
- ì´ ë¬¸í•­: {total_questions}ê°œ (ê·¼ê³¨ê²©ê³„ 11ë¬¸í•­, ì‹ ê²½ê³„ 8ë¬¸í•­, ì‹¬í 2ë¬¸í•­, ê¸°íƒ€ 9ë¬¸í•­)
- ì •ë‹µ: {correct_answers}ê°œ 
- ì •ë‹µë¥ : {accuracy_rate:.1%}
- ì´ ì†Œìš”ì‹œê°„: {total_time:.0f}ì´ˆ

{time_analysis_str}

## ğŸ¯ ë„ë©”ì¸ë³„ ì„±ê³¼ ë¶„ì„ (ì§„ë‹¨í…ŒìŠ¤íŠ¸ ì‹¤ì œ êµ¬ì„±)
"""
        
        for domain, stats in domain_stats.items():
            expected_questions = {'ê·¼ê³¨ê²©ê³„': 11, 'ì‹ ê²½ê³„': 8, 'ì‹¬íê³„': 2, 'ê¸°íƒ€/ê¸°ì´ˆì˜í•™': 9}.get(domain, 0)
            analysis_request += f"""
### {domain} ì˜ì—­ (ì „ì²´ {expected_questions}ë¬¸í•­ ì¤‘ {stats['question_count']}ë¬¸í•­ ì‘ë‹µ)
- ì •ë‹µë¥ : {stats['accuracy']:.1%}
- í‰ê·  ì†Œìš”ì‹œê°„: {stats['avg_time']:.0f}ì´ˆ
- ì˜ˆìƒ ìˆ˜ì¤€: {'ê¸°ì´ˆ ë¶€ì¡±' if stats['accuracy'] < 0.6 else 'ë³´í†µ' if stats['accuracy'] < 0.8 else 'ì–‘í˜¸'}
"""
        
        analysis_request += f"""
## ğŸ§  AI í•™ìŠµ íŒ¨í„´ ë¶„ì„
- ì‘ë‹µ ìŠ¤íƒ€ì¼: {learning_style.get('response_style', 'ì•Œ ìˆ˜ ì—†ìŒ')}
- ì¸ì§€ ë¶€í•˜: {cognitive_metrics.get('cognitive_load', 0):.1%}
- ì£¼ì˜ë ¥ ìˆ˜ì¤€: {cognitive_metrics.get('attention_level', 0):.1%}
- ì‹œê°„ ì¼ê´€ì„±: {time_analysis.get('time_consistency', 0):.1%}
- ì‹œê°„ íŠ¸ë Œë“œ: {time_analysis.get('time_trend', 'ì•Œ ìˆ˜ ì—†ìŒ')}
- í”¼ë¡œë„ ê°ì§€: {'ì˜ˆ' if time_analysis.get('fatigue_detected', False) else 'ì•„ë‹ˆì˜¤'}

## ğŸ” DKT ëª¨ë¸ ì˜ˆì¸¡ (Deep Knowledge Tracing)
ì „ì²´ í•™ìŠµ ìƒíƒœ: {dkt_analysis.get('knowledge_state', {}).get('overall_mastery', 0):.1%}
ê°œë…ë³„ ìˆ™ë ¨ë„:
"""
        
        concept_mastery = dkt_analysis.get('concept_mastery', {})
        domain_name_mapping = {
            'anatomy': 'í•´ë¶€í•™ (ê·¼ê³¨ê²©ê³„)',
            'physiology': 'ìƒë¦¬í•™ (ê¸°ì´ˆì˜í•™)', 
            'kinesiology': 'ìš´ë™í•™ (ê·¼ê³¨ê²©ê³„)',
            'therapy': 'ì¹˜ë£Œí•™ (ì„ìƒ)',
            'assessment': 'í‰ê°€í•™ (ì„ìƒ)'
        }
        
        for domain_en, score in concept_mastery.items():
            domain_display = domain_name_mapping.get(domain_en, domain_en)
            analysis_request += f"- {domain_display}: {score:.1%}\n"
        
        analysis_request += f"""
## ğŸš¨ ì£¼ìš” ìš°ë ¤ì‚¬í•­
{"- **ê·¹ë„ë¡œ ë¹ ë¥¸ í’€ì´**: 1ë¶„ ë¯¸ë§Œì€ ì¶”ì¸¡/ì°ê¸°ë¥¼ ì˜ë¯¸í•˜ë©° ì •í™•í•œ ì‹¤ë ¥ ì§„ë‹¨ì´ ì–´ë ¤ì›€" if total_time < 60 else ""}
{"- **ê¸°ì´ˆ ì˜í•™ ì§€ì‹ ë¶€ì¡±**: ë¬¼ë¦¬ì¹˜ë£Œì‚¬ êµ­ê°€ê³ ì‹œ ìˆ˜ì¤€ì˜ ê¸°ë³¸ê¸°ê°€ ë¶€ì¡±í•¨" if accuracy_rate < 0.6 else ""}
- **ì²´ê³„ì  í•™ìŠµ í•„ìš”**: ë¬´ì‘ì • ë¬¸ì œ í’€ì´ë³´ë‹¤ëŠ” ê°œë… ì •ë¦¬ê°€ ìš°ì„ 

## ğŸ“‹ ë¶„ì„ ìš”ì²­ì‚¬í•­ (ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼ ì „ë¬¸ê°€ ê´€ì )
1. **ì •í™•í•œ ì‹¤ë ¥ ì§„ë‹¨**: ë¹ ë¥¸ í’€ì´ë¡œ ì¸í•œ ì‹ ë¢°ë„ ë¬¸ì œ ì§€ì 
2. **ë„ë©”ì¸ë³„ ì•½ì  ë¶„ì„**: ê·¼ê³¨ê²©ê³„, ì‹ ê²½ê³„, ê¸°ì´ˆì˜í•™ ê° ì˜ì—­ì˜ êµ¬ì²´ì  ë¬¸ì œì 
3. **í•™ìŠµ ë°©í–¥ì„± ì œì‹œ**: ë¬¼ë¦¬ì¹˜ë£Œì‚¬ êµ­ê°€ê³ ì‹œ ì¤€ë¹„ë¥¼ ìœ„í•œ ë‹¨ê³„ë³„ í•™ìŠµ ê³„íš
4. **ê¸°ì´ˆ ì§€ì‹ ë³´ê°• ë°©ì•ˆ**: í•´ë¶€í•™, ìƒë¦¬í•™, ë³‘ë¦¬í•™ ë“± ê¸°ì´ˆ ì˜í•™ í•™ìŠµë²•
5. **ë¬¸ì œ í’€ì´ íƒœë„ ê°œì„ **: ì‹ ì¤‘í•˜ê³  ì²´ê³„ì ì¸ ì ‘ê·¼ë²• ì œì•ˆ
6. **ë™ê¸°ë¶€ì—¬ ë°©ì•ˆ**: ë¬¼ë¦¬ì¹˜ë£Œì‚¬ë¼ëŠ” ëª©í‘œë¥¼ ìœ„í•œ í•™ìŠµ ë™ê¸° ê°•í™” ë°©ë²•

ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼ í•™ìƒì˜ ê´€ì ì—ì„œ **ì‹¤ë¬´ì— í•„ìš”í•œ í•µì‹¬ ì—­ëŸ‰**ê³¼ **êµ­ê°€ê³ ì‹œ í•©ê²©**ì„ ëª©í‘œë¡œ í•œ 
êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë¶„ì„ê³¼ ì¡°ì–¸ì„ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
"""
        
        return analysis_request
    
    def _extract_insights_from_deepseek(self, content: str) -> Dict[str, Any]:
        """DeepSeek ì‘ë‹µì—ì„œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        
        insights = {
            'key_findings': [],
            'strength_areas': [],
            'improvement_areas': [],
            'learning_characteristics': []
        }
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP í•„ìš”)
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            if 'ê°•ì ' in line or 'ìš°ìˆ˜' in line:
                insights['strength_areas'].append(line)
            elif 'ì•½ì ' in line or 'ë³´ì™„' in line or 'ê°œì„ ' in line:
                insights['improvement_areas'].append(line)
            elif 'íŠ¹ì„±' in line or 'ì„±í–¥' in line:
                insights['learning_characteristics'].append(line)
            elif line and len(line) > 10:
                insights['key_findings'].append(line)
        
        return insights
    
    def _extract_recommendations_from_deepseek(self, content: str) -> List[str]:
        """DeepSeek ì‘ë‹µì—ì„œ ì¶”ì²œì‚¬í•­ ì¶”ì¶œ"""
        
        recommendations = []
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            if any(keyword in line for keyword in ['ì¶”ì²œ', 'ì œì•ˆ', 'ê¶Œì¥', 'ë°©ë²•', 'ì „ëµ']):
                if len(line) > 5:
                    recommendations.append(line)
        
        # ê¸°ë³¸ ì¶”ì²œì‚¬í•­ì´ ì—†ìœ¼ë©´ ì¼ë°˜ì ì¸ ê²ƒ ì¶”ê°€
        if not recommendations:
            recommendations = [
                "ì§€ì†ì ì¸ í•™ìŠµì„ í†µí•´ ì•½ì  ì˜ì—­ì„ ë³´ê°•í•˜ì„¸ìš”",
                "ê°•ì  ì˜ì—­ì„ í™œìš©í•˜ì—¬ ìì‹ ê°ì„ ê¸°ë¥´ì„¸ìš”",
                "ê·œì¹™ì ì¸ ë³µìŠµ ìŠ¤ì¼€ì¤„ì„ ë§Œë“¤ì–´ ì‹¤ì²œí•˜ì„¸ìš”"
            ]
        
        return recommendations[:5]  # ìµœëŒ€ 5ê°œ
    
    def _generate_local_analysis(
        self, 
        dkt_analysis: Dict[str, Any], 
        pattern_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ë¡œì»¬ ë¶„ì„ ê²°ê³¼ ìƒì„± (DeepSeek ì‹¤íŒ¨ì‹œ ëŒ€ì•ˆ)"""
        
        # DKT ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
        concept_mastery = dkt_analysis.get('concept_mastery', {})
        if concept_mastery:
            strongest_domain = max(concept_mastery.items(), key=lambda x: x[1])[0]
            weakest_domain = min(concept_mastery.items(), key=lambda x: x[1])[0]
        else:
            strongest_domain, weakest_domain = 'anatomy', 'physiology'
        
        # ë„ë©”ì¸ ì´ë¦„ ë³€í™˜
        domain_names = {v: k for k, v in self.domain_mapping.items()}
        strongest_kr = domain_names.get(strongest_domain, 'í•´ë¶€í•™')
        weakest_kr = domain_names.get(weakest_domain, 'ìƒë¦¬í•™')
        
        # í•™ìŠµ íŒ¨í„´ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
        learning_style = pattern_analysis.get('learning_style', {}).get('response_style', 'ê· í˜•í˜•')
        cognitive_load = pattern_analysis.get('cognitive_metrics', {}).get('cognitive_load', 0.5)
        
        # ë¶„ì„ ìš”ì•½ ìƒì„±
        analysis_summary = f"""
## AI ëª¨ë¸ ê¸°ë°˜ í•™ìŠµ ë¶„ì„ ê²°ê³¼

**ê°•ì  ì˜ì—­**: {strongest_kr} 
- ì´ ì˜ì—­ì—ì„œ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.

**ê°œì„  ì˜ì—­**: {weakest_kr}
- ì¶”ê°€ì ì¸ í•™ìŠµê³¼ ë³µìŠµì´ í•„ìš”í•œ ì˜ì—­ì…ë‹ˆë‹¤.

**í•™ìŠµ íŠ¹ì„±**:
- ì‘ë‹µ ìŠ¤íƒ€ì¼: {learning_style}
- ì¸ì§€ ë¶€í•˜ ìˆ˜ì¤€: {'ë†’ìŒ' if cognitive_load > 0.7 else 'ì ì ˆí•¨'}

**ì¢…í•© í‰ê°€**:
ì „ë°˜ì ìœ¼ë¡œ ë¬¼ë¦¬ì¹˜ë£Œí•™ ê¸°ì´ˆ ì§€ì‹ì„ ê°–ì¶”ê³  ìˆìœ¼ë‚˜, 
ê· í˜•ì¡íŒ ë°œì „ì„ ìœ„í•´ ì•½ì  ì˜ì—­ì˜ ë³´ê°•ì´ í•„ìš”í•©ë‹ˆë‹¤.
"""
        
        # ì¶”ì²œì‚¬í•­ ìƒì„±
        recommendations = [
            f"{strongest_kr} ì˜ì—­ì˜ ê°•ì ì„ í™œìš©í•˜ì—¬ ë‹¤ë¥¸ ì˜ì—­ í•™ìŠµì— ì—°ê³„í•˜ì„¸ìš”",
            f"{weakest_kr} ì˜ì—­ì˜ ê¸°ì´ˆ ê°œë…ë¶€í„° ì°¨ê·¼ì°¨ê·¼ ë³µìŠµí•˜ì„¸ìš”",
            f"{learning_style} íŠ¹ì„±ì— ë§ëŠ” í•™ìŠµ ë°©ë²•ì„ ì§€ì†ì ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”"
        ]
        
        if cognitive_load > 0.7:
            recommendations.append("í˜„ì¬ ì¸ì§€ ë¶€í•˜ê°€ ë†’ìœ¼ë¯€ë¡œ ì ì ˆí•œ íœ´ì‹ì„ ì·¨í•˜ì„¸ìš”")
        else:
            recommendations.append("í˜„ì¬ ì»¨ë””ì…˜ì´ ì¢‹ìœ¼ë‹ˆ ì§‘ì¤‘ì ì¸ í•™ìŠµì„ ì§„í–‰í•˜ì„¸ìš”")
        
        return {
            'status': 'local_analysis',
            'analysis_summary': analysis_summary.strip(),
            'insights': {
                'strongest_domain': strongest_kr,
                'weakest_domain': weakest_kr,
                'learning_style': learning_style,
                'cognitive_status': 'ë†’ì€ ë¶€í•˜' if cognitive_load > 0.7 else 'ì ì ˆí•œ ìƒíƒœ'
            },
            'recommendations': recommendations,
            'generated_at': datetime.now().isoformat(),
            'source': 'local_ai_models'
        }
    
    def _integrate_ai_analyses(
        self,
        dkt_analysis: Dict[str, Any],
        pattern_analysis: Dict[str, Any],
        deepseek_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """AI ë¶„ì„ ê²°ê³¼ í†µí•©"""
        
        return {
            'dkt_insights': dkt_analysis,
            'learning_patterns': pattern_analysis,
            'deepseek_analysis': deepseek_analysis,
            'integration_metadata': {
                'analysis_timestamp': datetime.now().isoformat(),
                'models_used': ['DKT', 'LSTM', 'RNN', 'DeepSeek'],
                'confidence_score': self._calculate_integration_confidence(
                    dkt_analysis, pattern_analysis, deepseek_analysis
                )
            }
        }
    
    def _calculate_integration_confidence(
        self,
        dkt_analysis: Dict[str, Any],
        pattern_analysis: Dict[str, Any],
        deepseek_analysis: Dict[str, Any]
    ) -> float:
        """í†µí•© ë¶„ì„ ì‹ ë¢°ë„ ê³„ì‚°"""
        
        confidence_factors = []
        
        # DKT ì‹ ë¢°ë„
        dkt_confidence = dkt_analysis.get('knowledge_state', {}).get('confidence_score')
        if dkt_confidence:
            confidence_factors.append(dkt_confidence)
        
        # íŒ¨í„´ ë¶„ì„ ì‹ ë¢°ë„
        pattern_confidence = pattern_analysis.get('learning_style', {}).get('style_confidence')
        if pattern_confidence:
            confidence_factors.append(pattern_confidence)
        
        # DeepSeek ë¶„ì„ ì„±ê³µ ì—¬ë¶€
        if deepseek_analysis.get('status') == 'success':
            confidence_factors.append(0.9)
        else:
            confidence_factors.append(0.6)
        
        return float(np.mean(confidence_factors)) if confidence_factors else 0.7
    
    def _get_default_dkt_analysis(self) -> Dict[str, Any]:
        """ê¸°ë³¸ DKT ë¶„ì„ (ë°ì´í„° ë¶€ì¡±ì‹œ)"""
        
        return {
            'concept_mastery': {
                'anatomy': 0.7,
                'physiology': 0.6,
                'kinesiology': 0.75,
                'therapy': 0.65,
                'assessment': 0.7
            },
            'learning_progress': {
                'overall_progress': 0.65,
                'improvement_rate': 0.1,
                'domain_progress': {}
            },
            'knowledge_state': {
                'overall_mastery': 0.68,
                'confidence_score': 0.6,
                'difficulty_prediction': 0.4,
                'time_estimation': 55.0
            }
        }
    
    def _get_statistical_analysis(self, responses: List[Dict]) -> Dict[str, Any]:
        """í†µê³„ì  ë¶„ì„ (AI ëª¨ë¸ ì—†ì´)"""
        
        if not responses:
            return self._get_fallback_analysis([])
        
        # ê¸°ë³¸ í†µê³„
        total = len(responses)
        correct = sum(r.get('is_correct', False) for r in responses)
        accuracy = correct / total
        avg_time = np.mean([r.get('time_spent', 60) for r in responses])
        
        # ë„ë©”ì¸ë³„ ë¶„ì„
        domain_stats = {}
        for domain_kr in self.domain_mapping.keys():
            domain_responses = [r for r in responses if r.get('domain') == domain_kr]
            if domain_responses:
                domain_accuracy = sum(r.get('is_correct', False) for r in domain_responses) / len(domain_responses)
                domain_time = np.mean([r.get('time_spent', 60) for r in domain_responses])
                domain_stats[domain_kr] = {
                    'accuracy': domain_accuracy,
                    'avg_time': domain_time,
                    'question_count': len(domain_responses)
                }
        
        # ìµœê³ /ìµœì € ë„ë©”ì¸
        if domain_stats:
            best_domain = max(domain_stats.items(), key=lambda x: x[1]['accuracy'])[0]
            worst_domain = min(domain_stats.items(), key=lambda x: x[1]['accuracy'])[0]
        else:
            best_domain, worst_domain = 'í•´ë¶€í•™', 'ìƒë¦¬í•™'
        
        return {
            'dkt_insights': {
                'concept_mastery': {self.domain_mapping.get(k, k): v['accuracy'] for k, v in domain_stats.items()},
                'knowledge_state': {
                    'overall_mastery': accuracy,
                    'confidence_score': 0.7
                }
            },
            'learning_patterns': {
                'learning_style': {'response_style': 'ê· í˜•í˜•'},
                'time_analysis': {
                    'average_response_time': avg_time,
                    'time_consistency': 0.7,
                    'time_trend': 'ì¼ê´€ë¨',
                    'fatigue_detected': False
                }
            },
            'deepseek_analysis': {
                'status': 'statistical',
                'analysis_summary': f"""
## í†µê³„ì  ë¶„ì„ ê²°ê³¼

**ì „ì²´ ì„±ê³¼**: ì´ {total}ë¬¸í•­ ì¤‘ {correct}ë¬¸í•­ ì •ë‹µ (ì •ë‹µë¥  {accuracy:.1%})
**í‰ê·  ì†Œìš”ì‹œê°„**: {avg_time:.0f}ì´ˆ

**ë„ë©”ì¸ë³„ ì„±ê³¼**:
- ìµœê³  ì„±ê³¼: {best_domain} ({domain_stats.get(best_domain, {}).get('accuracy', 0):.1%})
- ê°œì„  í•„ìš”: {worst_domain} ({domain_stats.get(worst_domain, {}).get('accuracy', 0):.1%})

**í•™ìŠµ ë¶„ì„**: AI ëª¨ë¸ì„ í™œìš©í•œ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
""",
                'recommendations': [
                    f"{best_domain} ì˜ì—­ì˜ ê°•ì ì„ ìœ ì§€í•˜ì„¸ìš”",
                    f"{worst_domain} ì˜ì—­ì˜ ì¶”ê°€ í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤",
                    "ì •ê¸°ì ì¸ ë³µìŠµì„ í†µí•´ ì „ì²´ì ì¸ ê· í˜•ì„ ë§ì¶”ì„¸ìš”"
                ]
            },
            'integration_metadata': {
                'analysis_timestamp': datetime.now().isoformat(),
                'models_used': ['statistical'],
                'confidence_score': 0.5
            }
        }
    
    def _get_fallback_analysis(self, responses: List[Dict]) -> Dict[str, Any]:
        """ëŒ€ì•ˆ ë¶„ì„ (ëª¨ë“  ê²ƒì´ ì‹¤íŒ¨í–ˆì„ ë•Œ)"""
        
        total = len(responses) if responses else 0
        correct = sum(r.get('is_correct', False) for r in responses) if responses else 0
        accuracy = correct / total if total > 0 else 0.5
        
        return {
            'dkt_insights': self._get_default_dkt_analysis(),
            'learning_patterns': {
                'learning_style': {'response_style': 'ê· í˜•í˜•'},
                'time_analysis': {
                    'average_response_time': 56.0,
                    'time_consistency': 0.7,
                    'time_trend': 'ì¼ê´€ë¨',
                    'fatigue_detected': False
                }
            },
            'deepseek_analysis': {
                'status': 'fallback',
                'analysis_summary': f"ê¸°ë³¸ ë¶„ì„: ì´ {total}ë¬¸í•­ ì¤‘ {correct}ë¬¸í•­ ì •ë‹µ (ì •ë‹µë¥  {accuracy:.1%})",
                'recommendations': [
                    "ë” ë§ì€ ë¬¸ì œë¥¼ í’€ì–´ ì •í™•í•œ ë¶„ì„ì„ ë°›ì•„ë³´ì„¸ìš”",
                    "ì§€ì†ì ì¸ í•™ìŠµì„ í†µí•´ ì‹¤ë ¥ì„ í–¥ìƒì‹œí‚¤ì„¸ìš”"
                ]
            },
            'integration_metadata': {
                'analysis_timestamp': datetime.now().isoformat(),
                'models_used': ['fallback'],
                'confidence_score': 0.3
            }
        }
    
    def _load_models(self):
        """AI ëª¨ë¸ë“¤ ë¡œë“œ"""
        try:
            if self.dkt_trainer:
                self.dkt_trainer.load_model(f"{self.model_dir}/dkt_model.pth")
                logger.info("DKT ëª¨ë¸ ë¡œë“œ ì‹œë„ ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
knowledge_tracer = KnowledgeTracer() 