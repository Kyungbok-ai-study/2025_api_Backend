"""
Gemini API ì„œë¹„ìŠ¤
PDF ë¬¸ì„œ íŒŒì‹± ë° ì»¨í…ì¸  ë¶„ì„ì„ ìœ„í•œ Gemini API í†µí•©
"""
import os
import logging
import json
from typing import Dict, Any, Optional, List
from datetime import datetime
from pathlib import Path
import base64
import asyncio
from dotenv import load_dotenv

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    genai = None

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

logger = logging.getLogger(__name__)

class GeminiService:
    """Google Gemini API ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
        self.model_name = os.getenv("GEMINI_MODEL_NAME", "gemini-1.5-flash")
        
        if GEMINI_AVAILABLE and self.api_key:
            try:
                genai.configure(api_key=self.api_key)
                self.model = genai.GenerativeModel(self.model_name)
                logger.info(f"âœ… Gemini API ì´ˆê¸°í™” ì™„ë£Œ: {self.model_name}")
            except Exception as e:
                logger.error(f"âŒ Gemini API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.model = None
        else:
            self.model = None
            if not GEMINI_AVAILABLE:
                logger.warning("âŒ Gemini API ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install google-generativeai' ì‹¤í–‰í•˜ì„¸ìš”.")
            elif not self.api_key:
                logger.warning("âŒ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    async def parse_pdf_document(
        self,
        file_path: str,
        department: str = "ì¼ë°˜í•™ê³¼",
        extraction_type: str = "comprehensive"
    ) -> Dict[str, Any]:
        """
        Gemini APIë¥¼ ì´ìš©í•œ PDF ë¬¸ì„œ íŒŒì‹±
        
        Args:
            file_path: PDF íŒŒì¼ ê²½ë¡œ
            department: í•™ê³¼ ì •ë³´
            extraction_type: ì¶”ì¶œ ìœ í˜• (comprehensive, summary, questions)
        """
        try:
            if not self.model:
                # Gemini ì‚¬ìš© ë¶ˆê°€ì‹œ ëŒ€ì²´ íŒŒì‹± ë°©ë²• ì‚¬ìš©
                return await self._fallback_pdf_parsing(file_path, department)
            
            logger.info(f"ğŸ” Gemini PDF íŒŒì‹± ì‹œì‘: {file_path}")
            
            # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì—¬ Geminiì— ì „ì†¡
            pdf_images = await self._convert_pdf_to_images(file_path)
            
            if not pdf_images:
                raise Exception("PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # í•™ê³¼ë³„ íŒŒì‹± í”„ë¡¬í”„íŠ¸ ìƒì„±
            parsing_prompt = self._build_parsing_prompt(department, extraction_type)
            
            # Gemini API í˜¸ì¶œ
            content_parts = [parsing_prompt]
            
            # ì´ë¯¸ì§€ë“¤ ì¶”ê°€ (ìµœëŒ€ 10í˜ì´ì§€)
            for i, image_data in enumerate(pdf_images[:10]):
                content_parts.append({
                    "mime_type": "image/png",
                    "data": image_data
                })
            
            response = await asyncio.to_thread(
                self.model.generate_content,
                content_parts
            )
            
            if not response or not response.text:
                raise Exception("Gemini API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            
            # íŒŒì‹± ê²°ê³¼ ì²˜ë¦¬
            parsing_result = self._process_gemini_response(
                response.text, file_path, department
            )
            
            logger.info(f"âœ… Gemini PDF íŒŒì‹± ì™„ë£Œ: {len(parsing_result['content'])} ë¬¸ì")
            
            return {
                "success": True,
                "content": parsing_result["content"],
                "metadata": parsing_result["metadata"],
                "pages_processed": len(pdf_images),
                "extraction_type": extraction_type,
                "department": department,
                "parsed_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ Gemini PDF íŒŒì‹± ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ì‹œ ëŒ€ì²´ ë°©ë²• ì‚¬ìš©
            return await self._fallback_pdf_parsing(file_path, department)
    
    def _build_parsing_prompt(self, department: str, extraction_type: str) -> str:
        """í•™ê³¼ë³„ íŒŒì‹± í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        department_context = {
            "ê°„í˜¸í•™ê³¼": {
                "focus": "ê°„í˜¸í•™ êµìœ¡ ë‚´ìš©, í™˜ì ì¼€ì–´, ì„ìƒ ì‹¤ìŠµ, ê°„í˜¸ ì´ë¡ ",
                "key_concepts": "ê°„í˜¸ê³¼ì •, í™˜ìì•ˆì „, ê°ì—¼ê´€ë¦¬, ì•½ë¬¼ê´€ë¦¬, ê±´ê°•ì‚¬ì •",
                "terminology": "ê°„í˜¸ì§„ë‹¨, ê°„í˜¸ì¤‘ì¬, ê°„í˜¸í‰ê°€, í™˜ìêµìœ¡, ì˜ë£Œì§„ í˜‘ë ¥"
            },
            "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": {
                "focus": "ì¬í™œì¹˜ë£Œ, ìš´ë™ì¹˜ë£Œ, ë¬¼ë¦¬ì  ì¸ìì¹˜ë£Œ, ê¸°ëŠ¥ íšŒë³µ",
                "key_concepts": "ìš´ë™í•™, í•´ë¶€í•™, ì¹˜ë£Œê³„íš, ê¸°ëŠ¥í‰ê°€, ì¬í™œí”„ë¡œê·¸ë¨",
                "terminology": "ROM, MMT, ADL, ë³´í–‰í›ˆë ¨, ì „ê¸°ì¹˜ë£Œ, ë„ìˆ˜ì¹˜ë£Œ"
            },
            "ì‘ì—…ì¹˜ë£Œí•™ê³¼": {
                "focus": "ì¼ìƒìƒí™œí™œë™, ì¸ì§€ì¬í™œ, ì •ì‹ ì‚¬íšŒ ì¹˜ë£Œ, ë³´ì¡°ê³µí•™",
                "key_concepts": "í™œë™ë¶„ì„, í™˜ê²½ìˆ˜ì •, ë³´ì¡°ê¸°êµ¬, ê°ê°í†µí•©, ì¸ì§€ì¬í™œ",
                "terminology": "ADL, IADL, ì¸ì§€í‰ê°€, ì‘ì—…ë¶„ì„, í™˜ê²½ì ì‘, ë³´ì¡°ê³µí•™"
            }
        }
        
        context = department_context.get(department, {
            "focus": "ì¼ë°˜ êµìœ¡ ë‚´ìš©",
            "key_concepts": "ê¸°ë³¸ ê°œë…, ì´ë¡ , ì‹¤ìŠµ",
            "terminology": "ì „ë¬¸ ìš©ì–´"
        })
        
        if extraction_type == "comprehensive":
            prompt = f"""
ë‹¹ì‹ ì€ {department} ì „ë¬¸ êµìœ¡ìë£Œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ PDF ë¬¸ì„œë¥¼ {department} ê´€ì ì—ì„œ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

=== ë¶„ì„ ì´ˆì  ===
- ì£¼ìš” ì˜ì—­: {context['focus']}
- í•µì‹¬ ê°œë…: {context['key_concepts']}
- ì „ë¬¸ ìš©ì–´: {context['terminology']}

=== ì¶”ì¶œ ìš”êµ¬ì‚¬í•­ ===
1. ëª¨ë“  í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì •í™•íˆ ì¶”ì¶œ
2. êµ¬ì¡°ì™€ ê³„ì¸µì„ ìœ ì§€ (ì œëª©, ë³¸ë¬¸, ëª©ë¡ ë“±)
3. í‘œ, ê·¸ë˜í”„, ë‹¤ì´ì–´ê·¸ë¨ì˜ ë‚´ìš©ë„ í…ìŠ¤íŠ¸ë¡œ ì„¤ëª…
4. {department} ì „ë¬¸ ìš©ì–´ëŠ” ì •í™•íˆ ë³´ì¡´
5. í˜ì´ì§€ ë²ˆí˜¸ë‚˜ í—¤ë”/í‘¸í„°ëŠ” ì œì™¸

=== ì¶œë ¥ í˜•ì‹ ===
ì œëª©ê³¼ ë³¸ë¬¸ì„ êµ¬ë¶„í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”.
ì¤‘ìš”í•œ ê°œë…ì´ë‚˜ ìš©ì–´ëŠ” ê°•ì¡° í‘œì‹œí•´ì£¼ì„¸ìš”.

í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ê³  ì¶”ê°€ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.
"""
        
        elif extraction_type == "summary":
            prompt = f"""
ë‹¹ì‹ ì€ {department} ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ PDF ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ {department} ê´€ì ì—ì„œ ìš”ì•½í•´ì£¼ì„¸ìš”.

=== ìš”ì•½ ê¸°ì¤€ ===
- ì£¼ìš” ê°œë…ê³¼ ì´ë¡ 
- ì‹¤ìŠµ/ì„ìƒ ê´€ë ¨ ë‚´ìš©
- ì¤‘ìš”í•œ ì ˆì°¨ë‚˜ í”„ë¡œí† ì½œ
- í•µì‹¬ ìš©ì–´ ì •ì˜

=== ì¶œë ¥ í˜•ì‹ ===
1. ë¬¸ì„œ ê°œìš”
2. ì£¼ìš” ë‚´ìš© (í•­ëª©ë³„)
3. í•µì‹¬ ê°œë…
4. ì‹¤ë¬´ ì ìš© ì‚¬í•­
"""
        
        else:  # questions
            prompt = f"""
ë‹¹ì‹ ì€ {department} êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ PDF ë¬¸ì„œì—ì„œ í•™ìŠµ ë¬¸ì œë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ë‚´ìš©ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

=== ì¶”ì¶œ ê¸°ì¤€ ===
- ë¬¸ì œ ì¶œì œ ê°€ëŠ¥í•œ ê°œë…
- ì‚¬ë¡€ ì—°êµ¬ ìë£Œ
- í‰ê°€ ê°€ëŠ¥í•œ ì§€ì‹
- ì‹¤ìŠµ ê´€ë ¨ ë‚´ìš©

ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ë˜, ë¬¸ì œ ì¶œì œì— ì í•©í•œ ë¶€ë¶„ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
"""
        
        return prompt
    
    async def _convert_pdf_to_images(self, file_path: str) -> List[str]:
        """PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (í†µí•© íŒŒì„œ ì‚¬ìš©)"""
        try:
            from app.services.question_parser import QuestionParser
            parser = QuestionParser()
            return parser._convert_pdf_to_images_unified(file_path, max_pages=10)
        except Exception as e:
            logger.error(f"í†µí•© PDF ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return []
    
    def _process_gemini_response(
        self, 
        response_text: str, 
        file_path: str, 
        department: str
    ) -> Dict[str, Any]:
        """Gemini ì‘ë‹µ ì²˜ë¦¬"""
        
        # ì‘ë‹µ í…ìŠ¤íŠ¸ ì •ë¦¬
        content = response_text.strip()
        
        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        metadata = {
            "source_file": Path(file_path).name,
            "department": department,
            "content_length": len(content),
            "word_count": len(content.split()),
            "extracted_at": datetime.now().isoformat(),
            "parser": "Gemini API"
        }
        
        # ê°„ë‹¨í•œ êµ¬ì¡° ë¶„ì„
        lines = content.split('\n')
        sections = []
        current_section = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # ì œëª©ìœ¼ë¡œ ë³´ì´ëŠ” ë¼ì¸ ê°ì§€
            if (len(line) < 100 and 
                (line.isupper() or 
                 any(marker in line for marker in ['ì œ', 'ì¥', 'ì ˆ', 'í•­']) or
                 line.endswith(':'))):
                
                if current_section:
                    sections.append(current_section)
                
                current_section = {
                    "title": line,
                    "content": [],
                    "type": "section"
                }
            else:
                if current_section:
                    current_section["content"].append(line)
                else:
                    # ì²« ë²ˆì§¸ ì„¹ì…˜
                    current_section = {
                        "title": "ë³¸ë¬¸",
                        "content": [line],
                        "type": "content"
                    }
        
        if current_section:
            sections.append(current_section)
        
        metadata["sections"] = len(sections)
        metadata["structure"] = [{"title": s["title"], "lines": len(s["content"])} for s in sections]
        
        return {
            "content": content,
            "metadata": metadata,
            "sections": sections
        }
    
    async def _fallback_pdf_parsing(
        self, 
        file_path: str, 
        department: str
    ) -> Dict[str, Any]:
        """Gemini ì‚¬ìš© ë¶ˆê°€ì‹œ ëŒ€ì²´ PDF íŒŒì‹± (í†µí•© íŒŒì„œ ì‚¬ìš©)"""
        try:
            logger.info(f"ğŸ“„ ëŒ€ì²´ PDF íŒŒì‹± ë°©ë²• ì‚¬ìš©: {file_path}")
            
            from app.services.question_parser import QuestionParser
            parser = QuestionParser()
            content = parser._extract_pdf_text_fallback(file_path)
            
            if not content.strip():
                raise Exception("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            return {
                "success": True,
                "content": content.strip(),
                "metadata": {
                    "source_file": Path(file_path).name,
                    "department": department,
                    "content_length": len(content),
                    "parser": "í†µí•© íŒŒì„œ (fallback)",
                    "extracted_at": datetime.now().isoformat()
                },
                "extraction_type": "fallback",
                "department": department,
                "parsed_at": datetime.now().isoformat()
            }
                
        except Exception as e:
            logger.error(f"âŒ ëŒ€ì²´ PDF íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "content": "",
                "metadata": {},
                "extraction_type": "failed",
                "department": department,
                "parsed_at": datetime.now().isoformat()
            }
    
    async def analyze_content_structure(
        self,
        content: str,
        department: str
    ) -> Dict[str, Any]:
        """ì»¨í…ì¸  êµ¬ì¡° ë¶„ì„"""
        try:
            if not self.model:
                return self._basic_structure_analysis(content)
            
            prompt = f"""
ë‹¤ìŒ {department} êµìœ¡ ì»¨í…ì¸ ì˜ êµ¬ì¡°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

=== ë¶„ì„í•  ì»¨í…ì¸  ===
{content[:3000]}...

=== ë¶„ì„ ìš”êµ¬ì‚¬í•­ ===
1. ì£¼ìš” ì„¹ì…˜ êµ¬ë¶„
2. ì´ë¡ /ì‹¤ìŠµ/ì‚¬ë¡€ ë“± ì»¨í…ì¸  ìœ í˜• ë¶„ë¥˜
3. ë‚œì´ë„ ìˆ˜ì¤€ í‰ê°€
4. í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ

JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "sections": [...],
    "content_types": [...],
    "difficulty_level": "...",
    "keywords": [...],
    "summary": "..."
}}
"""
            
            response = await asyncio.to_thread(
                self.model.generate_content,
                prompt
            )
            
            # JSON íŒŒì‹± ì‹œë„
            import re
            json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
            if json_match:
                # í†µí•© AI JSON íŒŒì„œ ì‚¬ìš©
                from app.services.question_parser import QuestionParser
                result = QuestionParser.parse_ai_json_response(
                    json_match.group(),
                    fallback_data={"error": "JSON íŒŒì‹± ì‹¤íŒ¨"}
                )
                
                if "error" not in result:
                    return result
                else:
                    return json.loads(json_match.group())
            
        except Exception as e:
            logger.warning(f"Gemini êµ¬ì¡° ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        # ê¸°ë³¸ ë¶„ì„ìœ¼ë¡œ ëŒ€ì²´
        return self._basic_structure_analysis(content)
    
    def _basic_structure_analysis(self, content: str) -> Dict[str, Any]:
        """ê¸°ë³¸ êµ¬ì¡° ë¶„ì„"""
        lines = content.split('\n')
        sections = []
        keywords = []
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
        import re
        words = re.findall(r'\b[ê°€-í£]{2,}\b', content)
        word_freq = {}
        for word in words:
            word_freq[word] = word_freq.get(word, 0) + 1
        
        # ë¹ˆë„ ê¸°ì¤€ìœ¼ë¡œ í‚¤ì›Œë“œ ì„ ì •
        keywords = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:10]
        keywords = [word for word, freq in keywords if freq > 1]
        
        return {
            "sections": [{"title": "ì „ì²´ ë‚´ìš©", "lines": len(lines)}],
            "content_types": ["ì´ë¡ "],
            "difficulty_level": "ë³´í†µ",
            "keywords": keywords,
            "summary": f"{len(content)} ë¬¸ìì˜ êµìœ¡ ì»¨í…ì¸ "
        }

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
gemini_service = GeminiService() 