"""
ë¬¸ì œ ë° ì •ë‹µ ë°ì´í„° íŒŒì‹± ì„œë¹„ìŠ¤ (Gemini 2.0 Flash ê¸°ë°˜)

ëª¨ë“  íŒŒì¼ í˜•ì‹ì„ Gemini APIë¡œ í†µí•© ì²˜ë¦¬ - ëª¨ë“  í•™ê³¼ ì§€ì›
í†µí•©ëœ PDF ì²˜ë¦¬ ë° ë°°ì¹˜ íŒŒì‹± ê¸°ëŠ¥ í¬í•¨
"""
import json
from typing import List, Dict, Any, Optional, Union, Callable
from datetime import datetime, timezone
import google.generativeai as genai
import os
from pathlib import Path
import base64
import logging
import re
import requests
import pandas as pd
from app.models.question import DifficultyLevel
from app.core.config import settings
from app.services.question_type_mapper import question_type_mapper
from app.services.evaluator_type_mapper import evaluator_type_mapper
# AI ë¬¸ì œ ë¶„ì„ê¸° import ì¶”ê°€
from app.services.ai_question_analyzer import get_ai_analyzer

logger = logging.getLogger(__name__)

# Poppler ê²½ë¡œ ì„¤ì • (PDFâ†’ì´ë¯¸ì§€ ë³€í™˜ìš©) - í´ë¼ìš°ë“œ í™˜ê²½ ìµœì í™”
_default_poppler = '/usr/bin'
POPPLER_PATH = os.getenv('POPPLER_PATH', _default_poppler)

# í•™ê³¼ ë§¤í•‘
DEPARTMENT_MAPPING = {
    "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": "ë¬¼ë¦¬ì¹˜ë£Œ",
    "ì‘ì—…ì¹˜ë£Œí•™ê³¼": "ì‘ì—…ì¹˜ë£Œ", 
    "ê°„í˜¸í•™ê³¼": "ê°„í˜¸",
    "ë¬¼ë¦¬ì¹˜ë£Œ": "ë¬¼ë¦¬ì¹˜ë£Œ",
    "ì‘ì—…ì¹˜ë£Œ": "ì‘ì—…ì¹˜ë£Œ",
    "ê°„í˜¸": "ê°„í˜¸"
}

class QuestionParser:
    """gemini-2.0-flash-exp ê¸°ë°˜ í†µí•© íŒŒì„œ - ëª¨ë“  í•™ê³¼ ì§€ì› + í†µí•© PDF ì²˜ë¦¬"""
    
    # í´ë˜ìŠ¤ ìƒìˆ˜
    MAX_QUESTIONS = 22
    DEFAULT_YEAR = 2024
    DEFAULT_DIFFICULTY = "ì¤‘"
    DEFAULT_DEPARTMENT = "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼"
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Args:
            api_key: Gemini API í‚¤ (Noneì¸ ê²½ìš° í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´)
        """
        # ì§ì ‘ API í‚¤ ì„¤ì •
        self.api_key = api_key or "AIzaSyAU_5m68cNAMIBn7m1uQPrYKNFR0oPO3QA"
        if self.api_key:
            genai.configure(api_key=self.api_key)
            # Gemini 2.0 Flash ëª¨ë¸ ì‚¬ìš© (ì •í™•í•œ ëª¨ë¸ëª…ìœ¼ë¡œ ìˆ˜ì •)
            model_name = getattr(settings, 'GEMINI_MODEL_NAME', 'gemini-2.0-flash-exp')
            self.model = genai.GenerativeModel(model_name)
            logger.info(f"Gemini ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ: {model_name}")
        else:
            self.model = None
            logger.warning("Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def _apply_question_limit(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """22ê°œ ì œí•œ ë¡œì§ í†µí•© ë©”ì„œë“œ"""
        if not isinstance(data, list):
            return data
        
        # ë¬¸ì œë²ˆí˜¸ê°€ 22 ì´í•˜ì¸ ê²ƒë§Œ í•„í„°ë§ í›„ 22ê°œë¡œ ì œí•œ
        filtered_data = [item for item in data if item.get('question_number', 0) <= self.MAX_QUESTIONS]
        limited_data = filtered_data[:self.MAX_QUESTIONS]
        
        if len(filtered_data) > self.MAX_QUESTIONS:
            logger.info(f"ğŸ“‹ ë¬¸ì œ ì œí•œ ì ìš©: {len(filtered_data)}ê°œ â†’ {len(limited_data)}ê°œ")
        
        return limited_data
    
    def _normalize_year(self, item: Dict[str, Any], fallback_year: Optional[int] = None) -> int:
        """ì—°ë„ ì •ê·œí™” í†µí•© ë©”ì„œë“œ"""
        year = item.get('year')
        
        # ìœ íš¨í•œ ì—°ë„ ì²´í¬
        if year and isinstance(year, int) and 2000 <= year <= 2030:
            return year
        
        # ë¬¸ìì—´ ì—°ë„ ë³€í™˜ ì‹œë„
        if isinstance(year, str) and year.isdigit():
            year_int = int(year)
            if 2000 <= year_int <= 2030:
                return year_int
        
        # í´ë°± ì—°ë„ ì‚¬ìš©
        if fallback_year and 2000 <= fallback_year <= 2030:
            return fallback_year
        
        # ê¸°ë³¸ê°’
        return self.DEFAULT_YEAR
    
    def _get_normalized_department(self, department: str) -> str:
        """í•™ê³¼ëª… ì •ê·œí™” í†µí•© ë©”ì„œë“œ"""
        return DEPARTMENT_MAPPING.get(department, "ë¬¼ë¦¬ì¹˜ë£Œ")
    
    def detect_department_from_content(self, file_path: str, content_sample: str = "") -> str:
        """
        íŒŒì¼ëª…ê³¼ ë‚´ìš©ìœ¼ë¡œë¶€í„° í•™ê³¼ ìë™ ê°ì§€
        
        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            content_sample: íŒŒì¼ ë‚´ìš© ìƒ˜í”Œ
            
        Returns:
            str: ê°ì§€ëœ í•™ê³¼ëª…
        """
        file_name = Path(file_path).name.lower()
        content_lower = content_sample.lower()
        
        # íŒŒì¼ëª… ê¸°ë°˜ ê°ì§€
        if any(keyword in file_name for keyword in ['ë¬¼ì¹˜', 'ë¬¼ë¦¬ì¹˜ë£Œ', 'pt', 'physical']):
            return "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼"
        elif any(keyword in file_name for keyword in ['ì‘ì¹˜', 'ì‘ì—…ì¹˜ë£Œ', 'ot', 'occupational']):
            return "ì‘ì—…ì¹˜ë£Œí•™ê³¼"
        elif any(keyword in file_name for keyword in ['ê°„í˜¸', 'nursing', 'ë„ˆì‹±']):
            return "ê°„í˜¸í•™ê³¼"
        
        # ë‚´ìš© ê¸°ë°˜ ê°ì§€
        if any(keyword in content_lower for keyword in ['ë¬¼ë¦¬ì¹˜ë£Œ', 'ì¬í™œì˜í•™', 'ìš´ë™ì¹˜ë£Œ', 'ì „ê¸°ì¹˜ë£Œ']):
            return "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼"
        elif any(keyword in content_lower for keyword in ['ì‘ì—…ì¹˜ë£Œ', 'ì¸ì§€ì¹˜ë£Œ', 'ê°ê°í†µí•©', 'ë³´ì¡°ê¸°êµ¬']):
            return "ì‘ì—…ì¹˜ë£Œí•™ê³¼"
        elif any(keyword in content_lower for keyword in ['ê°„í˜¸í•™', 'ê°„í˜¸ì‚¬', 'í™˜ìê°„í˜¸', 'ì„ìƒê°„í˜¸']):
            return "ê°„í˜¸í•™ê³¼"
        
        # ê¸°ë³¸ê°’ (íŒŒì¼ëª…ì—ì„œ ì¶”ì •)
        if '2.' in file_name or '3.' in file_name:
            return "ì‘ì—…ì¹˜ë£Œí•™ê³¼"  # ì‘ì—…ì¹˜ë£Œ íŒŒì¼ íŒ¨í„´
        elif '1.' in file_name:
            return "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼"
        
        return "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼"  # ìµœì¢… ê¸°ë³¸ê°’
    
    def parse_any_file(
        self, 
        file_path: str, 
        content_type: str = "auto", 
        department: str = "auto",
        progress_callback: Optional[Callable[[str, float], None]] = None
    ) -> Dict[str, Any]:
        """
        ëª¨ë“  íŒŒì¼ í˜•ì‹ì„ Geminië¡œ íŒŒì‹± (ë¶„í•  íŒŒì‹± ì§€ì›) - ëª¨ë“  í•™ê³¼ ì§€ì›
        
        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            content_type: "questions", "answers", ë˜ëŠ” "auto" (ìë™ ê°ì§€)
            department: í•™ê³¼ ì •ë³´ ("auto"ì¸ ê²½ìš° ìë™ ê°ì§€)
            progress_callback: ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜ (message: str, progress: float)
            
        Returns:
            íŒŒì‹±ëœ ë°ì´í„°
        """
        if progress_callback:
            progress_callback("ğŸš€ íŒŒì‹± ì‹œì‘ ì¤‘...", 0.0)
        
        if not self.model:
            logger.error("Gemini APIê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return {"type": content_type, "data": [], "error": "Gemini API not initialized"}

        if not os.path.exists(file_path):
            logger.error(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
            return {"type": content_type, "data": [], "error": "File not found"}

        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = os.path.getsize(file_path)
        logger.info(f"ğŸ“„ íŒŒì¼ í¬ê¸°: {file_size / (1024*1024):.2f} MB")
        
        if progress_callback:
            progress_callback(f"ğŸ“„ íŒŒì¼ ë¶„ì„ ì¤‘... ({file_size / (1024*1024):.2f} MB)", 5.0)

        # í•™ê³¼ ìë™ ê°ì§€
        if department == "auto":
            try:
                # íŒŒì¼ëª…ìœ¼ë¡œ ë¨¼ì € ê°ì§€ ì‹œë„
                detected_dept = self.detect_department_from_content(file_path)
                logger.info(f"ğŸ¯ í•™ê³¼ ìë™ ê°ì§€: {detected_dept}")
                department = detected_dept
                
                if progress_callback:
                    progress_callback(f"ğŸ¯ í•™ê³¼ ê°ì§€ ì™„ë£Œ: {department}", 10.0)
            except Exception as e:
                logger.warning(f"í•™ê³¼ ìë™ ê°ì§€ ì‹¤íŒ¨: {e}, ê¸°ë³¸ê°’ ì‚¬ìš©")
                department = "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼"

        # DB ìŠ¤í‚¤ë§ˆ ì •ë³´
        db_schema = f"""
ìš°ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° ({department} ì „ìš©):
Question í…Œì´ë¸”:
- question_number: ë¬¸ì œ ë²ˆí˜¸ (ì •ìˆ˜, 1~22ê¹Œì§€ë§Œ)
- content: ë¬¸ì œ ë‚´ìš© (í…ìŠ¤íŠ¸)
- description: ë¬¸ì œ ì„¤ëª…/ì§€ë¬¸ (ë¬¸ìì—´ ë°°ì—´, ì˜ˆ: ["- ì„¤ëª…1", "- ì„¤ëª…2"])
- options: {{"1": "ì„ íƒì§€1", "2": "ì„ íƒì§€2", ..., "5": "ì„ íƒì§€5"}}
- correct_answer: ì •ë‹µ (ë¬¸ìì—´, ì˜ˆ: "3")
- subject: ê³¼ëª©ëª… ({department} ê´€ë ¨)
- area_name: ì˜ì—­ì´ë¦„ ({department} ì „ë¬¸ ì˜ì—­)
- difficulty: "í•˜", "ì¤‘", "ìƒ" ì¤‘ í•˜ë‚˜
- year: ì—°ë„ (ì •ìˆ˜)
ì¤‘ìš”: 22ë²ˆ ë¬¸ì œê¹Œì§€ë§Œ íŒŒì‹±í•˜ì„¸ìš”. ë” ë§ì€ ë¬¸ì œê°€ ìˆì–´ë„ 22ë²ˆê¹Œì§€ë§Œ ì²˜ë¦¬í•˜ê³  ì¤‘ë‹¨í•˜ì„¸ìš”.
"""

        try:
            # íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ì²˜ë¦¬
            file_extension = Path(file_path).suffix.lower()

            if file_extension in ['.xlsx', '.xls']:
                if progress_callback:
                    progress_callback("ğŸ“Š Excel íŒŒì¼ ì²˜ë¦¬ ì¤‘...", 15.0)
                all_data = self._process_excel_file_chunked(file_path, content_type, db_schema, department, progress_callback)
            elif file_extension == '.pdf':
                if progress_callback:
                    progress_callback("ğŸ“– PDF íŒŒì¼ ì²˜ë¦¬ ì¤‘...", 15.0)
                all_data = self._process_pdf_with_images(file_path, content_type, db_schema, progress_callback)
            else:
                if progress_callback:
                    progress_callback("ğŸ“ í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬ ì¤‘...", 15.0)
                all_data = self._process_text_file_chunked(file_path, content_type, db_schema, progress_callback)

            # 22ê°œ ì œí•œ ì ìš©
            all_data = self._apply_question_limit(all_data)

            if progress_callback:
                progress_callback(f"ğŸ“‹ ê¸°ë³¸ íŒŒì‹± ì™„ë£Œ: {len(all_data)}ê°œ ë¬¸ì œ", 70.0)

            logger.info(f"ë¶„í•  íŒŒì‹± ì™„ë£Œ: {file_path}, ì´ ë°ì´í„° ê°œìˆ˜: {len(all_data)}")
            
            # ğŸ“Š 3ë‹¨ê³„: AI ê¸°ë°˜ ë¬¸ì œ ë¶„ì„ (content_typeì´ questionsì¸ ê²½ìš°)
            if content_type == "questions" and all_data:
                try:
                    if progress_callback:
                        progress_callback(f"ğŸ¤– AI ë¬¸ì œ ë¶„ì„ ì‹œì‘: {len(all_data)}ê°œ ë¬¸ì œ", 75.0)
                    
                    logger.info(f"ğŸ¤– AI ë¬¸ì œ ë¶„ì„ ì‹œì‘: {len(all_data)}ê°œ ë¬¸ì œ ({department})")
                    
                    # AI ë¶„ì„ê¸° ì´ˆê¸°í™”
                    from app.services.ai_difficulty_analyzer import DifficultyAnalyzer
                    ai_analyzer = DifficultyAnalyzer()
                    
                    # í•™ê³¼ ì •ë³´ ë§¤í•‘
                    ai_department = DEPARTMENT_MAPPING.get(department, "ë¬¼ë¦¬ì¹˜ë£Œ")
                    
                    # ê° ë¬¸ì œë³„ AI ë¶„ì„
                    total_questions = len(all_data)
                    for idx, item in enumerate(all_data):
                        try:
                            content = item.get("content", "")
                            question_number = item.get("question_number", 1)
                            
                            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                            ai_progress = 75.0 + (idx / total_questions) * 20.0
                            if progress_callback:
                                progress_callback(f"ğŸ¤– ë¬¸ì œ {question_number} AI ë¶„ì„ ì¤‘... ({idx+1}/{total_questions})", ai_progress)
                            
                            if content and content.strip():
                                # AI ë¶„ì„
                                ai_result = ai_analyzer.analyze_question_auto(content, question_number, ai_department)
                                
                                if ai_result:
                                    # AI ë¶„ì„ ê²°ê³¼ ì¶”ê°€
                                    item["ai_difficulty"] = ai_result.get("difficulty", "ì¤‘")
                                    item["ai_question_type"] = ai_result.get("question_type", "ê°ê´€ì‹")
                                    item["ai_confidence"] = ai_result.get("confidence", "medium")
                                    item["ai_reasoning"] = ai_result.get("ai_reasoning", "AI ë¶„ì„ ì™„ë£Œ")
                                    item["ai_analysis_complete"] = True
                                    item["updated_at"] = datetime.now().isoformat()
                                    
                                    # ê¸°ë³¸ ë‚œì´ë„ ì—…ë°ì´íŠ¸
                                    item["difficulty"] = ai_result.get("difficulty", "ì¤‘")
                                    
                                    # ì˜ì—­ëª…ì€ AI ë¶„ì„ ê²°ê³¼ ìš°ì„ , ì—†ìœ¼ë©´ í‰ê°€ìœ„ì› ë°ì´í„°ì—ì„œ ì¡°íšŒ
                                    area_name = ai_result.get("area_name")
                                    if not area_name or area_name == "ì¼ë°˜":
                                        year = item.get("year", 2024)
                                        area_name = evaluator_type_mapper.get_area_name_for_question(
                                            department, year, question_number
                                        )
                                    item["area_name"] = area_name
                                    
                                    logger.info(f"âœ… ë¬¸ì œ {question_number} AI ë¶„ì„ ì™„ë£Œ: {ai_result.get('difficulty')} ë‚œì´ë„")
                                else:
                                    # AI ë¶„ì„ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
                                    item["ai_analysis_complete"] = False
                                    item["ai_reasoning"] = "AI ë¶„ì„ ë¶ˆê°€ëŠ¥ìœ¼ë¡œ ê¸°ë³¸ ê·œì¹™ ì ìš©"
                                    
                                    # ì˜ì—­ëª…ì€ í‰ê°€ìœ„ì› ë°ì´í„°ì—ì„œ ì¡°íšŒ
                                    year = item.get("year", 2024)
                                    area_name = evaluator_type_mapper.get_area_name_for_question(
                                        department, year, question_number
                                    )
                                    item["area_name"] = area_name
                                    
                                    logger.warning(f"âš ï¸ ë¬¸ì œ {question_number} AI ë¶„ì„ ì‹¤íŒ¨")
                            else:
                                logger.warning(f"âš ï¸ ë¬¸ì œ {question_number} content ì—†ìŒìœ¼ë¡œ AI ë¶„ì„ ê±´ë„ˆëœ€")
                                
                                # ì˜ì—­ëª…ì€ í‰ê°€ìœ„ì› ë°ì´í„°ì—ì„œ ì¡°íšŒ
                                year = item.get("year", 2024)
                                area_name = evaluator_type_mapper.get_area_name_for_question(
                                    department, year, question_number
                                )
                                item["area_name"] = area_name
                                
                        except Exception as e:
                            logger.error(f"âŒ ë¬¸ì œ {item.get('question_number')} AI ë¶„ì„ ì˜¤ë¥˜: {e}")
                            item["ai_analysis_complete"] = False
                            item["ai_reasoning"] = f"AI ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
                            
                            # ì˜ì—­ëª…ì€ í‰ê°€ìœ„ì› ë°ì´í„°ì—ì„œ ì¡°íšŒ
                            year = item.get("year", 2024)
                            question_number = item.get("question_number", 1)
                            area_name = evaluator_type_mapper.get_area_name_for_question(
                                department, year, question_number
                            )
                            item["area_name"] = area_name
                    
                    if progress_callback:
                        progress_callback(f"ğŸ¯ AI ë¶„ì„ ì™„ë£Œ: {len(all_data)}ê°œ ë¬¸ì œ ì²˜ë¦¬ë¨", 95.0)
                    
                    logger.info(f"ğŸ¯ AI ë¶„ì„ ì™„ë£Œ: {len(all_data)}ê°œ ë¬¸ì œ ì²˜ë¦¬ë¨")
                    
                except Exception as e:
                    logger.error(f"âŒ AI ë¶„ì„ ì „ì²´ ì‹¤íŒ¨: {e}")
                    if progress_callback:
                        progress_callback(f"âš ï¸ AI ë¶„ì„ ì‹¤íŒ¨, ê¸°ë³¸ íŒŒì‹± ê²°ê³¼ ì‚¬ìš©", 95.0)
                    # AI ë¶„ì„ ì‹¤íŒ¨í•´ë„ íŒŒì‹±ì€ ê³„ì† ì§„í–‰
            
            if progress_callback:
                progress_callback("âœ… íŒŒì‹± ì™„ë£Œ!", 100.0)
            
            return {
                "type": content_type if content_type != "auto" else "questions", 
                "data": all_data,
                "department": department,
                "total_questions": len(all_data)
            }

        except Exception as e:
            logger.error(f"ë¶„í•  íŒŒì‹± ì˜¤ë¥˜ ({file_path}): {e}")
            if progress_callback:
                progress_callback(f"âŒ íŒŒì‹± ì˜¤ë¥˜: {str(e)}", 0.0)
            return {"type": content_type, "data": [], "error": str(e)}
    
    def _generate_prompt(self, file_path: str, content_type: str, db_schema: str) -> str:
        """í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        file_name = Path(file_path).name
        
        if content_type == "auto":
            return f"""ë‹¤ìŒ íŒŒì¼ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

íŒŒì¼ëª…: {file_name}

ì´ íŒŒì¼ì´ ë¬¸ì œ ë°ì´í„°ì¸ì§€ ì •ë‹µ ë°ì´í„°ì¸ì§€ ìë™ìœ¼ë¡œ íŒë‹¨í•˜ê³ ,
ì•„ë˜ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°ì— ë§ê²Œ JSONìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

{db_schema}

ë°˜í™˜ í˜•ì‹:
{{
    "type": "questions" ë˜ëŠ” "answers",
    "data": [
        // ìœ„ ìŠ¤í‚¤ë§ˆì— ë§ëŠ” ê°ì²´ë“¤
    ]
}}

ì£¼ì˜ì‚¬í•­:
- ë¬¸ì œë²ˆí˜¸ëŠ” ë°˜ë“œì‹œ ì •ìˆ˜ë¡œ, 22ë²ˆê¹Œì§€ë§Œ ì²˜ë¦¬
- ì„ íƒì§€ ë²ˆí˜¸ëŠ” "1", "2", "3", "4", "5" ë¬¸ìì—´ë¡œ
- ë‚œì´ë„: "í•˜", "ì¤‘", "ìƒ" ì¤‘ í•˜ë‚˜ë¡œ í‘œì‹œ
- ì—°ë„ëŠ” íŒŒì¼ëª…ì´ë‚˜ ë‚´ìš©ì—ì„œ ì¶”ì¶œ
- ì—†ëŠ” í•„ë“œëŠ” nullë¡œ í‘œì‹œ
- JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”"""
            
        elif content_type == "questions":
            return f"""ì´ íŒŒì¼ì€ ì‹œí—˜ ë¬¸ì œì…ë‹ˆë‹¤.
            
{db_schema}

ìœ„ Question ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ëª¨ë“  ë¬¸ì œë¥¼ JSON ë°°ì—´ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.
ì„ íƒì§€ê°€ â‘ â‘¡â‘¢â‘£â‘¤ë¡œ ë˜ì–´ìˆë‹¤ë©´ "1", "2", "3", "4", "5"ë¡œ ë³€í™˜í•˜ì„¸ìš”.

ì¤‘ìš” ì œí•œì‚¬í•­:
- 22ë²ˆ ë¬¸ì œê¹Œì§€ë§Œ íŒŒì‹±í•˜ì„¸ìš”. ë” ë§ì€ ë¬¸ì œê°€ ìˆì–´ë„ 22ë²ˆì—ì„œ ì¤‘ë‹¨í•˜ì„¸ìš”.
- ë¬¸ì œë²ˆí˜¸ê°€ 22ë¥¼ ì´ˆê³¼í•˜ë©´ ë¬´ì‹œí•˜ì„¸ìš”.

ì£¼ì˜ì‚¬í•­:
- ë¬¸ì œì— ë³´ì¶© ì„¤ëª…ì´ë‚˜ ì§€ë¬¸ì´ ìˆìœ¼ë©´ description í•„ë“œì— ë°°ì—´ë¡œ ì €ì¥í•˜ì„¸ìš”
- descriptionì€ ë¬¸ì œë¥¼ í’€ê¸° ìœ„í•œ ì¶”ê°€ ì •ë³´ë‚˜ ì¡°ê±´ë“¤ì„ ë‹´ìŠµë‹ˆë‹¤
- ì˜ˆ: ["- ëª¸ì— ë„ë¦¬ ë¶„í¬í•˜ë©°, ëª¸ì˜ êµ¬ì¡°ë¥¼ ì´ë£¸", "- ì„¸í¬ë‚˜ ê¸°ê´€ ì‚¬ì´ í‹ˆì„ ë©”ìš°ê³ , ê¸°ê´€ì„ ì§€ì§€Â·ë³´í˜¸í•¨"]
- JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”"""
        else:  # answers
            return f"""ì´ íŒŒì¼ì€ ì‹œí—˜ ì •ë‹µì§€ì…ë‹ˆë‹¤. ê° ë¬¸ì œ ë²ˆí˜¸ì™€ í•´ë‹¹ ì •ë‹µì„ ì •í™•íˆ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

{db_schema}

ë‹µì•ˆì§€ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì°¾ì•„ JSON ë°°ì—´ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”:

**ì¶”ì¶œ ëŒ€ìƒ:**
- question_number: ë¬¸ì œ ë²ˆí˜¸ (1, 2, 3, ... í˜•íƒœì˜ ìˆ«ì)
- correct_answer: ì •ë‹µ (1, 2, 3, 4, 5 ì¤‘ í•˜ë‚˜)
- subject: ê³¼ëª©ëª… (ì´ë¯¸ì§€/í…ìŠ¤íŠ¸ì—ì„œ ì‹ë³„ ê°€ëŠ¥í•˜ë©´)
- area_name: ì˜ì—­ëª… (ì´ë¯¸ì§€/í…ìŠ¤íŠ¸ì—ì„œ ì‹ë³„ ê°€ëŠ¥í•˜ë©´)
- difficulty: ë‚œì´ë„ (ì´ë¯¸ì§€/í…ìŠ¤íŠ¸ì—ì„œ ì‹ë³„ ê°€ëŠ¥í•˜ë©´, ì—†ìœ¼ë©´ null)
- year: ì—°ë„ (íŒŒì¼ëª…ì´ë‚˜ ë‚´ìš©ì—ì„œ ì¶”ì¶œ)

**ë‹µì•ˆì§€ ì¸ì‹ íŒ¨í„´:**
- "1ë²ˆ: â‘¡", "2ë²ˆ: â‘ ", "3ë²ˆ: â‘¤" í˜•íƒœ
- "1. â‘¡", "2. â‘ ", "3. â‘¤" í˜•íƒœ  
- "ë¬¸ì œ 1: ì •ë‹µ 2", "ë¬¸ì œ 2: ì •ë‹µ 1" í˜•íƒœ
- í‘œ í˜•íƒœë¡œ ëœ ë‹µì•ˆ (ë¬¸ì œë²ˆí˜¸ | ì •ë‹µ)
- â‘ â‘¡â‘¢â‘£â‘¤ ê¸°í˜¸ëŠ” 1,2,3,4,5ë¡œ ë³€í™˜

**ì¶œë ¥ ì˜ˆì‹œ:**
[
  {
    "question_number": 1,
    "correct_answer": "2",
    "year": 2020
  },
  {
    "question_number": 2,
    "correct_answer": "1",
    "year": 2020
  }
]

**ì¤‘ìš” ì œí•œì‚¬í•­:**
- 22ë²ˆ ë¬¸ì œê¹Œì§€ë§Œ íŒŒì‹±í•˜ì„¸ìš”
- ì •ë‹µì€ ë°˜ë“œì‹œ "1", "2", "3", "4", "5" ì¤‘ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ
- ë¬¸ì œ ë²ˆí˜¸ê°€ ëª…í™•í•˜ì§€ ì•Šì€ ê²½ìš° ìˆœì„œëŒ€ë¡œ 1,2,3... ë°°ì •
- JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”"""
    
    async def _process_excel_file_chunked(
        self, 
        file_path: str, 
        content_type: str, 
        db_schema: str, 
        department: str = "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼",
        progress_callback: Optional[Callable[[str, float], None]] = None
    ) -> List[Dict[str, Any]]:
        """Excel íŒŒì¼ ë¶„í•  ì²˜ë¦¬ (openpyxl ì‚¬ìš©) - ëª¨ë“  í•™ê³¼ ì§€ì›"""
        try:
            from openpyxl import load_workbook
        except ImportError:
            logger.error("openpyxl ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            raise ImportError("openpyxlì´ í•„ìš”í•©ë‹ˆë‹¤. pip install openpyxlë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
        
        all_data = []
        
        if progress_callback:
            progress_callback(f"ğŸ“Š Excel íŒŒì¼ ë¡œë“œ ì¤‘... ({department})", 20.0)
        
        # ğŸ“Š 1ë‹¨ê³„: ë¬¸ì œ ìœ í˜• ë§¤í•‘ ë°ì´í„° ìƒì„± (content_typeì´ questionsì¸ ê²½ìš°)
        if content_type == "questions":
            try:
                # êµìˆ˜ëª… ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ)
                professor_name = self._extract_professor_from_filename(file_path)
                
                if progress_callback:
                    progress_callback(f"ğŸ¯ ë¬¸ì œ ìœ í˜• ìë™ ë°°ì • ì¤‘... ({professor_name})", 25.0)
                
                # ë¬¸ì œ ìœ í˜• ë§¤í•‘ ì²˜ë¦¬
                logger.info(f"ğŸ¯ ë¬¸ì œ ìœ í˜• ìë™ ë°°ì • ì‹œì‘: {professor_name} ({department})")
                type_result = await question_type_mapper.process_excel_for_question_types(
                    file_path, professor_name, department
                )
                
                if type_result.get("success"):
                    logger.info(f"âœ… ë¬¸ì œ ìœ í˜• ë§¤í•‘ ì™„ë£Œ: {type_result['total_questions']}ê°œ ë¬¸ì œ")
                    self.question_type_file_key = type_result["file_key"]
                else:
                    logger.warning(f"âš ï¸ ë¬¸ì œ ìœ í˜• ë§¤í•‘ ì‹¤íŒ¨: {type_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                    self.question_type_file_key = None
                    
            except Exception as e:
                logger.warning(f"âš ï¸ ë¬¸ì œ ìœ í˜• ë§¤í•‘ ê³¼ì •ì—ì„œ ì˜¤ë¥˜: {e}")
                self.question_type_file_key = None
        
        try:
            workbook = load_workbook(file_path, read_only=True)
            logger.info(f"Excel íŒŒì¼ ì‹œíŠ¸ ëª©ë¡: {workbook.sheetnames}")
            
            if progress_callback:
                progress_callback(f"ğŸ“Š ì‹œíŠ¸ ë¶„ì„ ì¤‘: {len(workbook.sheetnames)}ê°œ ì‹œíŠ¸", 30.0)
            
            total_sheets = len(workbook.sheetnames)
            for sheet_idx, sheet_name in enumerate(workbook.sheetnames):
                worksheet = workbook[sheet_name]
                logger.info(f"ì‹œíŠ¸ '{sheet_name}' ì²˜ë¦¬ ì¤‘... ({sheet_idx+1}/{total_sheets})")
                
                sheet_progress = 30.0 + (sheet_idx / total_sheets) * 30.0
                if progress_callback:
                    progress_callback(f"ğŸ“„ ì‹œíŠ¸ '{sheet_name}' ì²˜ë¦¬ ì¤‘... ({sheet_idx+1}/{total_sheets})", sheet_progress)
                
                # ì‹œíŠ¸ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                sheet_data = []
                row_count = 0
                
                for row in worksheet.iter_rows(values_only=True):
                    if row_count >= 100:  # ì‹œíŠ¸ë‹¹ ìµœëŒ€ 100í–‰
                        break
                    if any(cell for cell in row):  # ë¹ˆ í–‰ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                        sheet_data.append('\t'.join([str(cell) if cell is not None else '' for cell in row]))
                        row_count += 1
                
                if sheet_data:
                    sheet_text = '\n'.join(sheet_data)
                    
                    # Geminië¡œ êµ¬ì¡°í™” ìš”ì²­
                    prompt = self._generate_prompt(f"{file_path} (ì‹œíŠ¸: {sheet_name})", content_type, db_schema)
                    structured_prompt = f"""
ë‹¤ìŒì€ Excel ì‹œíŠ¸ '{sheet_name}'ì˜ ë°ì´í„°ì…ë‹ˆë‹¤ ({department} ì „ìš©).
ì´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

{prompt}

Excel ë°ì´í„°:
{sheet_text}

ì¤‘ìš”: 22ë²ˆ ë¬¸ì œê¹Œì§€ë§Œ ì²˜ë¦¬í•˜ì„¸ìš”.
í•™ê³¼: {department}
"""
                    
                    try:
                        response = self.model.generate_content([structured_prompt])
                        if response and response.text:
                            sheet_results = self._parse_gemini_response(response.text, content_type)
                            sheet_data_parsed = sheet_results.get("data", [])
                            
                            # 22ë²ˆ ì œí•œ ì ìš©
                            sheet_data_parsed = self._apply_question_limit(sheet_data_parsed)
                            
                            if sheet_data_parsed:
                                # year ë³´ì •: Geminiê°€ yearë¥¼ ëª» ë½‘ì•˜ê±°ë‚˜ 0/Noneì´ë©´ ì‹œíŠ¸ëª…ì—ì„œ ì¶”ì¶œ
                                year_in_sheet = None
                                match = re.search(r'(20\d{2})', sheet_name)
                                if match:
                                    year_in_sheet = int(match.group(1))
                                else:
                                    year_in_sheet = 2020  # ê¸°ë³¸ê°’
                                
                                # ğŸ“Š 2ë‹¨ê³„: ê° ë¬¸ì œì— ìœ í˜• ì •ë³´ ì¶”ê°€
                                for item in sheet_data_parsed:
                                    if not item.get('year') or item.get('year') in [0, None, '']:
                                        item['year'] = year_in_sheet
                                    
                                    # í•™ê³¼ ì •ë³´ ì¶”ê°€
                                    item['department'] = department
                                    
                                    # ë¬¸ì œ ìœ í˜• ìë™ ë°°ì • (questionsì¸ ê²½ìš°ë§Œ)
                                    if content_type == "questions" and hasattr(self, 'question_type_file_key'):
                                        question_content = item.get('content', '')
                                        question_number = item.get('question_number')
                                        
                                        # ë¬¸ì œ ìœ í˜• ì¡°íšŒ (ê¸°ì¡´ ê·œì¹™ ê¸°ë°˜)
                                        question_type = question_type_mapper.get_question_type_for_question(
                                            question_content, 
                                            self.question_type_file_key, 
                                            question_number
                                        )
                                        
                                        # ë¬¸ì œ ìœ í˜• ì •ë³´ ì¶”ê°€
                                        item['question_type'] = question_type
                                        item['type_name'] = question_type_mapper.question_types.get(
                                            question_type, {}
                                        ).get('name', question_type)
                                        
                                        logger.debug(f"   ë¬¸ì œ {question_number}: {question_type} ({item['type_name']})")
                                
                                logger.info(f"ì‹œíŠ¸ '{sheet_name}': {len(sheet_data_parsed)}ê°œ í•­ëª© íŒŒì‹± ì„±ê³µ (ì—°ë„ ë³´ì •: {year_in_sheet})")
                                all_data.extend(sheet_data_parsed)
                            else:
                                logger.warning(f"ì‹œíŠ¸ '{sheet_name}': íŒŒì‹±ëœ ë°ì´í„° ì—†ìŒ")
                    except Exception as e:
                        logger.error(f"ì‹œíŠ¸ '{sheet_name}' íŒŒì‹± ì‹¤íŒ¨: {e}")
                        continue
                        
                # 22ê°œ ë‹¬ì„±í•˜ë©´ ì¤‘ë‹¨
                if len(all_data) >= self.MAX_QUESTIONS:
                    all_data = self._apply_question_limit(all_data)
                    break
            
            workbook.close()
            
            if progress_callback:
                progress_callback(f"ğŸ“Š Excel íŒŒì‹± ì™„ë£Œ: {len(all_data)}ê°œ ë¬¸ì œ", 60.0)
            
            logger.info(f"Excel íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: ì´ {len(all_data)}ê°œ í•­ëª©")
            return all_data
            
        except Exception as e:
            logger.error(f"Excel íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            raise
    
    def _extract_professor_from_filename(self, file_path: str) -> str:
        """íŒŒì¼ëª…ì—ì„œ êµìˆ˜ëª… ì¶”ì¶œ"""
        try:
            filename = Path(file_path).name
            # "2. ì‹ ì¥í›ˆ_ì‘ì¹˜_ë§ˆìŠ¤í„°ì½”ë”©ì§€.xlsx" -> "ì‹ ì¥í›ˆ"
            if "_" in filename:
                parts = filename.split("_")
                if len(parts) >= 2:
                    name_part = parts[0].replace("2. ", "").strip()
                    return name_part
            
            # ê¸°ë³¸ê°’: íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°
            return Path(file_path).stem
            
        except Exception as e:
            logger.warning(f"êµìˆ˜ëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return "Unknown"
    
    def _process_pdf_with_images(
        self, 
        file_path: str, 
        content_type: str, 
        db_schema: str,
        progress_callback: Optional[Callable[[str, float], None]] = None
    ) -> List[Dict[str, Any]]:
        """PDF íŒŒì¼ì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì—¬ Geminië¡œ ì²˜ë¦¬ (í†µí•© PDF ì²˜ë¦¬ ì‚¬ìš©)"""
        all_questions = []
        
        try:
            if progress_callback:
                progress_callback("ğŸ“– PDF â†’ ì´ë¯¸ì§€ ë³€í™˜ ì¤‘...", 20.0)
            
            # í†µí•©ëœ PDF â†’ ì´ë¯¸ì§€ ë³€í™˜ ì‚¬ìš©
            logger.info("PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ ì¤‘...")
            page_images_base64 = self._convert_pdf_to_images_unified(file_path, max_pages=20)
            
            if not page_images_base64:
                # ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨ì‹œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
                logger.warning("ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨, í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„...")
                text_content = self._extract_pdf_text_fallback(file_path)
                if text_content:
                    return self._process_text_chunks(text_content, content_type, db_schema, progress_callback)
                else:
                    raise Exception("PDF ì²˜ë¦¬ ì‹¤íŒ¨: ì´ë¯¸ì§€ ë³€í™˜ê³¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ ëª¨ë‘ ì‹¤íŒ¨")
            
            logger.info(f"ì´ {len(page_images_base64)}ê°œ í˜ì´ì§€ ì´ë¯¸ì§€ ìƒì„±ë¨")
            
            if progress_callback:
                progress_callback(f"ğŸ“„ {len(page_images_base64)}ê°œ í˜ì´ì§€ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ", 40.0)
            
            # íŒŒì¼ íƒ€ì…ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
            if content_type == "answers":
                # ë‹µì•ˆì§€ ì „ìš© ê°•í™” í”„ë¡¬í”„íŠ¸
                gemini_prompt = f"""
ì´ ì´ë¯¸ì§€ëŠ” ì‹œí—˜ ì •ë‹µì§€/ë‹µì•ˆì§€ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ì—ì„œ ë¬¸ì œ ë²ˆí˜¸ì™€ ì •ë‹µì„ ì°¾ì•„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

**ì¤‘ìš”: ì´ë¯¸ì§€ì— ìˆëŠ” ëª¨ë“  ìˆ«ìì™€ ì„ íƒì§€ ê¸°í˜¸ë¥¼ ê¼¼ê¼¼íˆ ì‚´í´ë³´ì„¸ìš”!**

**ì°¾ì•„ì•¼ í•  íŒ¨í„´ë“¤:**
1. "1ë²ˆ â‘¡", "2ë²ˆ â‘ ", "3ë²ˆ â‘£" 
2. "1. â‘¡", "2. â‘ ", "3. â‘£"
3. "ë¬¸ì œ1 ì •ë‹µâ‘¡", "ë¬¸ì œ2 ì •ë‹µâ‘ "
4. "1ë²ˆë¬¸ì œ: â‘¡", "2ë²ˆë¬¸ì œ: â‘ "
5. "1-â‘¡", "2-â‘ ", "3-â‘£"
6. í‘œ í˜•íƒœ: | 1 | â‘¡ | ë˜ëŠ” | ë¬¸ì œ1 | ì •ë‹µâ‘¡ |
7. "ì •ë‹µ: 1â‘¡, 2â‘ , 3â‘£..."
8. ì„¸ë¡œë¡œ ë‚˜ì—´ëœ í˜•íƒœë„ ì°¾ì•„ë³´ì„¸ìš”

**ì„ íƒì§€ ë³€í™˜ ê·œì¹™:**
- â‘  â†’ "1"
- â‘¡ â†’ "2" 
- â‘¢ â†’ "3"
- â‘£ â†’ "4"
- â‘¤ â†’ "5"
- 1ë²ˆ â†’ "1"
- 2ë²ˆ â†’ "2"
- A â†’ "1", B â†’ "2", C â†’ "3", D â†’ "4", E â†’ "5"

**ì¶œë ¥ í˜•ì‹ (JSON ë°°ì—´ë§Œ):**
[
  {{"question_number": 1, "correct_answer": "2", "year": 2021}},
  {{"question_number": 2, "correct_answer": "1", "year": 2021}},
  {{"question_number": 3, "correct_answer": "4", "year": 2021}}
]

**ì£¼ì˜ì‚¬í•­:**
- ì´ë¯¸ì§€ì—ì„œ ë³´ì´ëŠ” ëª¨ë“  ë¬¸ì œ-ì •ë‹µ ìŒì„ ì°¾ìœ¼ì„¸ìš”
- 22ë²ˆê¹Œì§€ë§Œ ì¶”ì¶œí•˜ì„¸ìš”
- ë¬¸ì œë²ˆí˜¸ê°€ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ ìˆœì„œëŒ€ë¡œ 1,2,3... ë°°ì •í•˜ì„¸ìš”
- ì •ë‹µì´ ë³´ì´ì§€ ì•ŠëŠ” ë¬¸ì œëŠ” ì œì™¸í•˜ì„¸ìš”
- ë°˜ë“œì‹œ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”

ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ë³´ê³  ì •ë‹µì§€ì˜ ëª¨ë“  ì •ë³´ë¥¼ ë†“ì¹˜ì§€ ë§ˆì„¸ìš”!
"""
            else:
                # ë¬¸ì œì§€ ì „ìš© í”„ë¡¬í”„íŠ¸
                gemini_prompt = f"""
ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì‹œí—˜ ë¬¸ì œë¥¼ ì°¾ì•„ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

{db_schema}

ìœ„ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ê° ë¬¸ì œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:
- question_number: ë¬¸ì œ ë²ˆí˜¸ (1~22ë§Œ)
- content: ë¬¸ì œ ë‚´ìš©
- description: ë¬¸ì œ ì„¤ëª…/ì§€ë¬¸ì´ ìˆë‹¤ë©´ ë°°ì—´ë¡œ
- options: ì„ íƒì§€ (â‘ â‘¡â‘¢â‘£â‘¤ â†’ "1","2","3","4","5")
- year: ì—°ë„ (ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œ ê°€ëŠ¥í•˜ë©´)

JSON ë°°ì—´ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. 22ë²ˆ ë¬¸ì œê¹Œì§€ë§Œ ì²˜ë¦¬í•˜ì„¸ìš”.
"""
            
            # ğŸ’€ CRITICAL: ëª¨ë“  í˜ì´ì§€ì—ì„œ ë¬¸ì œ ì¶”ì¶œ (22ê°œê¹Œì§€)
            question_numbers_found = set()
            total_pages = len(page_images_base64)
            
            for page_num, page_image_base64 in enumerate(page_images_base64, 1):
                # base64ë¥¼ Geminiìš© ì´ë¯¸ì§€ ê°ì²´ë¡œ ë³€í™˜
                import io
                import base64
                from PIL import Image
                
                try:
                    image_data = base64.b64decode(page_image_base64)
                    page_image = Image.open(io.BytesIO(image_data))
                except Exception as e:
                    logger.error(f"í˜ì´ì§€ {page_num} ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨: {e}")
                    continue
                page_progress = 40.0 + (page_num / total_pages) * 50.0
                if progress_callback:
                    progress_callback(f"ğŸ“– í˜ì´ì§€ {page_num}/{total_pages} ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...", page_progress)
                
                logger.info(f"ğŸ“– í˜ì´ì§€ {page_num}/{total_pages} ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...")
                
                try:
                    # Gemini ë¶„ì„
                    response = self.model.generate_content([gemini_prompt, page_image])
                    
                    if response and response.text:
                        try:
                            # ğŸ” ë‹µì•ˆì§€ì¸ ê²½ìš° ìƒì„¸ ë””ë²„ê¹…
                            if content_type == "answers":
                                logger.info(f"ğŸ” í˜ì´ì§€ {page_num} Gemini ì›ë³¸ ì‘ë‹µ: {response.text[:500]}...")
                            
                            # ì‘ë‹µ íŒŒì‹±
                            page_result = self._parse_gemini_response(response.text, content_type)
                            page_questions = page_result.get("data", [])
                            
                            # ğŸ” ë‹µì•ˆì§€ì¸ ê²½ìš° íŒŒì‹± ê²°ê³¼ ë¡œê¹…
                            if content_type == "answers":
                                logger.info(f"ğŸ” í˜ì´ì§€ {page_num} íŒŒì‹± ê²°ê³¼: {len(page_questions)}ê°œ í•­ëª©")
                                for i, q in enumerate(page_questions[:3]):  # ì²˜ìŒ 3ê°œë§Œ ë¡œê¹…
                                    logger.info(f"    í•­ëª© {i+1}: {q}")
                            
                            # ìœ íš¨í•œ ë°ì´í„° í•„í„°ë§ (ë‹µì•ˆì§€ëŠ” ë‹¤ë¥¸ ê²€ì¦ ê¸°ì¤€)
                            valid_page_data = []
                            
                            if content_type == "answers":
                                # ë‹µì•ˆì§€: question_numberì™€ correct_answerë§Œ ìˆìœ¼ë©´ ìœ íš¨
                                for q in page_questions:
                                    q_num = q.get('question_number', 0)
                                    answer = q.get('correct_answer', '')
                                    
                                    if (1 <= q_num <= 22 and 
                                        answer and answer.strip() and answer in ["1", "2", "3", "4", "5"] and
                                        q_num not in question_numbers_found):
                                        
                                        valid_page_data.append(q)
                                        question_numbers_found.add(q_num)
                                        logger.info(f"âœ… ì •ë‹µ {q_num}: {answer}")
                            else:
                                # ë¬¸ì œì§€: ê¸°ì¡´ ê²€ì¦ ë°©ì‹
                                for q in page_questions:
                                    q_num = q.get('question_number', 0)
                                    content = q.get('content', '')
                                    
                                    if (1 <= q_num <= 22 and 
                                        content and content.strip() and content != "null" and
                                        q_num not in question_numbers_found):
                                        
                                        valid_page_data.append(q)
                                        question_numbers_found.add(q_num)
                                        logger.info(f"âœ… ë¬¸ì œ {q_num} ì¶”ì¶œ ì„±ê³µ")
                            
                            if valid_page_data:
                                all_questions.extend(valid_page_data)
                                logger.info(f"ğŸ“„ í˜ì´ì§€ {page_num}: {len(valid_page_data)}ê°œ ì‹ ê·œ ë°ì´í„° ì¶”ê°€ (ì´ {len(all_questions)}ê°œ)")
                            else:
                                logger.warning(f"âš ï¸ í˜ì´ì§€ {page_num}: ìœ íš¨í•œ ë°ì´í„° ì—†ìŒ")
                                if content_type == "answers" and page_questions:
                                    logger.warning(f"    ì›ë³¸ ë°ì´í„°: {page_questions}")
                                
                        except Exception as e:
                            logger.error(f"âŒ í˜ì´ì§€ {page_num} íŒŒì‹± ì‹¤íŒ¨: {e}")
                            if content_type == "answers":
                                logger.error(f"    ì›ë³¸ ì‘ë‹µ: {response.text[:300]}...")
                            continue
                    else:
                        logger.warning(f"âš ï¸ í˜ì´ì§€ {page_num}: Gemini ì‘ë‹µ ì—†ìŒ")
                    
                    # 22ê°œ ë‹¬ì„± í™•ì¸
                    if len(question_numbers_found) >= 22:
                        logger.info(f"ğŸ¯ 22ë¬¸ì œ ë‹¬ì„±! ë” ì´ìƒ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ")
                        if progress_callback:
                            progress_callback("ğŸ¯ 22ë¬¸ì œ ë‹¬ì„±! íŒŒì‹± ì™„ë£Œ", 90.0)
                        break
                    
                except Exception as e:
                    logger.error(f"âŒ í˜ì´ì§€ {page_num} ì „ì²´ ì‹¤íŒ¨: {e}")
                    continue
            
            # ìµœì¢… 22ê°œ ì œí•œ ì ìš©
            all_questions = all_questions[:22]
            
            if progress_callback:
                progress_callback(f"ğŸ“– PDF ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ: {len(all_questions)}ê°œ ë¬¸ì œ", 90.0)
            
            logger.info(f"PDF ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ: ì´ {len(all_questions)}ê°œ ë¬¸ì œ")
            return all_questions
            
        except Exception as e:
            logger.error(f"PDF ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            if progress_callback:
                progress_callback(f"âŒ PDF ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}", 0.0)
            raise

    def _process_text_file_chunked(self, file_path: str, content_type: str, db_schema: str, progress_callback: Optional[Callable[[str, float], None]] = None) -> List[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ íŒŒì¼ ë¶„í•  ì²˜ë¦¬"""
        encodings = ['utf-8', 'cp949', 'euc-kr', 'latin-1']
        
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    content = f.read()
                break
            except UnicodeDecodeError:
                continue
        else:
            raise UnicodeDecodeError(f"íŒŒì¼ ì¸ì½”ë”©ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        
        return self._process_text_chunks(content, content_type, db_schema, progress_callback)

    def _process_text_chunks(self, content: str, content_type: str, db_schema: str, progress_callback: Optional[Callable[[str, float], None]] = None) -> List[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì²­í¬ë¡œ ë¶„í•  ì²˜ë¦¬"""
        all_data = []
        chunk_size = 15000  # ë¬¸ì ë‹¨ìœ„ ì²­í¬ í¬ê¸°
        
        # í…ìŠ¤íŠ¸ê°€ ì‘ì€ ê²½ìš° í•œë²ˆì— ì²˜ë¦¬
        if len(content) <= chunk_size:
            try:
                prompt = self._generate_prompt("text_content", content_type, db_schema)
                response = self.model.generate_content([prompt, f"í…ìŠ¤íŠ¸ ë‚´ìš©:\n{content}"])
                result = self._parse_gemini_response(response.text, content_type).get("data", [])
                # 22ë²ˆ ì œí•œ ì ìš©
                result = [item for item in result if item.get('question_number', 0) <= 22][:22]
                return result
            except Exception as e:
                logger.error(f"í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                return []
        
        # í° í…ìŠ¤íŠ¸ëŠ” ì²­í¬ë¡œ ë¶„í• 
        for i in range(0, len(content), chunk_size):
            chunk = content[i:i + chunk_size]
            
            try:
                prompt = self._generate_prompt("text_content", content_type, db_schema)
                response = self.model.generate_content([prompt, f"í…ìŠ¤íŠ¸ ì²­í¬:\n{chunk}"])
                chunk_data = self._parse_gemini_response(response.text, content_type).get("data", [])
                
                # 22ë²ˆ ì œí•œ ì ìš©
                chunk_data = self._apply_question_limit(chunk_data)
                
                all_data.extend(chunk_data)
                logger.info(f"í…ìŠ¤íŠ¸ ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ: {len(chunk_data)}ê°œ ë°ì´í„°")
                
                # 22ê°œ ë‹¬ì„±í•˜ë©´ ì¤‘ë‹¨
                if len(all_data) >= self.MAX_QUESTIONS:
                    all_data = self._apply_question_limit(all_data)
                    break
                    
            except Exception as e:
                logger.warning(f"í…ìŠ¤íŠ¸ ì²­í¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        return all_data

    # ì¤‘ë³µëœ JSON ì •ë¦¬ ë©”ì†Œë“œë“¤ì€ í†µí•© static ë©”ì†Œë“œë¡œ ëŒ€ì²´ë¨
    # _clean_json_text_unified ë° _aggressive_json_clean_unified ì‚¬ìš©
    
    def _parse_gemini_response(self, response_text: str, content_type: str) -> Dict[str, Any]:
        """Gemini ì‘ë‹µ íŒŒì‹± (í†µí•© ìœ í‹¸ë¦¬í‹° ì‚¬ìš©)"""
        
        try:
            # í†µí•© AI JSON íŒŒì„œ ì‚¬ìš©
            result = self.parse_ai_json_response(
                response_text,
                fallback_data={"error": "íŒŒì‹± ì‹¤íŒ¨", "data": [], "type": content_type}
            )
            
            # ì—ëŸ¬ ì‘ë‹µ í™•ì¸
            if "error" in result:
                logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {result['error']}")
                return {"type": content_type, "data": []}
            
            # ìë™ ê°ì§€ ëª¨ë“œì¸ ê²½ìš°
            if content_type == "auto" and isinstance(result, dict) and "type" in result:
                data = result.get("data", [])
                # 22ë²ˆ ì œí•œ ì ìš©
                data = self._apply_question_limit(data)
                return {
                    "type": result["type"],
                    "data": data
                }
            else:
                # ì§€ì •ëœ íƒ€ì…ì¸ ê²½ìš° - ë°ì´í„° ì •ê·œí™”
                if isinstance(result, list):
                    data = result
                elif isinstance(result, dict):
                    data = result.get("data", [result] if result else [])
                else:
                    data = []
                
                # 22ë²ˆ ì œí•œ ì ìš©
                data = self._apply_question_limit(data)
                return {
                    "type": content_type,
                    "data": data
                }
                
        except Exception as e:
            logger.error(f"âŒ Gemini ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜ˆì™¸: {e}")
            return {"type": content_type, "data": []}
    
    def match_questions_with_answers(
        self, 
        questions: List[Dict[str, Any]], 
        answers: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        ë¬¸ì œì™€ ì •ë‹µ ë§¤ì¹­ (22ê°œ ì œí•œ)
        
        ì •ë‹µì´ ì—†ëŠ” ë¬¸ì œë„ í¬í•¨ì‹œí‚¤ë˜ correct_answerë¥¼ ë¹ˆ ê°’ìœ¼ë¡œ ì„¤ì •
        22ë²ˆ ë¬¸ì œê¹Œì§€ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        """
        # ì…ë ¥ ë°ì´í„°ì— 22ê°œ ì œí•œ ì ìš©
        questions = [q for q in questions if q.get('question_number', 0) <= self.MAX_QUESTIONS][:self.MAX_QUESTIONS]
        answers = [a for a in answers if a.get('question_number', 0) <= self.MAX_QUESTIONS]

        # ì •ë‹µì„ ë¬¸ì œë²ˆí˜¸ë¡œ ì¸ë±ì‹±
        answer_map = {}
        for ans in answers:
            q_num = ans.get("question_number")
            if q_num is not None and q_num <= self.MAX_QUESTIONS:  # 22ë²ˆê¹Œì§€ë§Œ
                answer_map[str(q_num)] = ans

        matched_data = []
        matched_count = 0

        # ì •ë‹µì´ ìˆëŠ” ë¬¸ì œë²ˆí˜¸ ë²”ìœ„ í™•ì¸
        if answer_map:
            available_answer_numbers = set(answer_map.keys())
            logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì •ë‹µ: {len(available_answer_numbers)}ê°œ ë¬¸ì œ ({min(available_answer_numbers) if available_answer_numbers else 'N/A'} ~ {max(available_answer_numbers) if available_answer_numbers else 'N/A'}ë²ˆ)")
        else:
            logger.warning("ì •ë‹µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ë¬¸ì œë¥¼ ì •ë‹µ ì—†ì´ í¬í•¨í•©ë‹ˆë‹¤.")
            available_answer_numbers = set()

        for question in questions:
            q_num = question.get("question_number")
            if q_num is None:
                logger.warning(f"ë¬¸ì œë²ˆí˜¸ê°€ ì—†ëŠ” ë¬¸ì œ ê±´ë„ˆë›°ê¸°: {question.get('content', '')[:50]}...")
                continue

            q_num_str = str(q_num)

            # ê¸°ë³¸ ë¬¸ì œ ë°ì´í„° ì„¤ì •
            matched_item = {
                **question,
                "correct_answer": "",
                "answer_source": "no_answer"
            }

            # ì •ë‹µì´ ìˆëŠ” ê²½ìš° ë³‘í•©
            if q_num_str in answer_map:
                answer_data = answer_map[q_num_str]
                matched_item.update({
                    "correct_answer": answer_data.get("correct_answer") or answer_data.get("answer", ""),
                    "subject": answer_data.get("subject", question.get("subject", "")),
                    "area_name": answer_data.get("area_name", question.get("area_name", "")),
                    "difficulty": answer_data.get("difficulty", question.get("difficulty", "ì¤‘")),
                    "year": answer_data.get("year", question.get("year")),
                    "answer_source": "matched"
                })
                matched_count += 1
                logger.debug(f"âœ… ë¬¸ì œ {q_num}: ì •ë‹µ ë§¤ì¹­ ì™„ë£Œ")
            else:
                logger.debug(f"âš ï¸ ë¬¸ì œ {q_num}: ì •ë‹µ ì—†ìŒ, ë¹ˆ ê°’ìœ¼ë¡œ ì„¤ì •")

            # ê¸°ë³¸ í•„ìˆ˜ í•„ë“œ ê²€ì¦ (contentë§Œ í™•ì¸)
            if matched_item.get("content") and matched_item.get("content").strip():
                matched_data.append(matched_item)
            else:
                logger.warning(f"ë¬¸ì œ {q_num}: contentê°€ ì—†ì–´ ì œì™¸")

        # 22ê°œ ì œí•œ ì¬ì ìš©
        matched_data = matched_data[:self.MAX_QUESTIONS]

        # ë§¤ì¹­ ê²°ê³¼ ë¡œê¹…
        total_questions = len(questions)
        final_count = len(matched_data)

        logger.info(f"ğŸ“Š ë§¤ì¹­ ì™„ë£Œ:")
        logger.info(f"  - ì „ì²´ ë¬¸ì œ: {total_questions}ê°œ")
        logger.info(f"  - ìµœì¢… í¬í•¨: {final_count}ê°œ")
        logger.info(f"  - ì •ë‹µ ë§¤ì¹­: {matched_count}ê°œ")
        logger.info(f"  - ì •ë‹µ ì—†ìŒ: {final_count - matched_count}ê°œ")

        return matched_data
    
    def _is_complete_question_data(self, question_data: Dict[str, Any]) -> bool:
        """
        ë¬¸ì œ ë°ì´í„°ê°€ ì™„ì „í•œì§€ ê²€ì¦
        
        Args:
            question_data: ê²€ì¦í•  ë¬¸ì œ ë°ì´í„°
            
        Returns:
            bool: ì™„ì „í•œ ë°ì´í„° ì—¬ë¶€
        """
        required_fields = ["question_number", "content", "correct_answer"]
        
        for field in required_fields:
            value = question_data.get(field)
            if value is None or (isinstance(value, str) and not value.strip()):
                return False
        
        # ì„ íƒì§€ê°€ ìˆëŠ” ê²½ìš° ê²€ì¦
        options = question_data.get("options", {})
        if options and len(options) < 2:
            return False
        
        return True
    
    def convert_to_db_format(self, matched_data: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """
        ë§¤ì¹­ëœ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        """
        questions = []
        answer_options = []
        correct_answers = []
        
        current_time = datetime.now(timezone.utc).isoformat()
        
        for idx, item in enumerate(matched_data, 1):
            question_id = idx
            
            # Question ë ˆì½”ë“œ
            question_record = {
                "id": question_id,
                "content": item.get("content", ""),
                "description": item.get("description", None),
                "difficulty": item.get("difficulty", "ì¤‘"),
                "subject": item.get("subject", ""),
                "area_name": item.get("area_name", ""),
                "is_active": True,
                "question_metadata": {
                    "question_number": item.get("question_number"),
                    "year": item.get("year"),
                    "answer_source": item.get("answer_source", ""),
                },
                "created_at": current_time,
                "updated_at": current_time
            }
            
            # ê°„ë‹¨ ë²„ì „ í•„ë“œ ì¶”ê°€
            options = item.get("options", {})
            if options:
                question_record["choices"] = list(options.values())
                question_record["correct_answer"] = item.get("correct_answer", "")
            
            questions.append(question_record)
            
            # AnswerOption ë ˆì½”ë“œë“¤
            for option_label, option_text in options.items():
                option_record = {
                    "question_id": question_id,
                    "option_text": option_text,
                    "option_label": option_label,
                    "display_order": int(option_label) if option_label.isdigit() else 0,
                    "created_at": current_time,
                    "updated_at": current_time
                }
                answer_options.append(option_record)
            
            # CorrectAnswer ë ˆì½”ë“œ
            correct_answer = item.get("correct_answer")
            if correct_answer:
                correct_answer_record = {
                    "question_id": question_id,
                    "answer_text": correct_answer,
                    "created_at": current_time,
                    "updated_at": current_time
                }
                correct_answers.append(correct_answer_record)
        
        logger.info(f"DB í˜•ì‹ ë³€í™˜ ì™„ë£Œ: Questions({len(questions)}), Options({len(answer_options)}), Answers({len(correct_answers)})")
        
        return {
            "questions": questions,
            "answer_options": answer_options,
            "correct_answers": correct_answers
        }

    # ============= í†µí•© AI ì‘ë‹µ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°ë“¤ =============
    
    @staticmethod
    def parse_ai_json_response(response_text: str, fallback_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        AI ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ ë° íŒŒì‹± (ëª¨ë“  AI ì„œë¹„ìŠ¤ì—ì„œ ê³µí†µ ì‚¬ìš©)
        
        Args:
            response_text: AI ì‘ë‹µ í…ìŠ¤íŠ¸
            fallback_data: íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’
            
        Returns:
            íŒŒì‹±ëœ JSON ë°ì´í„°
        """
        try:
            # 1ë‹¨ê³„: JSON ë¸”ë¡ ì¶”ì¶œ ì‹œë„
            import re
            
            # ```json ... ``` ë¸”ë¡ ì°¾ê¸°
            json_block_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
            if json_block_match:
                json_str = json_block_match.group(1).strip()
            else:
                # { ... } íŒ¨í„´ ì°¾ê¸°
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    json_str = json_match.group().strip()
                else:
                    # [ ... ] ë°°ì—´ íŒ¨í„´ ì°¾ê¸°
                    array_match = re.search(r'\[.*\]', response_text, re.DOTALL)
                    if array_match:
                        json_str = array_match.group().strip()
                    else:
                        json_str = response_text.strip()
            
            # 2ë‹¨ê³„: JSON íŒŒì‹± ì‹œë„
            cleaned_json = QuestionParser._clean_json_text_unified(json_str)
            result = json.loads(cleaned_json)
            
            logger.debug(f"âœ… AI JSON íŒŒì‹± ì„±ê³µ: {len(str(result))} ë¬¸ì")
            return result
            
        except json.JSONDecodeError as e:
            logger.warning(f"âš ï¸ AI JSON íŒŒì‹± ì‹¤íŒ¨, ì ê·¹ì  ì •ë¦¬ ì‹œë„: {e}")
            
            try:
                # 3ë‹¨ê³„: ì ê·¹ì  JSON ì •ë¦¬
                aggressive_cleaned = QuestionParser._aggressive_json_clean_unified(response_text)
                result = json.loads(aggressive_cleaned)
                
                logger.info("âœ… ì ê·¹ì  JSON ì •ë¦¬ë¡œ íŒŒì‹± ì„±ê³µ")
                return result
                
            except json.JSONDecodeError as e2:
                logger.error(f"âŒ ëª¨ë“  JSON íŒŒì‹± ì‹œë„ ì‹¤íŒ¨: {e2}")
                
                # 4ë‹¨ê³„: í´ë°± ë°ì´í„° ë°˜í™˜
                if fallback_data:
                    logger.info("ğŸ“‹ í´ë°± ë°ì´í„° ì‚¬ìš©")
                    return fallback_data
                else:
                    logger.info("ğŸ“‹ ê¸°ë³¸ ì—ëŸ¬ êµ¬ì¡° ë°˜í™˜")
                    return {
                        "error": "JSON íŒŒì‹± ì‹¤íŒ¨",
                        "raw_response": response_text[:200] + "..." if len(response_text) > 200 else response_text,
                        "parse_attempted": True
                    }
        
        except Exception as e:
            logger.error(f"âŒ AI ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            return fallback_data or {"error": str(e), "parse_attempted": True}
    
    @staticmethod
    def _clean_json_text_unified(text: str) -> str:
        """í†µí•© JSON í…ìŠ¤íŠ¸ ì •ë¦¬ (ëª¨ë“  ì„œë¹„ìŠ¤ ê³µí†µ ì‚¬ìš©)"""
        lines = text.split('\n')
        cleaned_lines = []
        
        for line in lines:
            # // ì£¼ì„ ì œê±°
            if '//' in line:
                # JSON ë¬¸ìì—´ ë‚´ë¶€ì˜ //ëŠ” ë³´ì¡´
                in_string = False
                escaped = False
                cleaned_line = ""
                
                for i, char in enumerate(line):
                    if escaped:
                        cleaned_line += char
                        escaped = False
                        continue
                    
                    if char == '\\':
                        escaped = True
                        cleaned_line += char
                        continue
                    
                    if char == '"' and not escaped:
                        in_string = not in_string
                        cleaned_line += char
                        continue
                    
                    if not in_string and char == '/' and i + 1 < len(line) and line[i + 1] == '/':
                        # ì£¼ì„ ì‹œì‘, ë‚˜ë¨¸ì§€ ì¤„ ë¬´ì‹œ
                        break
                    
                    cleaned_line += char
                
                line = cleaned_line
            
            # /* */ ì£¼ì„ ì œê±° (ë‹¨ìˆœ ë²„ì „)
            while '/*' in line and '*/' in line:
                start = line.find('/*')
                end = line.find('*/', start) + 2
                line = line[:start] + line[end:]
            
            # ë¹ˆ ì¤„ì´ ì•„ë‹ˆë©´ ì¶”ê°€
            if line.strip():
                cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines)
    
    @staticmethod
    def _aggressive_json_clean_unified(text: str) -> str:
        """ì ê·¹ì  JSON ì •ë¦¬ (ëª¨ë“  ì„œë¹„ìŠ¤ ê³µí†µ ì‚¬ìš©)"""
        import re
        
        # ë§ˆì§€ë§‰ } ë˜ëŠ” ] ì´í›„ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ ì œê±°
        text = text.strip()
        
        # JSON ë°°ì—´ì¸ì§€ ê°ì²´ì¸ì§€ í™•ì¸
        if text.startswith('['):
            # ë§ˆì§€ë§‰ ]ì˜ ìœ„ì¹˜ ì°¾ê¸°
            last_bracket = text.rfind(']')
            if last_bracket != -1:
                text = text[:last_bracket + 1]
        elif text.startswith('{'):
            # ë§ˆì§€ë§‰ }ì˜ ìœ„ì¹˜ ì°¾ê¸°
            last_brace = text.rfind('}')
            if last_brace != -1:
                text = text[:last_brace + 1]
        
        # ë¶ˆì™„ì „í•œ JSON í‚¤-ê°’ ìˆ˜ì •
        text = re.sub(r',\s*}', '}', text)  # ë§ˆì§€ë§‰ ì½¤ë§ˆ ì œê±°
        text = re.sub(r',\s*]', ']', text)  # ë°°ì—´ ë§ˆì§€ë§‰ ì½¤ë§ˆ ì œê±°
        text = re.sub(r'([^"])\s*:\s*([^"\[\{].*?)([,\}\]])', r'\1: "\3"\3', text)  # ê°’ ë”°ì˜´í‘œ ì¶”ê°€
        
        return text
    
    @staticmethod 
    def extract_ai_content_patterns(response_text: str, patterns: Dict[str, str]) -> Dict[str, str]:
        """
        AI ì‘ë‹µì—ì„œ íŠ¹ì • íŒ¨í„´ ì¶”ì¶œ (ëª¨ë“  AI ì„œë¹„ìŠ¤ ê³µí†µ)
        
        Args:
            response_text: AI ì‘ë‹µ í…ìŠ¤íŠ¸
            patterns: {"key": "regex_pattern"} í˜•íƒœì˜ ì¶”ì¶œ íŒ¨í„´ë“¤
            
        Returns:
            ì¶”ì¶œëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        import re
        
        extracted = {}
        
        for key, pattern in patterns.items():
            try:
                match = re.search(pattern, response_text, re.IGNORECASE | re.DOTALL)
                if match:
                    if match.groups():
                        extracted[key] = match.group(1).strip()
                    else:
                        extracted[key] = match.group(0).strip()
                else:
                    extracted[key] = ""
                    
            except Exception as e:
                logger.warning(f"íŒ¨í„´ ì¶”ì¶œ ì‹¤íŒ¨ ({key}): {e}")
                extracted[key] = ""
        
        return extracted
    
    @staticmethod
    def validate_ai_analysis_result(
        analysis_result: Dict[str, Any], 
        required_fields: List[str],
        default_values: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        AI ë¶„ì„ ê²°ê³¼ ê²€ì¦ ë° ë³´ì™„ (ëª¨ë“  AI ë¶„ì„ ì„œë¹„ìŠ¤ ê³µí†µ)
        
        Args:
            analysis_result: AI ë¶„ì„ ê²°ê³¼
            required_fields: í•„ìˆ˜ í•„ë“œ ëª©ë¡
            default_values: ê¸°ë³¸ê°’ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            ê²€ì¦ëœ ë¶„ì„ ê²°ê³¼
        """
        validated = analysis_result.copy() if analysis_result else {}
        defaults = default_values or {}
        
        # í•„ìˆ˜ í•„ë“œ í™•ì¸ ë° ê¸°ë³¸ê°’ ì„¤ì •
        for field in required_fields:
            if field not in validated or not validated[field]:
                if field in defaults:
                    validated[field] = defaults[field]
                    logger.debug(f"ğŸ“‹ ê¸°ë³¸ê°’ ì ìš©: {field} = {defaults[field]}")
                else:
                    validated[field] = None
                    logger.warning(f"âš ï¸ í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
        
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        validated["validation_timestamp"] = datetime.now().isoformat()
        validated["validation_applied"] = True
        
        return validated

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
question_parser = QuestionParser()