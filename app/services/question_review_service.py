"""
ë¬¸ì œ ê²€í†  ë° ìŠ¹ì¸ ì„œë¹„ìŠ¤
"""
import json
import os
from typing import List, Dict, Any, Optional
from datetime import datetime
from pathlib import Path

from sqlalchemy.orm import Session
from sqlalchemy import and_, desc

from ..models.question import Question, DifficultyLevel
from ..models.user import User
from ..schemas.question_review import (
    ParsedFilePreview, QuestionPreviewItem, QuestionUpdateRequest,
    BulkApprovalRequest, QuestionApprovalResponse, ApprovalStatus
)
from ..core.config import settings
import logging

# AI ë‚œì´ë„ ë¶„ì„ê¸° ì„í¬íŠ¸
try:
    from .ai_difficulty_analyzer import difficulty_analyzer
    AI_ANALYZER_AVAILABLE = True
except ImportError:
    AI_ANALYZER_AVAILABLE = False
    logger.warning("âŒ AI ë‚œì´ë„ ë¶„ì„ê¸°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

logger = logging.getLogger(__name__)

class QuestionReviewService:
    """ë¬¸ì œ ê²€í†  ë° ìŠ¹ì¸ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.save_parser_dir = Path("data/save_parser")
        self.save_parser_dir.mkdir(parents=True, exist_ok=True)
    
    def save_parsed_data_to_json(
        self,
        parsed_data: List[Dict[str, Any]],
        source_file_name: str,
        user_id: int
    ) -> str:
        """
        íŒŒì‹±ëœ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        
        Returns:
            str: ì €ì¥ëœ JSON íŒŒì¼ ê²½ë¡œ
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_filename = f"{timestamp}_{user_id}_{source_file_name}"
        json_filename = f"{Path(safe_filename).stem}.json"
        json_path = self.save_parser_dir / json_filename
        
        # JSON ë°ì´í„° ì¤€ë¹„
        save_data = {
            "meta": {
                "source_file": source_file_name,
                "parsed_at": datetime.now().isoformat(),
                "parsed_by": user_id,
                "total_questions": len(parsed_data)
            },
            "questions": parsed_data
        }
        
        # JSON íŒŒì¼ ì €ì¥
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"íŒŒì‹±ëœ ë°ì´í„° JSON ì €ì¥ ì™„ë£Œ: {json_path}")
        return str(json_path)
    
    def create_pending_questions(
        self,
        db: Session,
        parsed_data: List[Dict[str, Any]],
        source_file_path: str,
        parsed_data_path: str,
        user_id: int,
        file_title: str = None,
        file_category: str = None
    ) -> List[Question]:
        """
        íŒŒì‹±ëœ ë°ì´í„°ë¥¼ ëŒ€ê¸° ìƒíƒœ ë¬¸ì œë¡œ ìƒì„±
        """
        questions = []
        
        # 22ë¬¸ì œ ì œí•œ ì ìš©
        limited_data = parsed_data[:22] if len(parsed_data) > 22 else parsed_data
        
        # ë¬¸ì œ ë²ˆí˜¸ ìˆœì„œë¡œ ì •ë ¬
        limited_data.sort(key=lambda x: x.get("question_number", 0))
        
        for item in limited_data:
            logger.info(f"ë¬¸ì œ {item.get('question_number')} ìƒì„± ì‹œë„ ì¤‘...")
            
            # ê¸°ë³¸ í•„ë“œ ì¶”ì¶œ
            question_type = item.get("file_type", "objective")
            if question_type == "questions":
                question_type = "objective"
            
            content = item.get("content", "")
            difficulty = item.get("difficulty", "ì¤‘")
            
            # AI ë¶„ì„ ì‹¤í–‰
            ai_analysis = None
            if AI_ANALYZER_AVAILABLE and content:
                try:
                    # ì‚¬ìš©ì ë¶€ì„œ ì •ë³´ë¡œ í•™ê³¼ íŒë‹¨ (ì„ì‹œë¡œ ë¬¼ë¦¬ì¹˜ë£Œë¡œ ì„¤ì •)
                    department = "ë¬¼ë¦¬ì¹˜ë£Œ"  # TODO: ì‚¬ìš©ì ë¶€ì„œì—ì„œ ê°€ì ¸ì˜¤ê¸°
                    question_number = item.get("question_number", 1)
                    
                    ai_analysis = difficulty_analyzer.analyze_question_auto(
                        content, question_number, department
                    )
                    
                    # AI ë¶„ì„ ê²°ê³¼ë¡œ ë‚œì´ë„ ì—…ë°ì´íŠ¸
                    if ai_analysis:
                        difficulty = ai_analysis.get("difficulty", difficulty)
                        # ë¬¸ì œ ìœ í˜•ë„ AI ë¶„ì„ ê²°ê³¼ ë°˜ì˜
                        ai_question_type = ai_analysis.get("question_type", "")
                        
                        # JSON íŒŒì¼ì— AI ë¶„ì„ ê²°ê³¼ ë°˜ì˜
                        item["difficulty"] = difficulty
                        item["ai_question_type"] = ai_question_type
                        item["ai_analysis_complete"] = True
                        item["ai_confidence"] = ai_analysis.get("confidence", "medium")
                        item["ai_reasoning"] = ai_analysis.get("ai_reasoning", "")
                        
                        logger.info(f"ğŸ¤– ë¬¸ì œ {question_number}: AI ë¶„ì„ ì™„ë£Œ (ë‚œì´ë„: {difficulty})")
                except Exception as e:
                    logger.warning(f"âš ï¸ AI ë¶„ì„ ì‹¤íŒ¨ (ë¬¸ì œ {item.get('question_number')}): {e}")

            # AI ë¶„ì„ ì •ë³´ë¥¼ ë©”íƒ€ë°ì´í„°ì— í¬í•¨
            ai_metadata = {}
            if ai_analysis:
                ai_metadata = {
                    "ai_analysis_complete": True,
                    "ai_confidence": ai_analysis.get("confidence", "medium"),
                    "ai_reasoning": ai_analysis.get("ai_reasoning", ""),
                    "position_based_difficulty": ai_analysis.get("position_based", "ì¤‘"),
                    "ai_suggested_difficulty": ai_analysis.get("ai_suggested", "ì¤‘"),
                    "analysis_timestamp": datetime.now().isoformat()
                }
            else:
                ai_metadata = {
                    "ai_analysis_complete": False,
                    "analysis_status": "ëŒ€ê¸° ì¤‘",
                    "fallback_mode": True
                }

            question = Question(
                question_number=item.get("question_number", 1),
                question_type=question_type,
                content=content,
                description=item.get("description"),
                options=item.get("options", {}),
                correct_answer=item.get("correct_answer", ""),
                subject=item.get("subject", ""),
                area_name=item.get("area_name", ""),
                difficulty=difficulty,
                year=item.get("year"),
                approval_status="pending",
                source_file_path=source_file_path,
                parsed_data_path=parsed_data_path,
                file_title=file_title,
                file_category=file_category,
                is_active=True,
                last_modified_by=user_id,  # êµìˆ˜ IDë¥¼ ìƒì„±ì ê²¸ ë§ˆì§€ë§‰ ìˆ˜ì •ìë¡œ ì„¤ì •
                last_modified_at=datetime.now(),
                metadata=ai_metadata  # AI ë¶„ì„ ì •ë³´ ì €ì¥
            )
            
            db.add(question)
            questions.append(question)
            logger.info(f"ë¬¸ì œ {item.get('question_number')} ì¶”ê°€ ì™„ë£Œ")
        
        # AI ë¶„ì„ ê²°ê³¼ë¡œ JSON íŒŒì¼ ì—…ë°ì´íŠ¸
        if parsed_data_path and os.path.exists(parsed_data_path):
            self.update_json_with_ai_results(parsed_data_path, limited_data)
        
        db.commit()
        logger.info(f"ëŒ€ê¸° ìƒíƒœ ë¬¸ì œ {len(questions)}ê°œ ìƒì„± ì™„ë£Œ")
        return questions

    def update_json_with_ai_results(self, json_path: str, updated_data: List[Dict[str, Any]]) -> bool:
        """
        AI ë¶„ì„ ê²°ê³¼ë¡œ JSON íŒŒì¼ ì—…ë°ì´íŠ¸
        """
        try:
            if not os.path.exists(json_path):
                return False
            
            with open(json_path, 'r', encoding='utf-8') as f:
                json_data = json.load(f)
            
            # ê¸°ì¡´ questions ë°°ì—´ì„ AI ë¶„ì„ ê²°ê³¼ë¡œ ì—…ë°ì´íŠ¸
            if "questions" in json_data:
                for i, question in enumerate(json_data["questions"]):
                    if i < len(updated_data):
                        # AI ë¶„ì„ ê²°ê³¼ í•„ë“œ ì—…ë°ì´íŠ¸
                        updated_question = updated_data[i]
                        question["difficulty"] = updated_question.get("difficulty", question.get("difficulty"))
                        question["ai_question_type"] = updated_question.get("ai_question_type", "ê°ê´€ì‹")
                        question["ai_analysis_complete"] = updated_question.get("ai_analysis_complete", False)
                        question["ai_confidence"] = updated_question.get("ai_confidence", "medium")
                        question["ai_reasoning"] = updated_question.get("ai_reasoning", "")
                        question["updated_at"] = datetime.now().isoformat()
            
            # ë©”íƒ€ ì •ë³´ ì—…ë°ì´íŠ¸
            if "meta" in json_data:
                json_data["meta"]["ai_analysis_completed"] = True
                json_data["meta"]["last_ai_update"] = datetime.now().isoformat()
            
            # íŒŒì¼ ì €ì¥
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(json_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… JSON íŒŒì¼ AI ë¶„ì„ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {json_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ JSON íŒŒì¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def get_pending_questions(
        self, 
        db: Session, 
        user_id: Optional[int] = None,
        limit: int = 50
    ) -> List[QuestionPreviewItem]:
        """
        ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì¸ ë¬¸ì œë“¤ ì¡°íšŒ (êµìˆ˜ ID ê¸°ë°˜ ì§€ì†ì„±)
        """
        query = db.query(Question).filter(
            Question.approval_status == "pending"
        )
        
        if user_id:
            # last_modified_byë¡œ êµìˆ˜ ë¬¸ì œ í•„í„°ë§ (ìƒì„±ì ì¶”ì )
            query = query.filter(Question.last_modified_by == user_id)
        
        questions = query.order_by(Question.question_number.asc(), desc(Question.created_at)).limit(limit).all()
        
        result = []
        for q in questions:
            # AI ë¶„ì„ ìƒíƒœ í™•ì¸ (ì•ˆì „í•œ ì ‘ê·¼)
            ai_metadata = {}
            if hasattr(q, 'metadata') and q.metadata:
                if isinstance(q.metadata, dict):
                    ai_metadata = q.metadata
                else:
                    ai_metadata = {}
            
            ai_status = "ğŸ¤– AI ë¶„ì„ ì™„ë£Œ" if ai_metadata.get("ai_analysis_complete") else "ğŸ¤– AIê°€ ë‚œì´ë„ ë¶„ì„ ì¤‘..."
            
            result.append(QuestionPreviewItem(
                id=q.id,
                question_number=q.question_number,
                content=q.content,
                description=q.description,
                options=q.options or {},
                correct_answer=q.correct_answer or "",
                subject=q.subject,
                area_name=q.area_name,
                difficulty=q.difficulty if q.difficulty else "ì¤‘",
                year=q.year,
                file_title=q.file_title,
                file_category=q.file_category,
                last_modified_by=q.last_modified_by,
                last_modified_at=q.last_modified_at,
                ai_analysis_status=ai_status,
                ai_confidence=ai_metadata.get("ai_confidence", "unknown"),
                ai_reasoning=ai_metadata.get("ai_reasoning", "")
            ))
        
        return result
    
    def get_professor_questions_all(self, db: Session, user_id: int) -> dict:
        """
        êµìˆ˜ì˜ ëª¨ë“  ë¬¸ì œ ì¡°íšŒ (ìŠ¹ì¸ëœ ê²ƒê³¼ ëŒ€ê¸° ì¤‘ì¸ ê²ƒ ëª¨ë‘)
        ì„œë²„ ì¬ì‹œì‘ í›„ì—ë„ ë°ì´í„° ì§€ì†ì„± ë³´ì¥
        """
        try:
            from sqlalchemy import or_
            
            # êµìˆ˜ê°€ ì—…ë¡œë“œí•œ ëª¨ë“  ë¬¸ì œ ì¡°íšŒ (last_modified_by ê¸°ì¤€)
            all_questions = db.query(Question).filter(
                Question.last_modified_by == user_id
            ).order_by(Question.question_number.asc(), desc(Question.created_at)).all()
            
            # ìƒíƒœë³„ë¡œ ë¶„ë¥˜
            pending_questions = []
            approved_questions = []
            rejected_questions = []
            
            for q in all_questions:
                # AI ë¶„ì„ ìƒíƒœ í™•ì¸ (ì•ˆì „í•œ ì ‘ê·¼)
                ai_metadata = {}
                if hasattr(q, 'metadata') and q.metadata:
                    if isinstance(q.metadata, dict):
                        ai_metadata = q.metadata
                    else:
                        ai_metadata = {}
                
                ai_status = "ğŸ¤– AI ë¶„ì„ ì™„ë£Œ" if ai_metadata.get("ai_analysis_complete") else "ğŸ¤– AIê°€ ë‚œì´ë„ ë¶„ì„ ì¤‘..."
                
                question_item = QuestionPreviewItem(
                    id=q.id,
                    question_number=q.question_number,
                    content=q.content,
                    description=q.description,
                    options=q.options or {},
                    correct_answer=q.correct_answer or "",
                    subject=q.subject,
                    area_name=q.area_name,
                    difficulty=q.difficulty if q.difficulty else "ì¤‘",
                    year=q.year,
                    file_title=q.file_title,
                    file_category=q.file_category,
                    last_modified_by=q.last_modified_by,
                    last_modified_at=q.last_modified_at,
                    ai_analysis_status=ai_status,
                    ai_confidence=ai_metadata.get("ai_confidence", "unknown"),
                    ai_reasoning=ai_metadata.get("ai_reasoning", "")
                )
                
                if q.approval_status == "pending":
                    pending_questions.append(question_item)
                elif q.approval_status == "approved":
                    approved_questions.append(question_item)
                elif q.approval_status == "rejected":
                    rejected_questions.append(question_item)
            
            return {
                "pending": pending_questions,
                "approved": approved_questions,
                "rejected": rejected_questions,
                "total_count": len(all_questions),
                "status_summary": {
                    "pending": len(pending_questions),
                    "approved": len(approved_questions),
                    "rejected": len(rejected_questions)
                }
            }
            
        except Exception as e:
            logger.error(f"êµìˆ˜ ë¬¸ì œ ì „ì²´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "pending": [],
                "approved": [],
                "rejected": [],
                "total_count": 0,
                "status_summary": {"pending": 0, "approved": 0, "rejected": 0}
            }
    
    def get_professor_rag_stats(self, db: Session, user_id: int) -> dict:
        """
        êµìˆ˜ë³„ RAG í†µê³„ ì¡°íšŒ (ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜)
        ì„œë²„ ì¬ì‹œì‘ í›„ì—ë„ ì§€ì†ì„± ë³´ì¥
        """
        try:
            from sqlalchemy import or_
            
            # êµìˆ˜ê°€ ì—…ë¡œë“œí•œ ë¬¸ì œë“¤ì˜ í†µê³„ (last_modified_by ê¸°ì¤€)
            professor_questions = db.query(Question).filter(
                Question.last_modified_by == user_id
            ).all()
            
            # íŒŒì¼ë³„ ê·¸ë£¹í•‘ (source_file_path ê¸°ì¤€)
            uploaded_files = set()
            for q in professor_questions:
                if q.source_file_path:
                    # ì„¸ë¯¸ì½œë¡ ìœ¼ë¡œ êµ¬ë¶„ëœ íŒŒì¼ë“¤ ì²˜ë¦¬
                    files = q.source_file_path.split(';')
                    for file_path in files:
                        if file_path.strip():
                            # íŒŒì¼ëª…ë§Œ ì¶”ì¶œ
                            file_name = Path(file_path.strip()).name
                            uploaded_files.add(file_name)
            
            # ì£¼ì œë³„ ê·¸ë£¹í•‘
            subjects = set()
            for q in professor_questions:
                if q.subject:
                    subjects.add(q.subject)
            
            # ë‚œì´ë„ë³„ ê·¸ë£¹í•‘
            difficulty_stats = {"ìƒ": 0, "ì¤‘": 0, "í•˜": 0}
            for q in professor_questions:
                if q.difficulty:
                    difficulty_key = q.difficulty.value if hasattr(q.difficulty, 'value') else str(q.difficulty)
                    if difficulty_key in difficulty_stats:
                        difficulty_stats[difficulty_key] += 1
            
            # ìµœê·¼ ì—…ë¡œë“œ ì‹œê°„
            latest_question = None
            if professor_questions:
                latest_question = max(professor_questions, key=lambda x: x.created_at)
            
            return {
                "total_documents": len(uploaded_files),
                "total_questions": len(professor_questions),
                "uploaded_files": list(uploaded_files),
                "subjects": list(subjects),
                "difficulty_distribution": difficulty_stats,
                "last_upload": latest_question.created_at.isoformat() if latest_question else None,
                "status_distribution": {
                    "pending": len([q for q in professor_questions if q.approval_status == "pending"]),
                    "approved": len([q for q in professor_questions if q.approval_status == "approved"]),
                    "rejected": len([q for q in professor_questions if q.approval_status == "rejected"])
                }
            }
            
        except Exception as e:
            logger.error(f"êµìˆ˜ RAG í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "total_documents": 0,
                "total_questions": 0,
                "uploaded_files": [],
                "subjects": [],
                "difficulty_distribution": {"ìƒ": 0, "ì¤‘": 0, "í•˜": 0},
                "last_upload": None,
                "status_distribution": {"pending": 0, "approved": 0, "rejected": 0}
            }
    
    def update_question(
        self,
        db: Session,
        question_id: int,
        update_data: QuestionUpdateRequest,
        user_id: int
    ) -> bool:
        """
        ë¬¸ì œ ë‚´ìš© ìˆ˜ì •
        """
        question = db.query(Question).filter(Question.id == question_id).first()
        if not question:
            return False
        
        # ìˆ˜ì • ì‚¬í•­ ì ìš©
        if update_data.content is not None:
            question.content = update_data.content
        if update_data.description is not None:
            question.description = update_data.description
        if update_data.options is not None:
            question.options = update_data.options
        if update_data.correct_answer is not None:
            question.correct_answer = update_data.correct_answer
        if update_data.subject is not None:
            question.subject = update_data.subject
        if update_data.area_name is not None:
            question.area_name = update_data.area_name
        if update_data.difficulty is not None:
            # ë°ì´í„°ë² ì´ìŠ¤ enumì— ì§ì ‘ ë¬¸ìì—´ ê°’ í• ë‹¹ (SQLAlchemy enum ê°ì²´ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
            logger.info(f"ë‚œì´ë„ ìˆ˜ì • ìš”ì²­: '{update_data.difficulty}' -> ì§ì ‘ ë¬¸ìì—´ í• ë‹¹")
            if update_data.difficulty in ["í•˜", "ì¤‘", "ìƒ"]:
                # ë°ì´í„°ë² ì´ìŠ¤ì— ì§ì ‘ í•œê¸€ ê°’ ì €ì¥
                question.difficulty = update_data.difficulty
                logger.info(f"ë‚œì´ë„ ì„¤ì • ì™„ë£Œ: '{update_data.difficulty}' (ì§ì ‘ ë¬¸ìì—´)")
            else:
                # ê¸°ë³¸ê°’
                question.difficulty = "ì¤‘"
                logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ë‚œì´ë„ '{update_data.difficulty}', ê¸°ë³¸ê°’ 'ì¤‘'ìœ¼ë¡œ ì„¤ì •")
        
        # ìˆ˜ì • ì´ë ¥ ì—…ë°ì´íŠ¸
        question.last_modified_by = user_id
        question.last_modified_at = datetime.now()
        question.updated_at = datetime.now()
        
        db.commit()
        logger.info(f"ë¬¸ì œ {question_id} ìˆ˜ì • ì™„ë£Œ (ìˆ˜ì •ì: {user_id})")
        return True
    
    def bulk_approve_questions(
        self,
        db: Session,
        request: BulkApprovalRequest,
        approver_id: int
    ) -> QuestionApprovalResponse:
        """
        ë¬¸ì œ ì¼ê´„ ìŠ¹ì¸/ê±°ë¶€
        """
        approved_count = 0
        rejected_count = 0
        failed_count = 0
        
        for question_id in request.question_ids:
            try:
                question = db.query(Question).filter(Question.id == question_id).first()
                if not question:
                    failed_count += 1
                    continue
                
                if request.action == ApprovalStatus.APPROVED:
                    question.approval_status = "approved"
                    question.approved_by = approver_id
                    question.approved_at = datetime.now()
                    approved_count += 1
                elif request.action == ApprovalStatus.REJECTED:
                    question.approval_status = "rejected"
                    rejected_count += 1
                
                question.updated_at = datetime.now()
                
            except Exception as e:
                logger.error(f"ë¬¸ì œ {question_id} ìŠ¹ì¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                failed_count += 1
        
        db.commit()
        
        message = f"ì²˜ë¦¬ ì™„ë£Œ: ìŠ¹ì¸ {approved_count}ê°œ, ê±°ë¶€ {rejected_count}ê°œ"
        if failed_count > 0:
            message += f", ì‹¤íŒ¨ {failed_count}ê°œ"
        
        return QuestionApprovalResponse(
            success=True,
            message=message,
            approved_count=approved_count,
            rejected_count=rejected_count,
            failed_count=failed_count
        )
    
    def get_parsed_file_preview(
        self,
        parsed_data_path: str
    ) -> Optional[Dict[str, Any]]:
        """
        ì €ì¥ëœ JSON íŒŒì¼ì—ì„œ ë¯¸ë¦¬ë³´ê¸° ë°ì´í„° ë¡œë“œ
        """
        try:
            if not os.path.exists(parsed_data_path):
                return None
            
            with open(parsed_data_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            return data
        except Exception as e:
            logger.error(f"JSON íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({parsed_data_path}): {e}")
            return None
    
    def get_ai_analysis_stats(self, db: Session, user_id: int) -> dict:
        """
        AI ë¶„ì„ ê²€ì¦ë¥  ë° í†µê³„ ì¡°íšŒ
        """
        try:
            # êµìˆ˜ê°€ ì—…ë¡œë“œí•œ ëª¨ë“  ë¬¸ì œ ì¡°íšŒ
            professor_questions = db.query(Question).filter(
                Question.last_modified_by == user_id
            ).all()
            
            if not professor_questions:
                return {
                    "total_questions": 0,
                    "ai_analyzed_count": 0,
                    "analysis_completion_rate": 0.0,
                    "confidence_distribution": {},
                    "difficulty_accuracy": {},
                    "error_rate": 0.0,
                    "average_confidence": 0.0
                }
            
            total_questions = len(professor_questions)
            ai_analyzed_count = 0
            confidence_scores = []
            confidence_distribution = {"high": 0, "medium": 0, "low": 0, "unknown": 0}
            difficulty_distribution = {"í•˜": 0, "ì¤‘": 0, "ìƒ": 0}
            
            for q in professor_questions:
                # AI ë¶„ì„ ë©”íƒ€ë°ì´í„° ì•ˆì „í•˜ê²Œ ì ‘ê·¼
                ai_metadata = {}
                if hasattr(q, 'metadata') and q.metadata:
                    if isinstance(q.metadata, dict):
                        ai_metadata = q.metadata
                
                # AI ë¶„ì„ ì™„ë£Œ ì—¬ë¶€ í™•ì¸
                if ai_metadata.get("ai_analysis_complete"):
                    ai_analyzed_count += 1
                    
                    # ì‹ ë¢°ë„ ë¶„í¬
                    confidence = ai_metadata.get("ai_confidence", "unknown")
                    confidence_distribution[confidence] = confidence_distribution.get(confidence, 0) + 1
                    
                    # ì‹ ë¢°ë„ ì ìˆ˜ ìˆ˜ì§‘ (í‰ê·  ê³„ì‚°ìš©)
                    confidence_score_map = {"high": 0.9, "medium": 0.7, "low": 0.5, "unknown": 0.5}
                    confidence_scores.append(confidence_score_map.get(confidence, 0.5))
                
                # ë‚œì´ë„ ë¶„í¬
                if q.difficulty and str(q.difficulty) in difficulty_distribution:
                    difficulty_distribution[str(q.difficulty)] += 1
            
            # ê²€ì¦ë¥  ê³„ì‚°
            analysis_completion_rate = (ai_analyzed_count / total_questions) * 100 if total_questions > 0 else 0.0
            
            # í‰ê·  ì‹ ë¢°ë„
            average_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.0
            
            # ì˜¤ì°¨ìœ¨ ê³„ì‚° (ì‹ ë¢°ë„ ê¸°ë°˜ ì¶”ì •)
            error_rate = (1 - average_confidence) * 100
            
            # í‰ê°€ìœ„ì› íŒ¨í„´ê³¼ì˜ ì¼ì¹˜ìœ¨ ê³„ì‚° (ë”ë¯¸ ë°ì´í„°)
            evaluator_match_rate = 85.5  # ì‹¤ì œë¡œëŠ” í‰ê°€ìœ„ì› ë°ì´í„°ì™€ ë¹„êµí•´ì•¼ í•¨
            
            return {
                "total_questions": total_questions,
                "ai_analyzed_count": ai_analyzed_count,
                "analysis_completion_rate": round(analysis_completion_rate, 1),
                "confidence_distribution": confidence_distribution,
                "difficulty_distribution": difficulty_distribution,
                "error_rate": round(error_rate, 1),
                "average_confidence": round(average_confidence * 100, 1),
                "evaluator_match_rate": evaluator_match_rate,
                "accuracy_summary": {
                    "high_confidence": confidence_distribution.get("high", 0),
                    "reliable_predictions": ai_analyzed_count - confidence_distribution.get("low", 0),
                    "needs_review": confidence_distribution.get("low", 0)
                }
            }
            
        except Exception as e:
            logger.error(f"AI ë¶„ì„ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "total_questions": 0,
                "ai_analyzed_count": 0,
                "analysis_completion_rate": 0.0,
                "confidence_distribution": {},
                "difficulty_accuracy": {},
                "error_rate": 100.0,
                "average_confidence": 0.0,
                "error": str(e)
            } 