"""
ë¬¸ì œ ê²€í†  ë° ìŠ¹ì¸ ì„œë¹„ìŠ¤ - ëª¨ë“  í•™ê³¼ ì§€ì› ë° ì‹¤ì‹œê°„ ì§„í–‰ë¥  í‘œì‹œ
"""
import json
import os
from typing import List, Dict, Any, Optional, Callable
from datetime import datetime
from pathlib import Path

from sqlalchemy.orm import Session
from sqlalchemy import and_, desc

from ..models.question import Question, DifficultyLevel
from ..models.user import User
from ..schemas.question_review import (
    ParsedFilePreview, QuestionPreviewItem, QuestionUpdateRequest,
    BulkApprovalRequest, QuestionApprovalResponse, ApprovalStatus
)
from ..core.config import settings
import logging

# AI ë‚œì´ë„ ë¶„ì„ê¸° ë° ìœ í˜• ë§¤í¼ ì„í¬íŠ¸
try:
    from .ai_difficulty_analyzer import difficulty_analyzer
    from .evaluator_type_mapper import evaluator_type_mapper
    AI_ANALYZER_AVAILABLE = True
except ImportError:
    AI_ANALYZER_AVAILABLE = False
    logger.warning("âŒ AI ë‚œì´ë„ ë¶„ì„ê¸°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

logger = logging.getLogger(__name__)

# í•™ê³¼ ì§€ì› ë§¤í•‘
SUPPORTED_DEPARTMENTS = {
    "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": {
        "short_name": "ë¬¼ë¦¬ì¹˜ë£Œ",
        "keywords": ["ë¬¼ì¹˜", "ë¬¼ë¦¬ì¹˜ë£Œ", "pt", "physical"],
        "areas": ["ê·¼ê³¨ê²©ê³„", "ì‹ ê²½ê³„", "ì‹¬íê³„", "ì†Œì•„ë°œë‹¬", "ìŠ¤í¬ì¸ ì˜í•™"]
    },
    "ì‘ì—…ì¹˜ë£Œí•™ê³¼": {
        "short_name": "ì‘ì—…ì¹˜ë£Œ", 
        "keywords": ["ì‘ì¹˜", "ì‘ì—…ì¹˜ë£Œ", "ot", "occupational"],
        "areas": ["ì¸ì§€ì¬í™œ", "ê°ê°í†µí•©", "ë³´ì¡°ê¸°êµ¬", "ì •ì‹ ê±´ê°•", "ì•„ë™ë°œë‹¬"]
    },
    "ê°„í˜¸í•™ê³¼": {
        "short_name": "ê°„í˜¸",
        "keywords": ["ê°„í˜¸", "nursing", "ë„ˆì‹±"],
        "areas": ["ê¸°ë³¸ê°„í˜¸", "ì„±ì¸ê°„í˜¸", "ì•„ë™ê°„í˜¸", "ëª¨ì„±ê°„í˜¸", "ì •ì‹ ê°„í˜¸", "ì§€ì—­ì‚¬íšŒê°„í˜¸"]
    }
}

class QuestionReviewService:
    """ë¬¸ì œ ê²€í†  ë° ìŠ¹ì¸ ì„œë¹„ìŠ¤ - ëª¨ë“  í•™ê³¼ ì§€ì›"""
    
    def __init__(self):
        self.save_parser_dir = Path("data/save_parser")
        self.save_parser_dir.mkdir(parents=True, exist_ok=True)
        
        # ì§„í–‰ë¥  ì¶”ì ìš© ìƒíƒœ ì €ì¥ì†Œ
        self.parsing_status = {}
    
    def detect_user_department(self, db: Session, user_id: int) -> str:
        """
        ì‚¬ìš©ì ì •ë³´ì—ì„œ í•™ê³¼ ê°ì§€
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            user_id: ì‚¬ìš©ì ID
            
        Returns:
            str: ê°ì§€ëœ í•™ê³¼ëª…
        """
        try:
            user = db.query(User).filter(User.id == user_id).first()
            if not user:
                return "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼"  # ê¸°ë³¸ê°’
            
            # ì‚¬ìš©ì ì´ë¦„ì´ë‚˜ ë¶€ì„œ ì •ë³´ì—ì„œ í•™ê³¼ ì¶”ì •
            user_info = (user.name or "").lower() + (user.department or "").lower()
            
            for dept_name, dept_info in SUPPORTED_DEPARTMENTS.items():
                if any(keyword in user_info for keyword in dept_info["keywords"]):
                    logger.info(f"ì‚¬ìš©ì {user_id} í•™ê³¼ ê°ì§€: {dept_name}")
                    return dept_name
            
            # ê¸°ë³¸ê°’
            return "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼"
            
        except Exception as e:
            logger.warning(f"ì‚¬ìš©ì í•™ê³¼ ê°ì§€ ì‹¤íŒ¨: {e}")
            return "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼"
    
    def create_progress_callback(self, user_id: int, file_name: str) -> Callable[[str, float], None]:
        """
        ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜ ìƒì„±
        
        Args:
            user_id: ì‚¬ìš©ì ID
            file_name: íŒŒì¼ëª…
            
        Returns:
            Callable: ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜
        """
        def progress_callback(message: str, progress: float):
            progress_key = f"{user_id}_{file_name}"
            self.parsing_status[progress_key] = {
                "message": message,
                "progress": progress,
                "timestamp": datetime.now().isoformat(),
                "user_id": user_id,
                "file_name": file_name
            }
            logger.info(f"ğŸ“Š íŒŒì‹± ì§„í–‰ë¥  ({file_name}): {progress:.1f}% - {message}")
        
        return progress_callback
    
    def get_parsing_progress(self, user_id: int, file_name: str) -> Dict[str, Any]:
        """
        íŒŒì‹± ì§„í–‰ë¥  ì¡°íšŒ
        
        Args:
            user_id: ì‚¬ìš©ì ID  
            file_name: íŒŒì¼ëª…
            
        Returns:
            Dict: ì§„í–‰ë¥  ì •ë³´
        """
        progress_key = f"{user_id}_{file_name}"
        return self.parsing_status.get(progress_key, {
            "message": "ëŒ€ê¸° ì¤‘...",
            "progress": 0.0,
            "timestamp": datetime.now().isoformat()
        })
    
    def clear_parsing_progress(self, user_id: int, file_name: str):
        """
        íŒŒì‹± ì§„í–‰ë¥  ì •ë¦¬
        """
        progress_key = f"{user_id}_{file_name}"
        if progress_key in self.parsing_status:
            del self.parsing_status[progress_key]
    
    def save_parsed_data_to_json(
        self,
        parsed_data: List[Dict[str, Any]],
        source_file_name: str,
        user_id: int,
        department: str = "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼"
    ) -> str:
        """
        íŒŒì‹±ëœ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥ (í•™ê³¼ ì •ë³´ í¬í•¨)
        
        Returns:
            str: ì €ì¥ëœ JSON íŒŒì¼ ê²½ë¡œ
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_filename = f"{timestamp}_{user_id}_{department}_{source_file_name}"
        json_filename = f"{Path(safe_filename).stem}.json"
        json_path = self.save_parser_dir / json_filename
        
        # JSON ë°ì´í„° ì¤€ë¹„ (í•™ê³¼ ì •ë³´ ì¶”ê°€)
        save_data = {
            "meta": {
                "source_file": source_file_name,
                "department": department,
                "parsed_at": datetime.now().isoformat(),
                "parsed_by": user_id,
                "total_questions": len(parsed_data),
                "supported_areas": SUPPORTED_DEPARTMENTS.get(department, {}).get("areas", [])
            },
            "questions": parsed_data
        }
        
        # JSON íŒŒì¼ ì €ì¥
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"íŒŒì‹±ëœ ë°ì´í„° JSON ì €ì¥ ì™„ë£Œ: {json_path} ({department})")
        return str(json_path)
    
    async def parse_and_create_questions(
        self,
        db: Session,
        file_path: str,
        user_id: int,
        content_type: str = "auto",
        file_title: str = None,
        file_category: str = None
    ) -> Dict[str, Any]:
        """
        íŒŒì¼ íŒŒì‹± ë° ë¬¸ì œ ìƒì„± (ëª¨ë“  í•™ê³¼ ì§€ì›, ì‹¤ì‹œê°„ ì§„í–‰ë¥ )
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            file_path: ì—…ë¡œë“œëœ íŒŒì¼ ê²½ë¡œ
            user_id: ì‚¬ìš©ì ID
            content_type: íŒŒì¼ íƒ€ì… ("questions", "answers", "auto")
            file_title: íŒŒì¼ ì œëª©
            file_category: íŒŒì¼ ì¹´í…Œê³ ë¦¬
            
        Returns:
            Dict: íŒŒì‹± ê²°ê³¼ ë° ìƒì„±ëœ ë¬¸ì œ ì •ë³´
        """
        file_name = Path(file_path).name
        
        try:
            # 1ë‹¨ê³„: ì‚¬ìš©ì í•™ê³¼ ê°ì§€
            user_department = self.detect_user_department(db, user_id)
            logger.info(f"ğŸ¯ ì‚¬ìš©ì {user_id} í•™ê³¼: {user_department}")
            
            # 2ë‹¨ê³„: ì§„í–‰ë¥  ì½œë°± ìƒì„±
            progress_callback = self.create_progress_callback(user_id, file_name)
            progress_callback("ğŸš€ íŒŒì‹± ì‹œì‘ ì¤‘...", 0.0)
            
            # 3ë‹¨ê³„: QuestionParserë¡œ íŒŒì‹± (í•™ê³¼ ìë™ê°ì§€ + ì§„í–‰ë¥  ì½œë°±)
            from .question_parser import question_parser
            
            parsing_result = question_parser.parse_any_file(
                file_path=file_path,
                content_type=content_type,
                department=user_department,  # ì‚¬ìš©ì í•™ê³¼ ì „ë‹¬
                progress_callback=progress_callback
            )
            
            if parsing_result.get("error"):
                progress_callback(f"âŒ íŒŒì‹± ì‹¤íŒ¨: {parsing_result['error']}", 0.0)
                return {
                    "success": False,
                    "error": parsing_result['error'],
                    "department": user_department
                }
            
            parsed_data = parsing_result.get("data", [])
            detected_department = parsing_result.get("department", user_department)
            
            if not parsed_data:
                progress_callback("âš ï¸ íŒŒì‹±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤", 0.0)
                return {
                    "success": False,
                    "error": "íŒŒì‹±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤",
                    "department": detected_department
                }
            
            # 4ë‹¨ê³„: JSON íŒŒì¼ ì €ì¥
            progress_callback(f"ğŸ’¾ JSON íŒŒì¼ ì €ì¥ ì¤‘... ({len(parsed_data)}ê°œ ë¬¸ì œ)", 90.0)
            
            json_path = self.save_parsed_data_to_json(
                parsed_data, file_name, user_id, detected_department
            )
            
            # 5ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ì— ë¬¸ì œ ìƒì„±
            progress_callback("ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì¤‘...", 95.0)
            
            questions = await self.create_pending_questions(
                db=db,
                parsed_data=parsed_data,
                source_file_path=file_path,
                parsed_data_path=json_path,
                user_id=user_id,
                file_title=file_title,
                file_category=file_category,
                department=detected_department
            )
            
            progress_callback("âœ… íŒŒì‹± ë° ì €ì¥ ì™„ë£Œ!", 100.0)
            
            # ê²°ê³¼ ë°˜í™˜
            result = {
                "success": True,
                "message": f"{detected_department} ë¬¸ì œ {len(questions)}ê°œ íŒŒì‹± ì™„ë£Œ",
                "department": detected_department,
                "total_questions": len(questions),
                "questions": [
                    {
                        "id": q.id,
                        "question_number": q.question_number,
                        "content": q.content[:100] + "..." if len(q.content) > 100 else q.content,
                        "difficulty": q.difficulty,
                        "area_name": q.area_name
                    } for q in questions[:5]  # ì²˜ìŒ 5ê°œë§Œ ë¯¸ë¦¬ë³´ê¸°
                ],
                "json_path": json_path,
                "supported_areas": SUPPORTED_DEPARTMENTS.get(detected_department, {}).get("areas", [])
            }
            
            # ì§„í–‰ë¥  ì •ë¦¬ (ì§€ì—° í›„)
            import asyncio
            asyncio.create_task(self._cleanup_progress_later(user_id, file_name))
            
            return result
            
        except Exception as e:
            logger.error(f"íŒŒì‹± ë° ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {e}")
            progress_callback(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", 0.0)
            return {
                "success": False,
                "error": str(e),
                "department": "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼"
            }
    
    async def _cleanup_progress_later(self, user_id: int, file_name: str):
        """
        ì§„í–‰ë¥  ì •ë³´ ì§€ì—° ì‚­ì œ (5ë¶„ í›„)
        """
        import asyncio
        await asyncio.sleep(300)  # 5ë¶„ ëŒ€ê¸°
        self.clear_parsing_progress(user_id, file_name)
    
    async def create_pending_questions(
        self,
        db: Session,
        parsed_data: List[Dict[str, Any]],
        source_file_path: str,
        parsed_data_path: str,
        user_id: int,
        file_title: str = None,
        file_category: str = None,
        department: str = "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼"
    ) -> List[Question]:
        """
        íŒŒì‹±ëœ ë°ì´í„°ë¥¼ ëŒ€ê¸° ìƒíƒœ ë¬¸ì œë¡œ ìƒì„± (ëª¨ë“  í•™ê³¼ ì§€ì›)
        """
        questions = []
        
        # 22ë¬¸ì œ ì œí•œ ì ìš©
        limited_data = parsed_data[:22] if len(parsed_data) > 22 else parsed_data
        
        # ë¬¸ì œ ë²ˆí˜¸ ìˆœì„œë¡œ ì •ë ¬
        limited_data.sort(key=lambda x: x.get("question_number", 0))
        
        logger.info(f"ğŸ“š {department} ë¬¸ì œ {len(limited_data)}ê°œ ìƒì„± ì‹œì‘")
        
        for item in limited_data:
            logger.info(f"ë¬¸ì œ {item.get('question_number')} ìƒì„± ì‹œë„ ì¤‘... ({department})")
            
            # ê¸°ë³¸ í•„ë“œ ì¶”ì¶œ (ë°ì´í„°ë² ì´ìŠ¤ enumì— ë§ëŠ” ê°’ ì‚¬ìš©)
            question_type = item.get("file_type", "multiple_choice")
            if question_type == "questions":
                question_type = "multiple_choice"
            
            # content ì•ˆì „ ì²˜ë¦¬ - ë‹¤ì–‘í•œ í•„ë“œëª… ì‹œë„
            content = (item.get("content") or 
                      item.get("question_content") or 
                      item.get("text") or 
                      item.get("question") or 
                      item.get("problem") or 
                      f"ë¬¸ì œ {item.get('question_number', '?')}ë²ˆ")
            
            # contentê°€ ë¹ˆ ë¬¸ìì—´ì´ë©´ ê°•ì œë¡œ ê¸°ë³¸ê°’ ì„¤ì •
            if not content or content.strip() == "":
                content = f"ë¬¸ì œ {item.get('question_number', 'Unknown')}ë²ˆ - íŒŒì‹±ëœ ë‚´ìš© ì—†ìŒ"
                logger.warning(f"ë¬¸ì œ {item.get('question_number')}ë²ˆ: contentê°€ ë¹„ì–´ìˆì–´ ê¸°ë³¸ê°’ ì‚¬ìš©")
            
            difficulty = item.get("difficulty", "ì¤‘")
            
            # AI ë¶„ì„ ê²°ê³¼ê°€ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸ (question_parserì—ì„œ ì²˜ë¦¬ë¨)
            ai_analysis = None
            if item.get("ai_analysis_complete"):
                ai_analysis = {
                    "ai_difficulty": item.get("ai_difficulty", "ì¤‘"),
                    "ai_question_type": item.get("ai_question_type", "ê°ê´€ì‹"),
                    "ai_confidence": item.get("ai_confidence", "medium"),
                    "ai_reasoning": item.get("ai_reasoning", "AI ë¶„ì„ ì™„ë£Œ"),
                    "analysis_method": "question_parser",
                    "department": department
                }
                
                # AI ë¶„ì„ ê²°ê³¼ë¡œ ë‚œì´ë„ ì—…ë°ì´íŠ¸
                difficulty = ai_analysis["ai_difficulty"]
                
                logger.info(f"ğŸ¤– ë¬¸ì œ {item.get('question_number')}: AI ë¶„ì„ ê²°ê³¼ ì‚¬ìš© (ë‚œì´ë„: {difficulty})")
            else:
                # AI ë¶„ì„ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
                ai_analysis = {
                    "ai_difficulty": difficulty,
                    "ai_question_type": "ê°ê´€ì‹",
                    "ai_confidence": "low",
                    "ai_reasoning": "íŒŒì‹± ë‹¨ê³„ì—ì„œ AI ë¶„ì„ ë¯¸ì™„ë£Œ",
                    "analysis_method": "default",
                    "department": department
                }
                
                logger.warning(f"âš ï¸ ë¬¸ì œ {item.get('question_number')}: AI ë¶„ì„ ê²°ê³¼ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©")

            # ì˜ì—­ëª… í™•ì¸ ë° ì„¤ì •
            area_name = item.get("area_name")
            if not area_name or area_name == "ì¼ë°˜":
                # í‰ê°€ìœ„ì› ë°ì´í„°ì—ì„œ ì˜ì—­ëª… ì¡°íšŒ
                year = item.get("year", 2024)
                question_number = item.get("question_number", 1)
                area_name = evaluator_type_mapper.get_area_name_for_question(
                    department, year, question_number
                )
                
                # í•™ê³¼ë³„ ê¸°ë³¸ ì˜ì—­ í• ë‹¹
                if not area_name:
                    default_areas = SUPPORTED_DEPARTMENTS.get(department, {}).get("areas", [])
                    if default_areas:
                        area_name = default_areas[0]  # ì²« ë²ˆì§¸ ì˜ì—­ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ
                    else:
                        area_name = "ì¼ë°˜"

            # AI ë¶„ì„ ì •ë³´ë¥¼ ë©”íƒ€ë°ì´í„°ì— í¬í•¨
            ai_metadata = {
                "ai_analysis_complete": ai_analysis is not None,
                "ai_confidence": ai_analysis.get("ai_confidence", "medium") if ai_analysis else "unknown",
                "ai_reasoning": ai_analysis.get("ai_reasoning", "") if ai_analysis else "",
                "ai_question_type": ai_analysis.get("ai_question_type", "ê°ê´€ì‹") if ai_analysis else "ê°ê´€ì‹",
                "ai_difficulty": ai_analysis.get("ai_difficulty", "ì¤‘") if ai_analysis else "ì¤‘",
                "analysis_timestamp": datetime.now().isoformat(),
                "department": department,
                "analysis_method": ai_analysis.get("analysis_method", "default") if ai_analysis else "default"
            }

            question = Question(
                question_number=item.get("question_number", 1),
                question_type=question_type,
                content=content,
                description=item.get("description"),
                options=item.get("options", {}),
                correct_answer=item.get("correct_answer", ""),
                subject=item.get("subject", ""),
                area_name=area_name,
                difficulty=difficulty,
                year=item.get("year"),
                approval_status="pending",
                source_file_path=source_file_path,
                parsed_data_path=parsed_data_path,
                file_title=file_title,
                file_category=file_category,
                is_active=True,
                last_modified_by=user_id,  # êµìˆ˜ IDë¥¼ ìƒì„±ì ê²¸ ë§ˆì§€ë§‰ ìˆ˜ì •ìë¡œ ì„¤ì •
                last_modified_at=datetime.now(),
                metadata=ai_metadata  # AI ë¶„ì„ ì •ë³´ ì €ì¥
            )
            
            db.add(question)
            questions.append(question)
            logger.info(f"ë¬¸ì œ {item.get('question_number')} ì¶”ê°€ ì™„ë£Œ ({department})")
        
        db.commit()
        logger.info(f"âœ… {department} ëŒ€ê¸° ìƒíƒœ ë¬¸ì œ {len(questions)}ê°œ ìƒì„± ì™„ë£Œ")
        return questions

    def get_pending_questions(
        self, 
        db: Session, 
        user_id: Optional[int] = None,
        limit: int = 300,
        department_filter: Optional[str] = None
    ) -> List[QuestionPreviewItem]:
        """
        ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì¸ ë¬¸ì œë“¤ ì¡°íšŒ (êµìˆ˜ ID ê¸°ë°˜ ì§€ì†ì„±) - í•™ê³¼ í•„í„° ì§€ì›
        """
        query = db.query(Question).filter(
            Question.approval_status == "pending"
        )
        
        if user_id:
            # last_modified_byë¡œ êµìˆ˜ ë¬¸ì œ í•„í„°ë§ (ìƒì„±ì ì¶”ì )
            query = query.filter(Question.last_modified_by == user_id)
        
        # í•™ê³¼ í•„í„°ë§ (ë©”íƒ€ë°ì´í„° ê¸°ë°˜)
        if department_filter:
            # JSON ë©”íƒ€ë°ì´í„°ì—ì„œ í•™ê³¼ ì •ë³´ í•„í„°ë§ (PostgreSQL JSON ì—°ì‚°ì ì‚¬ìš©)
            from sqlalchemy import text
            query = query.filter(
                text("metadata->>'department' = :dept").params(dept=department_filter)
            )
        
        questions = query.order_by(Question.question_number.asc(), desc(Question.created_at)).limit(limit).all()
        
        result = []
        for q in questions:
            # AI ë¶„ì„ ìƒíƒœ í™•ì¸ (ì•ˆì „í•œ ì ‘ê·¼)
            ai_metadata = {}
            if hasattr(q, 'metadata') and q.metadata:
                if isinstance(q.metadata, dict):
                    ai_metadata = q.metadata
                else:
                    ai_metadata = {}
            
            # í•™ê³¼ ì •ë³´ ì¶”ì¶œ
            question_department = ai_metadata.get("department", "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼")
            ai_status = "ğŸ¤– AI ë¶„ì„ ì™„ë£Œ" if ai_metadata.get("ai_analysis_complete") else "ğŸ¤– AIê°€ ë‚œì´ë„ ë¶„ì„ ì¤‘..."
            
            result.append(QuestionPreviewItem(
                id=q.id,
                question_number=q.question_number,
                content=q.content,
                description=q.description,
                options=q.options or {},
                correct_answer=q.correct_answer or "",
                subject=q.subject,
                area_name=q.area_name,
                difficulty=q.difficulty if q.difficulty else "ì¤‘",
                year=q.year,
                file_title=f"[{question_department}] {q.file_title}" if q.file_title else f"[{question_department}] íŒŒì¼",
                file_category=q.file_category,
                last_modified_by=q.last_modified_by,
                last_modified_at=q.last_modified_at,
                ai_analysis_status=ai_status,
                ai_confidence=ai_metadata.get("ai_confidence", "unknown"),
                ai_reasoning=ai_metadata.get("ai_reasoning", "")
            ))
        
        return result
    
    def get_professor_questions_all(self, db: Session, user_id: int) -> dict:
        """
        êµìˆ˜ì˜ ëª¨ë“  ë¬¸ì œ ì¡°íšŒ (ìŠ¹ì¸ëœ ê²ƒê³¼ ëŒ€ê¸° ì¤‘ì¸ ê²ƒ ëª¨ë‘)
        ì„œë²„ ì¬ì‹œì‘ í›„ì—ë„ ë°ì´í„° ì§€ì†ì„± ë³´ì¥
        """
        try:
            from sqlalchemy import or_
            
            # êµìˆ˜ê°€ ì—…ë¡œë“œí•œ ëª¨ë“  ë¬¸ì œ ì¡°íšŒ (last_modified_by ê¸°ì¤€)
            all_questions = db.query(Question).filter(
                Question.last_modified_by == user_id
            ).order_by(Question.question_number.asc(), desc(Question.created_at)).all()
            
            # ìƒíƒœë³„ë¡œ ë¶„ë¥˜
            pending_questions = []
            approved_questions = []
            rejected_questions = []
            
            for q in all_questions:
                # AI ë¶„ì„ ìƒíƒœ í™•ì¸ (ì•ˆì „í•œ ì ‘ê·¼)
                ai_metadata = {}
                if hasattr(q, 'metadata') and q.metadata:
                    if isinstance(q.metadata, dict):
                        ai_metadata = q.metadata
                    else:
                        ai_metadata = {}
                
                ai_status = "ğŸ¤– AI ë¶„ì„ ì™„ë£Œ" if ai_metadata.get("ai_analysis_complete") else "ğŸ¤– AIê°€ ë‚œì´ë„ ë¶„ì„ ì¤‘..."
                
                question_item = QuestionPreviewItem(
                    id=q.id,
                    question_number=q.question_number,
                    content=q.content,
                    description=q.description,
                    options=q.options or {},
                    correct_answer=q.correct_answer or "",
                    subject=q.subject,
                    area_name=q.area_name,
                    difficulty=q.difficulty if q.difficulty else "ì¤‘",
                    year=q.year,
                    file_title=q.file_title,
                    file_category=q.file_category,
                    last_modified_by=q.last_modified_by,
                    last_modified_at=q.last_modified_at,
                    ai_analysis_status=ai_status,
                    ai_confidence=ai_metadata.get("ai_confidence", "unknown"),
                    ai_reasoning=ai_metadata.get("ai_reasoning", "")
                )
                
                if q.approval_status == "pending":
                    pending_questions.append(question_item)
                elif q.approval_status == "approved":
                    approved_questions.append(question_item)
                elif q.approval_status == "rejected":
                    rejected_questions.append(question_item)
            
            return {
                "pending": pending_questions,
                "approved": approved_questions,
                "rejected": rejected_questions,
                "total_count": len(all_questions),
                "status_summary": {
                    "pending": len(pending_questions),
                    "approved": len(approved_questions),
                    "rejected": len(rejected_questions)
                }
            }
            
        except Exception as e:
            logger.error(f"êµìˆ˜ ë¬¸ì œ ì „ì²´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "pending": [],
                "approved": [],
                "rejected": [],
                "total_count": 0,
                "status_summary": {"pending": 0, "approved": 0, "rejected": 0}
            }
    
    def get_professor_rag_stats(self, db: Session, user_id: int) -> dict:
        """
        êµìˆ˜ë³„ RAG í†µê³„ ì¡°íšŒ (ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜)
        ì„œë²„ ì¬ì‹œì‘ í›„ì—ë„ ì§€ì†ì„± ë³´ì¥
        """
        try:
            from sqlalchemy import or_
            
            # êµìˆ˜ê°€ ì—…ë¡œë“œí•œ ë¬¸ì œë“¤ì˜ í†µê³„ (last_modified_by ê¸°ì¤€)
            professor_questions = db.query(Question).filter(
                Question.last_modified_by == user_id
            ).all()
            
            # íŒŒì¼ë³„ ê·¸ë£¹í•‘ (source_file_path ê¸°ì¤€)
            uploaded_files = set()
            for q in professor_questions:
                if q.source_file_path:
                    # ì„¸ë¯¸ì½œë¡ ìœ¼ë¡œ êµ¬ë¶„ëœ íŒŒì¼ë“¤ ì²˜ë¦¬
                    files = q.source_file_path.split(';')
                    for file_path in files:
                        if file_path.strip():
                            # íŒŒì¼ëª…ë§Œ ì¶”ì¶œ
                            file_name = Path(file_path.strip()).name
                            uploaded_files.add(file_name)
            
            # ì£¼ì œë³„ ê·¸ë£¹í•‘
            subjects = set()
            for q in professor_questions:
                if q.subject:
                    subjects.add(q.subject)
            
            # ë‚œì´ë„ë³„ ê·¸ë£¹í•‘
            difficulty_stats = {"ìƒ": 0, "ì¤‘": 0, "í•˜": 0}
            for q in professor_questions:
                if q.difficulty:
                    difficulty_key = q.difficulty.value if hasattr(q.difficulty, 'value') else str(q.difficulty)
                    if difficulty_key in difficulty_stats:
                        difficulty_stats[difficulty_key] += 1
            
            # ìµœê·¼ ì—…ë¡œë“œ ì‹œê°„
            latest_question = None
            if professor_questions:
                latest_question = max(professor_questions, key=lambda x: x.created_at)
            
            return {
                "total_documents": len(uploaded_files),
                "total_questions": len(professor_questions),
                "uploaded_files": list(uploaded_files),
                "subjects": list(subjects),
                "difficulty_distribution": difficulty_stats,
                "last_upload": latest_question.created_at.isoformat() if latest_question else None,
                "status_distribution": {
                    "pending": len([q for q in professor_questions if q.approval_status == "pending"]),
                    "approved": len([q for q in professor_questions if q.approval_status == "approved"]),
                    "rejected": len([q for q in professor_questions if q.approval_status == "rejected"])
                }
            }
            
        except Exception as e:
            logger.error(f"êµìˆ˜ RAG í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "total_documents": 0,
                "total_questions": 0,
                "uploaded_files": [],
                "subjects": [],
                "difficulty_distribution": {"ìƒ": 0, "ì¤‘": 0, "í•˜": 0},
                "last_upload": None,
                "status_distribution": {"pending": 0, "approved": 0, "rejected": 0}
            }
    
    def update_question(
        self,
        db: Session,
        question_id: int,
        update_data: QuestionUpdateRequest,
        user_id: int
    ) -> bool:
        """
        ë¬¸ì œ ë‚´ìš© ìˆ˜ì •
        """
        question = db.query(Question).filter(Question.id == question_id).first()
        if not question:
            return False
        
        # ìˆ˜ì • ì‚¬í•­ ì ìš©
        if update_data.content is not None:
            question.content = update_data.content
        if update_data.description is not None:
            question.description = update_data.description
        if update_data.options is not None:
            question.options = update_data.options
        if update_data.correct_answer is not None:
            question.correct_answer = update_data.correct_answer
        if update_data.subject is not None:
            question.subject = update_data.subject
        if update_data.area_name is not None:
            question.area_name = update_data.area_name
        if update_data.difficulty is not None:
            # ë°ì´í„°ë² ì´ìŠ¤ enumì— ì§ì ‘ ë¬¸ìì—´ ê°’ í• ë‹¹ (SQLAlchemy enum ê°ì²´ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
            logger.info(f"ë‚œì´ë„ ìˆ˜ì • ìš”ì²­: '{update_data.difficulty}' -> ì§ì ‘ ë¬¸ìì—´ í• ë‹¹")
            if update_data.difficulty in ["í•˜", "ì¤‘", "ìƒ"]:
                # ë°ì´í„°ë² ì´ìŠ¤ì— ì§ì ‘ í•œê¸€ ê°’ ì €ì¥
                question.difficulty = update_data.difficulty
                logger.info(f"ë‚œì´ë„ ì„¤ì • ì™„ë£Œ: '{update_data.difficulty}' (ì§ì ‘ ë¬¸ìì—´)")
            else:
                # ê¸°ë³¸ê°’
                question.difficulty = "ì¤‘"
                logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ë‚œì´ë„ '{update_data.difficulty}', ê¸°ë³¸ê°’ 'ì¤‘'ìœ¼ë¡œ ì„¤ì •")
        
        # ìˆ˜ì • ì´ë ¥ ì—…ë°ì´íŠ¸
        question.last_modified_by = user_id
        question.last_modified_at = datetime.now()
        question.updated_at = datetime.now()
        
        db.commit()
        logger.info(f"ë¬¸ì œ {question_id} ìˆ˜ì • ì™„ë£Œ (ìˆ˜ì •ì: {user_id})")
        return True
    
    def bulk_approve_questions(
        self,
        db: Session,
        request: BulkApprovalRequest,
        approver_id: int
    ) -> QuestionApprovalResponse:
        """
        ë¬¸ì œ ì¼ê´„ ìŠ¹ì¸/ê±°ë¶€
        """
        approved_count = 0
        rejected_count = 0
        failed_count = 0
        
        for question_id in request.question_ids:
            try:
                question = db.query(Question).filter(Question.id == question_id).first()
                if not question:
                    failed_count += 1
                    continue
                
                if request.action == ApprovalStatus.APPROVED:
                    question.approval_status = "approved"
                    question.approved_by = approver_id
                    question.approved_at = datetime.now()
                    approved_count += 1
                elif request.action == ApprovalStatus.REJECTED:
                    question.approval_status = "rejected"
                    rejected_count += 1
                
                question.updated_at = datetime.now()
                
            except Exception as e:
                logger.error(f"ë¬¸ì œ {question_id} ìŠ¹ì¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                failed_count += 1
        
        db.commit()
        
        message = f"ì²˜ë¦¬ ì™„ë£Œ: ìŠ¹ì¸ {approved_count}ê°œ, ê±°ë¶€ {rejected_count}ê°œ"
        if failed_count > 0:
            message += f", ì‹¤íŒ¨ {failed_count}ê°œ"
        
        return QuestionApprovalResponse(
            success=True,
            message=message,
            approved_count=approved_count,
            rejected_count=rejected_count,
            failed_count=failed_count
        )
    
    def get_parsed_file_preview(
        self,
        parsed_data_path: str
    ) -> Optional[Dict[str, Any]]:
        """
        ì €ì¥ëœ JSON íŒŒì¼ì—ì„œ ë¯¸ë¦¬ë³´ê¸° ë°ì´í„° ë¡œë“œ
        """
        try:
            if not os.path.exists(parsed_data_path):
                return None
            
            with open(parsed_data_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            return data
        except Exception as e:
            logger.error(f"JSON íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({parsed_data_path}): {e}")
            return None
    
    def get_ai_analysis_stats(self, db: Session, user_id: int) -> dict:
        """
        AI ë¶„ì„ ê²€ì¦ë¥  ë° í†µê³„ ì¡°íšŒ
        """
        try:
            # êµìˆ˜ê°€ ì—…ë¡œë“œí•œ ëª¨ë“  ë¬¸ì œ ì¡°íšŒ
            professor_questions = db.query(Question).filter(
                Question.last_modified_by == user_id
            ).all()
            
            if not professor_questions:
                return {
                    "total_questions": 0,
                    "ai_analyzed_count": 0,
                    "analysis_completion_rate": 0.0,
                    "confidence_distribution": {},
                    "difficulty_accuracy": {},
                    "error_rate": 0.0,
                    "average_confidence": 0.0
                }
            
            total_questions = len(professor_questions)
            ai_analyzed_count = 0
            confidence_scores = []
            confidence_distribution = {"high": 0, "medium": 0, "low": 0, "unknown": 0}
            difficulty_distribution = {"í•˜": 0, "ì¤‘": 0, "ìƒ": 0}
            
            for q in professor_questions:
                # AI ë¶„ì„ ë©”íƒ€ë°ì´í„° ì•ˆì „í•˜ê²Œ ì ‘ê·¼
                ai_metadata = {}
                if hasattr(q, 'metadata') and q.metadata:
                    if isinstance(q.metadata, dict):
                        ai_metadata = q.metadata
                
                # AI ë¶„ì„ ì™„ë£Œ ì—¬ë¶€ í™•ì¸
                if ai_metadata.get("ai_analysis_complete"):
                    ai_analyzed_count += 1
                    
                    # ì‹ ë¢°ë„ ë¶„í¬
                    confidence = ai_metadata.get("ai_confidence", "unknown")
                    confidence_distribution[confidence] = confidence_distribution.get(confidence, 0) + 1
                    
                    # ì‹ ë¢°ë„ ì ìˆ˜ ìˆ˜ì§‘ (í‰ê·  ê³„ì‚°ìš©)
                    confidence_score_map = {"high": 0.9, "medium": 0.7, "low": 0.5, "unknown": 0.5}
                    confidence_scores.append(confidence_score_map.get(confidence, 0.5))
                
                # ë‚œì´ë„ ë¶„í¬
                if q.difficulty and str(q.difficulty) in difficulty_distribution:
                    difficulty_distribution[str(q.difficulty)] += 1
            
            # ê²€ì¦ë¥  ê³„ì‚°
            analysis_completion_rate = (ai_analyzed_count / total_questions) * 100 if total_questions > 0 else 0.0
            
            # í‰ê·  ì‹ ë¢°ë„
            average_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.0
            
            # ì˜¤ì°¨ìœ¨ ê³„ì‚° (ì‹ ë¢°ë„ ê¸°ë°˜ ì¶”ì •)
            error_rate = (1 - average_confidence) * 100
            
            # í‰ê°€ìœ„ì› íŒ¨í„´ê³¼ì˜ ì¼ì¹˜ìœ¨ ê³„ì‚° (ë”ë¯¸ ë°ì´í„°)
            evaluator_match_rate = 85.5  # ì‹¤ì œë¡œëŠ” í‰ê°€ìœ„ì› ë°ì´í„°ì™€ ë¹„êµí•´ì•¼ í•¨
            
            return {
                "total_questions": total_questions,
                "ai_analyzed_count": ai_analyzed_count,
                "analysis_completion_rate": round(analysis_completion_rate, 1),
                "confidence_distribution": confidence_distribution,
                "difficulty_distribution": difficulty_distribution,
                "error_rate": round(error_rate, 1),
                "average_confidence": round(average_confidence * 100, 1),
                "evaluator_match_rate": evaluator_match_rate,
                "accuracy_summary": {
                    "high_confidence": confidence_distribution.get("high", 0),
                    "reliable_predictions": ai_analyzed_count - confidence_distribution.get("low", 0),
                    "needs_review": confidence_distribution.get("low", 0)
                }
            }
            
        except Exception as e:
            logger.error(f"AI ë¶„ì„ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "total_questions": 0,
                "ai_analyzed_count": 0,
                "analysis_completion_rate": 0.0,
                "confidence_distribution": {},
                "difficulty_accuracy": {},
                "error_rate": 100.0,
                "average_confidence": 0.0,
                "error": str(e)
            }

    def get_department_statistics(self, db: Session, user_id: Optional[int] = None) -> Dict[str, Any]:
        """
        í•™ê³¼ë³„ ë¬¸ì œ í†µê³„ ì¡°íšŒ
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            user_id: ì‚¬ìš©ì ID (Noneì¸ ê²½ìš° ì „ì²´ í†µê³„)
            
        Returns:
            Dict: í•™ê³¼ë³„ í†µê³„ ì •ë³´
        """
        try:
            query = db.query(Question)
            
            if user_id:
                query = query.filter(Question.last_modified_by == user_id)
            
            all_questions = query.all()
            
            # í•™ê³¼ë³„ ë¶„ë¥˜
            department_stats = {}
            
            for q in all_questions:
                # ë©”íƒ€ë°ì´í„°ì—ì„œ í•™ê³¼ ì •ë³´ ì¶”ì¶œ
                ai_metadata = {}
                if hasattr(q, 'metadata') and q.metadata:
                    if isinstance(q.metadata, dict):
                        ai_metadata = q.metadata
                
                department = ai_metadata.get("department", "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼")
                
                if department not in department_stats:
                    department_stats[department] = {
                        "total_questions": 0,
                        "pending": 0,
                        "approved": 0,
                        "rejected": 0,
                        "difficulty_distribution": {"í•˜": 0, "ì¤‘": 0, "ìƒ": 0},
                        "areas": set(),
                        "latest_upload": None
                    }
                
                stats = department_stats[department]
                stats["total_questions"] += 1
                
                # ìƒíƒœë³„ ì¹´ìš´íŠ¸
                if q.approval_status == "pending":
                    stats["pending"] += 1
                elif q.approval_status == "approved":
                    stats["approved"] += 1
                elif q.approval_status == "rejected":
                    stats["rejected"] += 1
                
                # ë‚œì´ë„ë³„ ì¹´ìš´íŠ¸
                if q.difficulty:
                    difficulty = str(q.difficulty)
                    if difficulty in stats["difficulty_distribution"]:
                        stats["difficulty_distribution"][difficulty] += 1
                
                # ì˜ì—­ ìˆ˜ì§‘
                if q.area_name:
                    stats["areas"].add(q.area_name)
                
                # ìµœì‹  ì—…ë¡œë“œ ì‹œê°„
                if not stats["latest_upload"] or q.created_at > stats["latest_upload"]:
                    stats["latest_upload"] = q.created_at
            
            # setì„ listë¡œ ë³€í™˜
            for dept_name, stats in department_stats.items():
                stats["areas"] = list(stats["areas"])
                if stats["latest_upload"]:
                    stats["latest_upload"] = stats["latest_upload"].isoformat()
            
            return {
                "department_statistics": department_stats,
                "supported_departments": list(SUPPORTED_DEPARTMENTS.keys()),
                "total_departments": len(department_stats),
                "overall_total": sum(stats["total_questions"] for stats in department_stats.values())
            }
            
        except Exception as e:
            logger.error(f"í•™ê³¼ë³„ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "department_statistics": {},
                "supported_departments": list(SUPPORTED_DEPARTMENTS.keys()),
                "total_departments": 0,
                "overall_total": 0,
                "error": str(e)
            } 