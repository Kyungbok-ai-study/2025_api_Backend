#!/usr/bin/env python3
"""
AI ê¸°ë°˜ ë¬¸ì œ ë¶„ì„ ì‹œìŠ¤í…œ
Gemini AIê°€ ì§ì ‘ ë¬¸ì œ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ë‚œì´ë„, ìœ í˜•, ë¶„ì„ ê·¼ê±°ë¥¼ ì œê³µ
"""

import logging
import json
import re
from typing import Dict, List, Any, Optional
from datetime import datetime
import google.generativeai as genai

logger = logging.getLogger(__name__)

class AIQuestionAnalyzer:
    """AI ê¸°ë°˜ ë¬¸ì œ ë¶„ì„ê¸°"""
    
    def __init__(self, api_key: str = None):
        # Gemini API ì„¤ì •
        if api_key:
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel('gemini-1.5-pro')
        else:
            logger.warning("Gemini API í‚¤ê°€ ì—†ì–´ AI ë¶„ì„ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.model = None
        
        # ë¬¸ì œ ìœ í˜• ì •ì˜ (AIê°€ ì‚¬ìš©í•  í‘œì¤€ ë¶„ë¥˜)
        self.question_types = {
            "ê°ê´€ì‹": {
                "code": "multiple_choice",
                "description": "5ì§€ì„ ë‹¤ ë˜ëŠ” ë‹¤ì§€ì„ ë‹¤í˜• ë¬¸ì œ",
                "examples": ["ë‹¤ìŒ ì¤‘ ì˜³ì€ ê²ƒì€?", "ê°€ì¥ ì ì ˆí•œ ê²ƒì€?"]
            },
            "ë‹¨ë‹µí˜•": {
                "code": "short_answer", 
                "description": "ê°„ë‹¨í•œ ë‹µì•ˆì„ ìš”êµ¬í•˜ëŠ” ë¬¸ì œ",
                "examples": ["ë¬´ì—‡ì¸ê°€?", "ëª‡ ê°œì¸ê°€?", "ì–¸ì œì¸ê°€?"]
            },
            "ë…¼ìˆ í˜•": {
                "code": "essay",
                "description": "ì¥ë¬¸ì˜ ì„œìˆ ì„ ìš”êµ¬í•˜ëŠ” ë¬¸ì œ", 
                "examples": ["ì„¤ëª…í•˜ì‹œì˜¤", "ë…¼ìˆ í•˜ì‹œì˜¤", "ë¶„ì„í•˜ì‹œì˜¤"]
            },
            "ê³„ì‚°í˜•": {
                "code": "calculation",
                "description": "ìˆ˜ì‹ì´ë‚˜ ê³„ì‚°ì„ ìš”êµ¬í•˜ëŠ” ë¬¸ì œ",
                "examples": ["ê³„ì‚°í•˜ì‹œì˜¤", "êµ¬í•˜ì‹œì˜¤", "ëª‡ %ì¸ê°€?"]
            },
            "ì°¸/ê±°ì§“": {
                "code": "true_false",
                "description": "ì˜³ê³  ê·¸ë¦„ì„ íŒë‹¨í•˜ëŠ” ë¬¸ì œ",
                "examples": ["ì°¸/ê±°ì§“", "O/X", "ë§ìœ¼ë©´ O, í‹€ë¦¬ë©´ X"]
            },
            "ë¹ˆì¹¸ì±„ìš°ê¸°": {
                "code": "fill_blank",
                "description": "ë¹ˆì¹¸ì„ ì±„ìš°ëŠ” ë¬¸ì œ",
                "examples": ["ë¹ˆì¹¸ì— ë“¤ì–´ê°ˆ", "( )ì— ì•Œë§ì€", "_____"]
            },
            "ë°°ì—´/ìˆœì„œ": {
                "code": "ordering",
                "description": "ìˆœì„œë¥¼ ë§ì¶”ëŠ” ë¬¸ì œ",
                "examples": ["ìˆœì„œëŒ€ë¡œ ë‚˜ì—´", "ë‹¨ê³„ë³„ë¡œ", "ìˆœì„œëŠ”?"]
            },
            "ë§¤ì¹­/ì—°ê²°": {
                "code": "matching",
                "description": "í•­ëª©ì„ ì—°ê²°í•˜ëŠ” ë¬¸ì œ",
                "examples": ["ì—°ê²°í•˜ì‹œì˜¤", "ì§ì§€ìœ¼ì‹œì˜¤", "ë§¤ì¹­í•˜ì‹œì˜¤"]
            }
        }
        
        # ë‚œì´ë„ ê¸°ì¤€ (AIê°€ ì‚¬ìš©í•  í‰ê°€ ê¸°ì¤€)
        self.difficulty_criteria = {
            "ìƒ": {
                "description": "ë§¤ìš° ì–´ë ¤ì›€ - ì „ë¬¸ì  ì§€ì‹ê³¼ ê¹Šì€ ì´í•´ í•„ìš”",
                "characteristics": [
                    "ë³µí•©ì  ê°œë… ì—°ê²° í•„ìš”",
                    "ì„ìƒì  íŒë‹¨ë ¥ ìš”êµ¬",
                    "ê³ ì°¨ì›ì  ì‚¬ê³  í•„ìš”",
                    "ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ì§€ì‹ ìš”êµ¬"
                ]
            },
            "ì¤‘": {
                "description": "ë³´í†µ - ê¸°ë³¸ì  ì´í•´ì™€ ì ìš© ëŠ¥ë ¥ í•„ìš”", 
                "characteristics": [
                    "ê¸°ë³¸ ê°œë…ì˜ ì‘ìš©",
                    "ì¼ë°˜ì ì¸ ì „ê³µ ì§€ì‹",
                    "í‘œì¤€ì ì¸ ì ˆì°¨ ì´í•´",
                    "ê¸°ë³¸ì  ë¶„ì„ ëŠ¥ë ¥"
                ]
            },
            "í•˜": {
                "description": "ì‰¬ì›€ - ê¸°ì´ˆì  ì•”ê¸°ì™€ ì´í•´ ìˆ˜ì¤€",
                "characteristics": [
                    "ë‹¨ìˆœ ì•”ê¸° ë‚´ìš©",
                    "ê¸°ì´ˆì  ê°œë… ì´í•´",
                    "ëª…í™•í•œ ì •ë‹µ ì¡´ì¬",
                    "ì§ê´€ì ìœ¼ë¡œ ì´í•´ ê°€ëŠ¥"
                ]
            }
        }
        
    async def analyze_question(
        self, 
        question_data: Dict[str, Any],
        department: str = "ì¼ë°˜",
        subject: str = None
    ) -> Dict[str, Any]:
        """
        AIê°€ ë¬¸ì œë¥¼ ë¶„ì„í•˜ì—¬ ìœ í˜•, ë‚œì´ë„, ë¶„ì„ ê·¼ê±° ì œê³µ
        
        Args:
            question_data: ë¬¸ì œ ë°ì´í„°
            department: í•™ê³¼ ì •ë³´
            subject: ê³¼ëª© ì •ë³´
            
        Returns:
            AI ë¶„ì„ ê²°ê³¼
        """
        
        if not self.model:
            return self._get_fallback_analysis(question_data)
        
        try:
            # ë¬¸ì œ ì •ë³´ ì¶”ì¶œ
            question_content = question_data.get('content', '')
            question_options = question_data.get('options', {})
            correct_answer = question_data.get('correct_answer', '')
            question_number = question_data.get('question_number', 0)
            
            # AI ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±
            analysis_prompt = self._create_analysis_prompt(
                question_content, question_options, correct_answer,
                department, subject, question_number
            )
            
            # Gemini AIë¡œ ë¶„ì„ ìš”ì²­
            response = self.model.generate_content([analysis_prompt])
            
            if response and response.text:
                # AI ì‘ë‹µ íŒŒì‹±
                analysis_result = self._parse_ai_response(response.text)
                
                # ë¶„ì„ ê²°ê³¼ ê²€ì¦ ë° ë³´ì™„
                validated_result = self._validate_analysis_result(
                    analysis_result, question_data
                )
                
                logger.info(f"ë¬¸ì œ {question_number} AI ë¶„ì„ ì™„ë£Œ: {validated_result.get('ai_question_type')} / {validated_result.get('ai_difficulty')}")
                
                return validated_result
            else:
                logger.warning(f"ë¬¸ì œ {question_number} AI ì‘ë‹µ ì—†ìŒ, í´ë°± ì‚¬ìš©")
                return self._get_fallback_analysis(question_data)
                
        except Exception as e:
            logger.error(f"ë¬¸ì œ {question_data.get('question_number', 0)} AI ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._get_fallback_analysis(question_data)
    
    def _create_analysis_prompt(
        self, 
        content: str, 
        options: Dict, 
        answer: str,
        department: str,
        subject: str,
        question_number: int
    ) -> str:
        """AI ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        # ì„ íƒì§€ ë¬¸ìì—´ ìƒì„±
        options_text = ""
        if options and isinstance(options, dict):
            for num, option in options.items():
                options_text += f"{num}. {option}\n"
        
        # ê³¼ëª©ë³„ íŠ¹ì„± ì •ë³´
        subject_context = ""
        if subject:
            subject_context = f"ê³¼ëª©: {subject}\n"
        if department != "ì¼ë°˜":
            subject_context += f"í•™ê³¼: {department}\n"
        
        prompt = f"""
ë‹¤ìŒ ë¬¸ì œë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ JSON í˜•íƒœë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

{subject_context}
ë¬¸ì œ ë²ˆí˜¸: {question_number}

ã€ë¬¸ì œ ë‚´ìš©ã€‘
{content}

ã€ì„ íƒì§€ã€‘
{options_text}

ã€ì •ë‹µã€‘
{answer}

ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ë¬¸ì œ ìœ í˜• ë¶„ë¥˜:**
   - ê°ê´€ì‹: 5ì§€ì„ ë‹¤ ë˜ëŠ” ë‹¤ì§€ì„ ë‹¤í˜•
   - ë‹¨ë‹µí˜•: ê°„ë‹¨í•œ ë‹µì•ˆ ì„œìˆ 
   - ë…¼ìˆ í˜•: ì¥ë¬¸ ì„œìˆ  ìš”êµ¬
   - ê³„ì‚°í˜•: ìˆ˜ì‹ì´ë‚˜ ê³„ì‚° í•„ìš”
   - ì°¸/ê±°ì§“: O/X íŒë‹¨
   - ë¹ˆì¹¸ì±„ìš°ê¸°: ë¹ˆì¹¸ì„ ì±„ìš°ëŠ” ë¬¸ì œ
   - ë°°ì—´/ìˆœì„œ: ìˆœì„œ ë§ì¶”ê¸°
   - ë§¤ì¹­/ì—°ê²°: í•­ëª© ì—°ê²°

2. **ë‚œì´ë„ í‰ê°€:**
   - ìƒ(ë§¤ìš° ì–´ë ¤ì›€): ì „ë¬¸ì  ì§€ì‹, ë³µí•©ì  ì‚¬ê³ , ì„ìƒ íŒë‹¨ë ¥ í•„ìš”
   - ì¤‘(ë³´í†µ): ê¸°ë³¸ ê°œë… ì‘ìš©, ì¼ë°˜ì  ì „ê³µ ì§€ì‹ í•„ìš”
   - í•˜(ì‰¬ì›€): ê¸°ì´ˆ ì•”ê¸°, ë‹¨ìˆœ ê°œë… ì´í•´ ìˆ˜ì¤€

3. **ë¶„ì„ ê·¼ê±°:** 
   ì™œ ê·¸ë ‡ê²Œ íŒë‹¨í–ˆëŠ”ì§€ êµ¬ì²´ì  ê·¼ê±° ì œì‹œ

4. **ì‹ ë¢°ë„:**
   - high: ë§¤ìš° í™•ì‹¤í•¨ (90% ì´ìƒ)
   - medium: ì–´ëŠ ì •ë„ í™•ì‹¤í•¨ (70-90%)
   - low: ë¶ˆí™•ì‹¤í•¨ (70% ë¯¸ë§Œ)

**ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:**

```json
{{
  "ai_question_type": "ê°ê´€ì‹",
  "ai_difficulty": "ì¤‘", 
  "ai_confidence": "high",
  "ai_reasoning": "êµ¬ì²´ì ì¸ ë¶„ì„ ê·¼ê±°ë¥¼ 200ì ì´ë‚´ë¡œ ì„¤ëª…",
  "ai_analysis_complete": true,
  "content_keywords": ["ì£¼ìš”", "í‚¤ì›Œë“œ", "ëª©ë¡"],
  "cognitive_level": "ì´í•´/ì ìš©/ë¶„ì„/ì¢…í•©/í‰ê°€ ì¤‘ í•˜ë‚˜"
}}
```

JSON ì™¸ì˜ ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.
"""
        
        return prompt
    
    def _parse_ai_response(self, response_text: str) -> Dict[str, Any]:
        """AI ì‘ë‹µ íŒŒì‹±"""
        
        try:
            # JSON ë¸”ë¡ ì¶”ì¶œ
            json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # JSON ë¸”ë¡ì´ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ JSON ì°¾ê¸°
                json_str = response_text
            
            # JSON íŒŒì‹±
            parsed_data = json.loads(json_str)
            
            return parsed_data
            
        except json.JSONDecodeError as e:
            logger.warning(f"AI ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            logger.warning(f"ì›ë³¸ ì‘ë‹µ: {response_text[:200]}...")
            
            # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ íŒŒì‹± ì‹œë„
            return self._parse_text_response(response_text)
    
    def _parse_text_response(self, response_text: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ ì‘ë‹µì—ì„œ ì •ë³´ ì¶”ì¶œ"""
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        result = {
            "ai_question_type": "ê°ê´€ì‹",
            "ai_difficulty": "ì¤‘",
            "ai_confidence": "medium",
            "ai_reasoning": "AI ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
            "ai_analysis_complete": False,
            "content_keywords": [],
            "cognitive_level": "ì´í•´"
        }
        
        # ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì •ë³´ ì¶”ì¶œ
        try:
            # ë¬¸ì œ ìœ í˜• ì¶”ì¶œ
            for qtype in self.question_types.keys():
                if qtype in response_text:
                    result["ai_question_type"] = qtype
                    break
            
            # ë‚œì´ë„ ì¶”ì¶œ
            if "ìƒ" in response_text and "ë‚œì´ë„" in response_text:
                result["ai_difficulty"] = "ìƒ"
            elif "í•˜" in response_text and "ë‚œì´ë„" in response_text:
                result["ai_difficulty"] = "í•˜"
            else:
                result["ai_difficulty"] = "ì¤‘"
            
            # ì‹ ë¢°ë„ ì¶”ì¶œ
            if "high" in response_text.lower():
                result["ai_confidence"] = "high"
            elif "low" in response_text.lower():
                result["ai_confidence"] = "low"
            else:
                result["ai_confidence"] = "medium"
            
            # ì‘ë‹µ ì¼ë¶€ë¥¼ reasoningìœ¼ë¡œ ì‚¬ìš©
            result["ai_reasoning"] = response_text[:150] + "..." if len(response_text) > 150 else response_text
            
        except Exception as e:
            logger.warning(f"í…ìŠ¤íŠ¸ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        return result
    
    def _map_to_db_enum(self, ai_type: str) -> str:
        """AI ë¶„ì„ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ enum ê°’ìœ¼ë¡œ ë§¤í•‘"""
        type_mapping = {
            "ê°ê´€ì‹": "multiple_choice",
            "ë‹¨ë‹µí˜•": "short_answer", 
            "ë…¼ìˆ í˜•": "essay",
            "ê³„ì‚°í˜•": "short_answer",  # ê³„ì‚°í˜•ì€ ë‹¨ë‹µí˜•ìœ¼ë¡œ ë§¤í•‘
            "ì°¸/ê±°ì§“": "true_false",
            "ë¹ˆì¹¸ì±„ìš°ê¸°": "fill_in_blank",
            "ë°°ì—´/ìˆœì„œ": "ordering",
            "ë§¤ì¹­/ì—°ê²°": "matching"
        }
        return type_mapping.get(ai_type, "multiple_choice")

    def _validate_analysis_result(
        self, 
        analysis_result: Dict[str, Any], 
        question_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ê²€ì¦ ë° ë³´ì™„"""
        
        # í•„ìˆ˜ í•„ë“œ í™•ì¸ ë° ê¸°ë³¸ê°’ ì„¤ì •
        validated = {
            "ai_question_type": analysis_result.get("ai_question_type", "ê°ê´€ì‹"),
            "ai_difficulty": analysis_result.get("ai_difficulty", "ì¤‘"),
            "ai_confidence": analysis_result.get("ai_confidence", "medium"),
            "ai_reasoning": analysis_result.get("ai_reasoning", "AI ë¶„ì„ ê²°ê³¼"),
            "ai_analysis_complete": True,
            "content_keywords": analysis_result.get("content_keywords", []),
            "cognitive_level": analysis_result.get("cognitive_level", "ì´í•´"),
            "updated_at": datetime.now().isoformat()
        }
        
        # ë¬¸ì œ ìœ í˜• ê²€ì¦
        if validated["ai_question_type"] not in self.question_types:
            # ì„ íƒì§€ ì¡´ì¬ ì—¬ë¶€ë¡œ ê¸°ë³¸ íŒë‹¨
            if question_data.get('options'):
                validated["ai_question_type"] = "ê°ê´€ì‹"
            else:
                validated["ai_question_type"] = "ë‹¨ë‹µí˜•"
        
        # ë‚œì´ë„ ê²€ì¦
        if validated["ai_difficulty"] not in ["ìƒ", "ì¤‘", "í•˜"]:
            validated["ai_difficulty"] = "ì¤‘"
        
        # ì‹ ë¢°ë„ ê²€ì¦
        if validated["ai_confidence"] not in ["high", "medium", "low"]:
            validated["ai_confidence"] = "medium"
        
        # reasoning ê¸¸ì´ ì œí•œ
        if len(validated["ai_reasoning"]) > 300:
            validated["ai_reasoning"] = validated["ai_reasoning"][:297] + "..."
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ìš© enum ê°’ ì¶”ê°€
        validated["db_question_type"] = self._map_to_db_enum(validated["ai_question_type"])
        
        return validated
    
    def _get_fallback_analysis(self, question_data: Dict[str, Any]) -> Dict[str, Any]:
        """AI ë¶„ì„ ì‹¤íŒ¨ ì‹œ í´ë°± ë¶„ì„"""
        
        # ê¸°ë³¸ì ì¸ ê·œì¹™ ê¸°ë°˜ ë¶„ì„
        content = question_data.get('content', '')
        options = question_data.get('options', {})
        
        # ë¬¸ì œ ìœ í˜• ì¶”ì •
        if options and len(options) >= 4:
            question_type = "ê°ê´€ì‹"
        elif any(keyword in content for keyword in ["ì„¤ëª…í•˜ì‹œì˜¤", "ë…¼ìˆ í•˜ì‹œì˜¤", "ë¶„ì„í•˜ì‹œì˜¤"]):
            question_type = "ë…¼ìˆ í˜•" 
        elif any(keyword in content for keyword in ["ê³„ì‚°í•˜ì‹œì˜¤", "êµ¬í•˜ì‹œì˜¤", "%"]):
            question_type = "ê³„ì‚°í˜•"
        elif "ë¹ˆì¹¸" in content or "_" in content:
            question_type = "ë¹ˆì¹¸ì±„ìš°ê¸°"
        else:
            question_type = "ë‹¨ë‹µí˜•"
        
        # ê¸°ë³¸ ë‚œì´ë„ (ì¤‘ê°„ê°’)
        difficulty = "ì¤‘"
        
        # ë°ì´í„°ë² ì´ìŠ¤ enum ê°’ ë§¤í•‘
        db_type = self._map_to_db_enum(question_type)
        
        return {
            "ai_question_type": question_type,
            "ai_difficulty": difficulty,
            "ai_confidence": "low",
            "ai_reasoning": "AI ë¶„ì„ ë¶ˆê°€ëŠ¥ìœ¼ë¡œ ê¸°ë³¸ ê·œì¹™ ì ìš©",
            "ai_analysis_complete": False,
            "content_keywords": [],
            "cognitive_level": "ì´í•´",
            "updated_at": datetime.now().isoformat(),
            "db_question_type": db_type
        }
    
    async def batch_analyze_questions(
        self, 
        questions_data: List[Dict[str, Any]],
        department: str = "ì¼ë°˜",
        subject: str = None
    ) -> List[Dict[str, Any]]:
        """ì—¬ëŸ¬ ë¬¸ì œ ì¼ê´„ ë¶„ì„"""
        
        logger.info(f"ğŸ¤– AI ì¼ê´„ ë¶„ì„ ì‹œì‘: {len(questions_data)}ê°œ ë¬¸ì œ")
        
        analyzed_questions = []
        
        for i, question in enumerate(questions_data):
            logger.info(f"   ë¶„ì„ ì¤‘... {i+1}/{len(questions_data)}")
            
            # ê° ë¬¸ì œë³„ AI ë¶„ì„
            ai_analysis = await self.analyze_question(
                question, department, subject
            )
            
            # ì›ë³¸ ë°ì´í„°ì— AI ë¶„ì„ ê²°ê³¼ ì¶”ê°€
            enhanced_question = {**question, **ai_analysis}
            analyzed_questions.append(enhanced_question)
        
        logger.info(f"âœ… AI ì¼ê´„ ë¶„ì„ ì™„ë£Œ: {len(analyzed_questions)}ê°œ ë¬¸ì œ")
        
        # ë¶„ì„ ìš”ì•½ ì¶œë ¥
        self._print_analysis_summary(analyzed_questions)
        
        return analyzed_questions
    
    def _print_analysis_summary(self, analyzed_questions: List[Dict[str, Any]]):
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        
        # ë¬¸ì œ ìœ í˜• í†µê³„
        type_counts = {}
        difficulty_counts = {}
        confidence_counts = {}
        
        for q in analyzed_questions:
            # ìœ í˜• í†µê³„
            qtype = q.get('ai_question_type', 'unknown')
            type_counts[qtype] = type_counts.get(qtype, 0) + 1
            
            # ë‚œì´ë„ í†µê³„  
            difficulty = q.get('ai_difficulty', 'unknown')
            difficulty_counts[difficulty] = difficulty_counts.get(difficulty, 0) + 1
            
            # ì‹ ë¢°ë„ í†µê³„
            confidence = q.get('ai_confidence', 'unknown')
            confidence_counts[confidence] = confidence_counts.get(confidence, 0) + 1
        
        logger.info("ğŸ“Š AI ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
        logger.info(f"   ë¬¸ì œ ìœ í˜•: {type_counts}")
        logger.info(f"   ë‚œì´ë„ ë¶„í¬: {difficulty_counts}")
        logger.info(f"   ì‹ ë¢°ë„ ë¶„í¬: {confidence_counts}")

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
ai_question_analyzer = None

def get_ai_analyzer(api_key: str = None) -> AIQuestionAnalyzer:
    """AI ë¶„ì„ê¸° ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global ai_question_analyzer
    if ai_question_analyzer is None or api_key:
        ai_question_analyzer = AIQuestionAnalyzer(api_key)
    return ai_question_analyzer 