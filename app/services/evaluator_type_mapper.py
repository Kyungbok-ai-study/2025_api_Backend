#!/usr/bin/env python3
"""
í‰ê°€ìœ„ì› ì—‘ì…€ íŒŒì¼ì—ì„œ ì˜ì—­ì´ë¦„(ìœ í˜•) ì •ë³´ ì¶”ì¶œ ë° ë§¤í•‘ ì„œë¹„ìŠ¤
"""
import pandas as pd
import json
from pathlib import Path
from typing import Dict, List, Optional, Any
import logging

logger = logging.getLogger(__name__)

class EvaluatorTypeMapper:
    """í‰ê°€ìœ„ì› ë°ì´í„°ì—ì„œ ì˜ì—­ì´ë¦„(ìœ í˜•) ì •ë³´ ë§¤í•‘"""
    
    def __init__(self):
        self.evaluator_data = {}
        self.type_patterns = {}
        self._load_evaluator_data()
    
    def _load_evaluator_data(self):
        """í‰ê°€ìœ„ì› ì—‘ì…€ íŒŒì¼ë“¤ì—ì„œ ë°ì´í„° ë¡œë“œ"""
        try:
            # ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼ ë°ì´í„° ë¡œë“œ
            pt_dir = Path("data/í‰ê°€ìœ„ì› ìˆ˜í–‰ê²°ê³¼/í‰ê°€ìœ„ì› ìˆ˜í–‰ê²°ê³¼_ë¬¼ë¦¬ì¹˜ë£Œ")
            if pt_dir.exists():
                self.evaluator_data["ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼"] = self._process_department_files(pt_dir)
            
            # ì‘ì—…ì¹˜ë£Œí•™ê³¼ ë°ì´í„° ë¡œë“œ  
            ot_dir = Path("data/í‰ê°€ìœ„ì› ìˆ˜í–‰ê²°ê³¼/í‰ê°€ìœ„ì› ìˆ˜í–‰ê²°ê³¼_ì‘ì—…ì¹˜ë£Œ")
            if ot_dir.exists():
                self.evaluator_data["ì‘ì—…ì¹˜ë£Œí•™ê³¼"] = self._process_department_files(ot_dir)
            
            # ìœ í˜• íŒ¨í„´ ë¶„ì„
            self._analyze_type_patterns()
            
            logger.info(f"âœ… í‰ê°€ìœ„ì› ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.evaluator_data)}ê°œ í•™ê³¼")
            
        except Exception as e:
            logger.error(f"âŒ í‰ê°€ìœ„ì› ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.evaluator_data = {}
    
    def _process_department_files(self, dept_dir: Path) -> Dict[str, Any]:
        """í•™ê³¼ë³„ í‰ê°€ìœ„ì› íŒŒì¼ë“¤ ì²˜ë¦¬"""
        dept_data = {
            "evaluators": {},
            "type_consensus": {},
            "year_coverage": []
        }
        
        for excel_file in dept_dir.glob("*.xlsx"):
            evaluator_name = self._extract_evaluator_name(excel_file.name)
            evaluator_data = self._process_evaluator_file(excel_file)
            
            if evaluator_data:
                dept_data["evaluators"][evaluator_name] = evaluator_data
                logger.info(f"   âœ… {evaluator_name}: {sum(len(year_data) for year_data in evaluator_data.values())}ê°œ ë¬¸ì œ")
        
        # ì—°ë„ë³„ í•©ì˜ ìœ í˜• ê³„ì‚°
        dept_data["type_consensus"] = self._calculate_type_consensus(dept_data["evaluators"])
        dept_data["year_coverage"] = sorted(set().union(*[eval_data.keys() for eval_data in dept_data["evaluators"].values()]))
        
        return dept_data
    
    def _extract_evaluator_name(self, filename: str) -> str:
        """íŒŒì¼ëª…ì—ì„œ í‰ê°€ìœ„ì› ì´ë¦„ ì¶”ì¶œ"""
        # "2. ì‹ ì¥í›ˆ_ë¬¼ì¹˜_ë§ˆìŠ¤í„°ì½”ë”©ì§€.xlsx" -> "ì‹ ì¥í›ˆ"
        try:
            parts = filename.split("_")
            if len(parts) >= 2:
                name_part = parts[0].replace("2. ", "").strip()
                return name_part
            return filename.replace(".xlsx", "")
        except:
            return filename.replace(".xlsx", "")
    
    def _process_evaluator_file(self, file_path: Path) -> Dict[str, Dict[int, str]]:
        """ë‹¨ì¼ í‰ê°€ìœ„ì› íŒŒì¼ ì²˜ë¦¬"""
        try:
            excel_file = pd.ExcelFile(file_path)
            evaluator_data = {}
            
            for sheet_name in excel_file.sheet_names:
                year = sheet_name.replace("ë…„ë„", "")
                if year.isdigit():
                    df = pd.read_excel(file_path, sheet_name=sheet_name)
                    
                    # ì˜ì—­ì´ë¦„(ìœ í˜•) ë°ì´í„° ì¶”ì¶œ
                    year_types = {}
                    for _, row in df.iterrows():
                        q_num = row.get('ë¬¸ì œë²ˆí˜¸')
                        area_name = row.get('ì˜ì—­ì´ë¦„')
                        
                        if pd.notna(q_num) and pd.notna(area_name) and isinstance(q_num, (int, float)):
                            q_num = int(q_num)
                            if 1 <= q_num <= 30:  # 1~30ë²ˆ ë¬¸ì œë§Œ
                                year_types[q_num] = str(area_name).strip()
                    
                    if year_types:
                        evaluator_data[year] = year_types
            
            return evaluator_data
        except Exception as e:
            logger.error(f"âŒ {file_path.name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_type_consensus(self, evaluators_data: Dict[str, Dict[str, Dict[int, str]]]) -> Dict[str, Dict[int, str]]:
        """í‰ê°€ìœ„ì›ë“¤ ê°„ì˜ ìœ í˜• í•©ì˜ ê³„ì‚°"""
        consensus = {}
        
        # ëª¨ë“  ì—°ë„ ìˆ˜ì§‘
        all_years = set()
        for eval_data in evaluators_data.values():
            all_years.update(eval_data.keys())
        
        for year in all_years:
            year_consensus = {}
            
            # í•´ë‹¹ ì—°ë„ì˜ ëª¨ë“  ë¬¸ì œ ë²ˆí˜¸ ìˆ˜ì§‘
            all_questions = set()
            for eval_data in evaluators_data.values():
                if year in eval_data:
                    all_questions.update(eval_data[year].keys())
            
            # ê° ë¬¸ì œë³„ë¡œ ë‹¤ìˆ˜ê²° ìœ í˜• ê³„ì‚°
            for q_num in all_questions:
                type_votes = []
                for eval_data in evaluators_data.values():
                    if year in eval_data and q_num in eval_data[year]:
                        type_votes.append(eval_data[year][q_num])
                
                if type_votes:
                    # ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ìœ í˜• ì„ íƒ
                    type_counts = {}
                    for vote in type_votes:
                        type_counts[vote] = type_counts.get(vote, 0) + 1
                    
                    consensus_type = max(type_counts.items(), key=lambda x: x[1])[0]
                    year_consensus[q_num] = consensus_type
            
            if year_consensus:
                consensus[year] = year_consensus
        
        return consensus
    
    def _analyze_type_patterns(self):
        """ìœ í˜• íŒ¨í„´ ë¶„ì„"""
        self.type_patterns = {
            "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": {},
            "ì‘ì—…ì¹˜ë£Œí•™ê³¼": {}
        }
        
        for dept, dept_data in self.evaluator_data.items():
            if "type_consensus" in dept_data:
                all_types = set()
                for year_data in dept_data["type_consensus"].values():
                    all_types.update(year_data.values())
                
                self.type_patterns[dept] = {
                    "available_types": sorted(list(all_types)),
                    "type_count": len(all_types)
                }
        
        logger.info(f"ğŸ“Š ìœ í˜• íŒ¨í„´ ë¶„ì„ ì™„ë£Œ:")
        for dept, patterns in self.type_patterns.items():
            logger.info(f"   {dept}: {patterns['type_count']}ê°œ ìœ í˜• - {patterns['available_types'][:5]}...")
    
    def get_area_name_for_question(self, department: str, year: int, question_number: int) -> str:
        """íŠ¹ì • ë¬¸ì œì˜ ì˜ì—­ì´ë¦„(ìœ í˜•) ë°˜í™˜ - ë¬¸ì œ ìœ„ì¹˜ ê¸°ë°˜ ì¼ë°˜ íŒ¨í„´ ì‚¬ìš©"""
        try:
            # í•™ê³¼ëª… ì •ê·œí™”
            if "ë¬¼ë¦¬ì¹˜ë£Œ" in department:
                dept_key = "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼"
            elif "ì‘ì—…ì¹˜ë£Œ" in department:
                dept_key = "ì‘ì—…ì¹˜ë£Œí•™ê³¼"
            else:
                dept_key = department
            
            if dept_key not in self.evaluator_data:
                return "ì¼ë°˜"
            
            # ğŸ“Š ì—°ë„ë³„ ì°¾ê¸°ë³´ë‹¤ëŠ” ë¬¸ì œ ìœ„ì¹˜ ê¸°ë°˜ ì¼ë°˜ íŒ¨í„´ ì‚¬ìš©
            return self._get_area_by_question_position(dept_key, question_number, year)
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì˜ì—­ì´ë¦„ ì¡°íšŒ ì‹¤íŒ¨ ({department}, {year}, {question_number}): {e}")
            return "ì¼ë°˜"
    
    def _get_area_by_question_position(self, dept_key: str, question_number: int, year: int = None) -> str:
        """ë¬¸ì œ ìœ„ì¹˜ ê¸°ë°˜ ì˜ì—­ì´ë¦„ ì˜ˆì¸¡ (ì—°ë„ ë¬´ê´€ ì¼ë°˜ íŒ¨í„´)"""
        try:
            dept_data = self.evaluator_data[dept_key]
            
            # 1. íŠ¹ì • ì—°ë„ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ì—°ë„ ìš°ì„  ì‚¬ìš©
            if year:
                year_str = str(year)
                if ("type_consensus" in dept_data and 
                    year_str in dept_data["type_consensus"] and
                    question_number in dept_data["type_consensus"][year_str]):
                    return dept_data["type_consensus"][year_str][question_number]
            
            # 2. ëª¨ë“  ì—°ë„ì˜ í•´ë‹¹ ë¬¸ì œë²ˆí˜¸ ë°ì´í„° ìˆ˜ì§‘
            position_patterns = []
            if "type_consensus" in dept_data:
                for year_data in dept_data["type_consensus"].values():
                    if question_number in year_data:
                        position_patterns.append(year_data[question_number])
            
            # 3. ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ì˜ì—­ì´ë¦„ ë°˜í™˜ (ë‹¤ìˆ˜ê²°)
            if position_patterns:
                from collections import Counter
                most_common = Counter(position_patterns).most_common(1)[0][0]
                logger.debug(f"ë¬¸ì œ {question_number}ë²ˆ íŒ¨í„´: {position_patterns} â†’ '{most_common}'")
                return most_common
            
            # 4. íŒ¨í„´ì´ ì—†ìœ¼ë©´ í•™ê³¼ë³„ ê¸°ë³¸ ì˜ì—­ ë°˜í™˜
            return self._get_default_area_by_position(dept_key, question_number)
            
        except Exception as e:
            logger.warning(f"âš ï¸ ìœ„ì¹˜ ê¸°ë°˜ ì˜ì—­ì´ë¦„ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return self._get_default_area_by_position(dept_key, question_number)
    
    def _get_default_area_by_position(self, dept_key: str, question_number: int) -> str:
        """ë¬¸ì œ ìœ„ì¹˜ì— ë”°ë¥¸ ê¸°ë³¸ ì˜ì—­ì´ë¦„ (í•™ê³¼ë³„ ì¼ë°˜ì ì¸ íŒ¨í„´)"""
        
        if dept_key == "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼":
            # ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼ ì¼ë°˜ì ì¸ ë¬¸ì œ ë°°ì¹˜ íŒ¨í„´
            if question_number <= 3:
                return "ì¸ì²´ì˜ êµ¬ë¶„ê³¼ ì¡°ì§"
            elif question_number <= 8:
                return "ë¼ˆëŒ€ê³„í†µ"
            elif question_number <= 12:
                return "ê·¼ìœ¡ê³„í†µ"
            elif question_number <= 16:
                return "ìˆœí™˜ê³„í†µ"
            elif question_number <= 20:
                return "ì‹ ê²½ê³„í†µ"
            else:
                return "ì‹ ê²½ê³„í†µ"
                
        elif dept_key == "ì‘ì—…ì¹˜ë£Œí•™ê³¼":
            # ì‘ì—…ì¹˜ë£Œí•™ê³¼ ì¼ë°˜ì ì¸ ë¬¸ì œ ë°°ì¹˜ íŒ¨í„´
            if question_number <= 2:
                return "ì¸ì²´ì˜ ì²´ê³„"
            elif question_number <= 6:
                return "ë¼ˆëŒ€ì™€ ê´€ì ˆê³„(í†µ)"
            elif question_number <= 10:
                return "ê·¼ìœ¡ê³„(í†µ)"
            elif question_number <= 15:
                return "ì‹ ê²½ê³„(í†µ)"
            elif question_number <= 20:
                return "ì‹¬í˜ˆê´€ê³„(í†µ), ë©´ì—­ê³„(í†µ)"
            elif question_number <= 25:
                return "ì‹ ê²½ê³„(í†µ)ì˜ ê¸°ëŠ¥"
            else:
                return "ê·¼ìœ¡ê³„(í†µ)ì˜ ê¸°ëŠ¥"
        
        return "ì¼ë°˜"
    
    def get_available_types(self, department: str) -> List[str]:
        """í•™ê³¼ë³„ ì‚¬ìš© ê°€ëŠ¥í•œ ìœ í˜• ëª©ë¡ ë°˜í™˜"""
        try:
            # í•™ê³¼ëª… ì •ê·œí™”
            if "ë¬¼ë¦¬ì¹˜ë£Œ" in department:
                dept_key = "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼"
            elif "ì‘ì—…ì¹˜ë£Œ" in department:
                dept_key = "ì‘ì—…ì¹˜ë£Œí•™ê³¼"
            else:
                dept_key = department
            
            if dept_key in self.type_patterns:
                return self.type_patterns[dept_key]["available_types"]
            
            return ["ì¼ë°˜"]
        except:
            return ["ì¼ë°˜"]
    
    def enrich_questions_with_types(self, questions: List[Dict[str, Any]], department: str) -> List[Dict[str, Any]]:
        """ë¬¸ì œ ë°ì´í„°ì— ì˜ì—­ì´ë¦„(ìœ í˜•) ì •ë³´ ë³´ê°•"""
        enriched_questions = []
        
        for question in questions:
            enriched_question = question.copy()
            
            # ê¸°ë³¸ê°’ë“¤
            year = question.get("year", 2024)
            question_number = question.get("question_number", 1)
            
            # ì˜ì—­ì´ë¦„ ì¡°íšŒ ë° ì„¤ì •
            area_name = self.get_area_name_for_question(department, year, question_number)
            enriched_question["area_name"] = area_name
            
            # ê³¼ëª©ëª…ë„ í•™ê³¼ëª…ìœ¼ë¡œ ì„¤ì •
            enriched_question["subject"] = department
            
            enriched_questions.append(enriched_question)
            logger.debug(f"   ë¬¸ì œ {question_number}: {area_name}")
        
        logger.info(f"âœ… ë¬¸ì œ ìœ í˜• ë³´ê°• ì™„ë£Œ: {len(enriched_questions)}ê°œ ë¬¸ì œ")
        return enriched_questions
    
    def save_enhanced_analysis(self, output_path: str = "data/enhanced_evaluator_analysis.json"):
        """ê°•í™”ëœ í‰ê°€ìœ„ì› ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        try:
            analysis_data = {
                "analysis_date": pd.Timestamp.now().isoformat(),
                "departments": self.evaluator_data,
                "type_patterns": self.type_patterns,
                "summary": {
                    "total_departments": len(self.evaluator_data),
                    "total_evaluators": sum(len(dept["evaluators"]) for dept in self.evaluator_data.values()),
                    "total_types": sum(len(patterns["available_types"]) for patterns in self.type_patterns.values())
                }
            }
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(analysis_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… ê°•í™”ëœ ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_path}")
            return True
        except Exception as e:
            logger.error(f"âŒ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
evaluator_type_mapper = EvaluatorTypeMapper() 