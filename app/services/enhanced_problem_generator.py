"""
í–¥ìƒëœ ë¬¸ì œ ìƒì„± ì„œë¹„ìŠ¤
7:3 ë¹„ìœ¨ ì§€ì‹ë² ì´ìŠ¤ í™œìš© + AI ì±—ë´‡ ìŠ¤íƒ€ì¼ ìƒì„¸ í•´ì„¤ + ì¤‘ë³µ ë°©ì§€
"""
import json
import logging
import random
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
from pathlib import Path
import asyncio

from sqlalchemy.orm import Session
from sqlalchemy import text, and_, func, or_

from ..models.question import Question
from ..models.user import User
from ..core.config import settings

logger = logging.getLogger(__name__)

class MockRAGService:
    """RAG ì„œë¹„ìŠ¤ Mock (API í‚¤ê°€ ì—†ì„ ë•Œ ì‚¬ìš©)"""
    
    def similarity_search(self, db: Session, query_text: str, limit: int = 5, similarity_threshold: float = 0.7, department_filter: str = None) -> List[Dict[str, Any]]:
        """Mock ìœ ì‚¬ë„ ê²€ìƒ‰ (í•™ê³¼ë³„ í•„í„°ë§ í¬í•¨)"""
        try:
            # ê¸°ë³¸ í•„í„°: ìŠ¹ì¸ëœ ë¬¸ì œë“¤ë§Œ
            query = db.query(Question).filter(
                and_(
                    Question.approval_status == "approved",
                    Question.is_active == True
                )
            )
            
            # í•™ê³¼ë³„ í•„í„°ë§ ì¶”ê°€
            if department_filter:
                # í•™ê³¼ëª…ì´ subjectë‚˜ file_titleì— í¬í•¨ëœ ê²½ìš°ë§Œ ì„ íƒ
                department_keywords = {
                    "ê°„í˜¸í•™ê³¼": ["ê°„í˜¸", "nursing", "í™˜ì", "ë³‘ì›", "ì˜ë£Œ"],
                    "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": ["ë¬¼ë¦¬ì¹˜ë£Œ", "ì¬í™œ", "ìš´ë™", "ê·¼ê³¨ê²©", "ì‹ ê²½"],
                    "ì‘ì—…ì¹˜ë£Œí•™ê³¼": ["ì‘ì—…ì¹˜ë£Œ", "ADL", "ì¸ì§€", "ì¼ìƒìƒí™œ", "ì¬í™œ"]
                }
                
                if department_filter in department_keywords:
                    keywords = department_keywords[department_filter]
                    filter_conditions = []
                    for keyword in keywords:
                        filter_conditions.append(Question.subject.like(f"%{keyword}%"))
                        filter_conditions.append(Question.content.like(f"%{keyword}%"))
                        filter_conditions.append(Question.file_title.like(f"%{keyword}%"))
                    
                    query = query.filter(or_(*filter_conditions))
            
            questions = query.limit(limit * 2).all()
            
            mock_results = []
            for q in questions[:limit]:
                mock_results.append({
                    "id": q.id,
                    "content": q.content,
                    "subject": q.subject,
                    "file_title": f"Mock ì§€ì‹ë² ì´ìŠ¤ - {q.subject}",
                    "similarity": 0.8 + random.random() * 0.15,
                    "department": department_filter or "ì¼ë°˜"
                })
            
            return mock_results
        except Exception as e:
            logger.warning(f"Mock ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

class EnhancedProblemGenerator:
    """í–¥ìƒëœ ë¬¸ì œ ìƒì„±ê¸° (ì¤‘ë³µ ë°©ì§€ ê¸°ëŠ¥ í¬í•¨)"""
    
    def __init__(self):
        try:
            from ..services.rag_system import RAGService
            self.rag_service = RAGService()
        except Exception as e:
            logger.warning(f"RAGService ì´ˆê¸°í™” ì‹¤íŒ¨, Mock ì‚¬ìš©: {e}")
            self.rag_service = MockRAGService()
        
        # ë¬¸ì œ ìƒì„± ì¶”ì ê¸° ì´ˆê¸°í™”
        try:
            from ..services.problem_generation_tracker import generation_tracker
            self.tracker = generation_tracker
        except Exception as e:
            logger.warning(f"Generation Tracker ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.tracker = None
        
        # ë¬¸ì œ ìƒì„± ë¹„ìœ¨ ì„¤ì •
        self.knowledge_base_ratio = 0.7  # 70% ì§€ì‹ë² ì´ìŠ¤
        self.ai_knowledge_ratio = 0.3    # 30% AI ì§€ì‹
        
        # í•™ê³¼ë³„ ì „ë¬¸ ìš©ì–´ ë° ê°œë…
        self.department_concepts = {
            "ê°„í˜¸í•™ê³¼": {
                "core_concepts": [
                    "í™˜ìì•ˆì „", "ê°ì—¼ê´€ë¦¬", "íˆ¬ì•½ê´€ë¦¬", "í™œë ¥ì§•í›„", "ê°„í˜¸ì§„ë‹¨",
                    "ê°„í˜¸ì¤‘ì¬", "í™˜ìêµìœ¡", "ê°€ì¡±ê°„í˜¸", "ì‘ê¸‰ê°„í˜¸", "ìˆ˜ìˆ ê°„í˜¸",
                    "ì •ì‹ ê°„í˜¸", "ì§€ì—­ì‚¬íšŒê°„í˜¸", "ëª¨ì„±ê°„í˜¸", "ì•„ë™ê°„í˜¸", "ë…¸ì¸ê°„í˜¸"
                ],
                "procedures": [
                    "ì •ë§¥ì£¼ì‚¬", "ë„ë‡¨ê´€ ì‚½ì…", "ìƒì²˜ë“œë ˆì‹±", "í¡ì¸", "ì‚°ì†Œìš”ë²•",
                    "ìœ„ê´€ì˜ì–‘", "ê´€ì¥", "í™œë ¥ì§•í›„ ì¸¡ì •", "CPR", "ì‘ê¸‰ì²˜ì¹˜"
                ],
                "assessment_areas": [
                    "ì‹ ì²´ì‚¬ì •", "í†µì¦ì‚¬ì •", "ì˜ì–‘ìƒíƒœ", "ë‚™ìƒìœ„í—˜", "ìš•ì°½ìœ„í—˜",
                    "ì •ì‹ ìƒíƒœ", "ì¸ì§€ê¸°ëŠ¥", "ì¼ìƒìƒí™œëŠ¥ë ¥", "ì˜ì‹ìˆ˜ì¤€", "í˜¸í¡ìƒíƒœ"
                ]
            },
            "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": {
                "core_concepts": [
                    "ê·¼ê³¨ê²©ê³„", "ì‹ ê²½ê³„", "ì‹¬íê¸°ëŠ¥", "ìš´ë™ì¹˜ë£Œ", "ë„ìˆ˜ì¹˜ë£Œ",
                    "ì „ê¸°ì¹˜ë£Œ", "ìš´ë™í•™ìŠµ", "ê¸°ëŠ¥í‰ê°€", "ì¬í™œì˜í•™", "ìš´ë™ì²˜ë°©"
                ],
                "procedures": [
                    "ê´€ì ˆê°€ë™ë²”ìœ„ ìš´ë™", "ê·¼ë ¥ê°•í™” ìš´ë™", "ë³´í–‰í›ˆë ¨", "ê· í˜•í›ˆë ¨",
                    "í˜¸í¡ì¬í™œ", "ì „ê¸°ìê·¹ì¹˜ë£Œ", "ì´ˆìŒíŒŒì¹˜ë£Œ", "ëƒ‰ì˜¨ì—´ì¹˜ë£Œ"
                ],
                "assessment_areas": [
                    "ê·¼ë ¥í‰ê°€", "ê´€ì ˆê°€ë™ë²”ìœ„", "ê· í˜•ëŠ¥ë ¥", "ë³´í–‰ë¶„ì„",
                    "ê¸°ëŠ¥ì  ì›€ì§ì„", "í†µì¦í‰ê°€", "ì‹ ê²½í•™ì  ê²€ì‚¬", "ì‹¬íê¸°ëŠ¥"
                ]
            },
            "ì‘ì—…ì¹˜ë£Œí•™ê³¼": {
                "core_concepts": [
                    "ì¼ìƒìƒí™œí™œë™", "ì¸ì§€ì¬í™œ", "ê°ê°í†µí•©", "ì§ì—…ì¬í™œ", "ë³´ì¡°ê¸°êµ¬",
                    "í™˜ê²½ìˆ˜ì •", "ì˜ë¯¸ìˆëŠ” í™œë™", "ê¸°ëŠ¥ì  ìˆ˜í–‰", "ì‚¶ì˜ ì§ˆ", "ì°¸ì—¬"
                ],
                "procedures": [
                    "ADL í›ˆë ¨", "ì¸ì§€í›ˆë ¨", "ì‘ì—…ë¶„ì„", "ë³´ì¡°ê¸° ì œì‘",
                    "í™˜ê²½í‰ê°€", "ì‘ì—…ìˆ˜í–‰ í‰ê°€", "ê°ê°ì¬í™œ", "ì†ê¸°ëŠ¥ í›ˆë ¨"
                ],
                "assessment_areas": [
                    "ì‘ì—…ìˆ˜í–‰", "ì¸ì§€ê¸°ëŠ¥", "ê°ê°ê¸°ëŠ¥", "ì‹œì§€ê°", "ì†ê¸°ëŠ¥",
                    "ì¼ìƒìƒí™œëŠ¥ë ¥", "ì‚¬íšŒì°¸ì—¬", "ì§ì—…ëŠ¥ë ¥", "ì—¬ê°€í™œë™"
                ]
            }
        }
    
    async def generate_problems_with_ratio(
        self,
        db: Session,
        user: User,
        subject: str,
        difficulty: str,
        question_type: str,
        count: int,
        keywords: Optional[str] = None,
        context: Optional[str] = None
    ) -> Dict[str, Any]:
        """7:3 ë¹„ìœ¨ë¡œ ë¬¸ì œ ìƒì„± (ì¤‘ë³µ ë°©ì§€ ì ìš©)"""
        
        logger.info(f"ğŸš€ ì¤‘ë³µ ë°©ì§€ ê¸°ëŠ¥ì´ ì ìš©ëœ ë¬¸ì œ ìƒì„± ì‹œì‘ - ì‚¬ìš©ì: {user.id}")
        
        # 1. ìƒì„± ì „ëµ ë¶„ì„ (ì¤‘ë³µ ë°©ì§€)
        generation_strategy = None
        if self.tracker:
            try:
                generation_strategy = await self.tracker.get_next_generation_strategy(
                    db=db,
                    user_id=user.id,
                    subject=subject,
                    difficulty=difficulty,
                    question_type=question_type,
                    requested_keywords=keywords,
                    count=count
                )
                logger.info(f"ğŸ“Š ìƒì„± ì „ëµ ì ìš©: {generation_strategy['diversification_level']}% ë‹¤ì–‘ì„±")
            except Exception as e:
                logger.warning(f"ìƒì„± ì „ëµ ë¶„ì„ ì‹¤íŒ¨, ê¸°ë³¸ ì „ëµ ì‚¬ìš©: {e}")
        
        # 2. ì „ëµì— ë”°ë¥¸ í‚¤ì›Œë“œ ë° ë¹„ìœ¨ ì¡°ì •
        if generation_strategy:
            effective_keywords = self._apply_generation_strategy(
                keywords, generation_strategy
            )
            # ë‹¤ì–‘ì„±ì´ ë†’ì„ ë•Œ ì§€ì‹ë² ì´ìŠ¤ ë¹„ì¤‘ ì¦ê°€
            # strategyëŠ” ë”•ì…”ë„ˆë¦¬ì´ë¯€ë¡œ ì§ì ‘ ì ‘ê·¼
            kb_ratio = 0.7  # ê¸°ë³¸ê°’
            if "knowledge_base_focus" in generation_strategy:
                kb_focus = generation_strategy["knowledge_base_focus"]
                if isinstance(kb_focus, dict) and "kb_ratio_adjustment" in kb_focus:
                    kb_ratio = kb_focus["kb_ratio_adjustment"]
                elif "kb_ratio_adjustment" in generation_strategy:
                    kb_ratio = generation_strategy["kb_ratio_adjustment"]
            ai_ratio = 1.0 - kb_ratio
        else:
            effective_keywords = keywords
            kb_ratio = self.knowledge_base_ratio
            ai_ratio = self.ai_knowledge_ratio
        
        # 3. ë¹„ìœ¨ ê³„ì‚°
        knowledge_base_count = max(1, int(count * kb_ratio))
        ai_knowledge_count = count - knowledge_base_count
        
        logger.info(f"ğŸ“ˆ ì¡°ì •ëœ ìƒì„± ë¹„ìœ¨ - ì§€ì‹ë² ì´ìŠ¤: {knowledge_base_count}ê°œ({kb_ratio:.1%}), AIì§€ì‹: {ai_knowledge_count}ê°œ({ai_ratio:.1%})")
        
        generated_problems = []
        
        # 4. ì§€ì‹ë² ì´ìŠ¤ ê¸°ë°˜ ë¬¸ì œ ìƒì„± (ì „ëµ ì ìš©)
        kb_problems = await self._generate_from_knowledge_base_with_strategy(
            db, user, subject, difficulty, question_type, 
            knowledge_base_count, effective_keywords, context, generation_strategy
        )
        generated_problems.extend(kb_problems)
        
        # 5. AI ì§€ì‹ ê¸°ë°˜ ë¬¸ì œ ìƒì„± (ì „ëµ ì ìš©)
        ai_problems = await self._generate_from_ai_knowledge_with_strategy(
            user, subject, difficulty, question_type,
            ai_knowledge_count, effective_keywords, context, generation_strategy
        )
        generated_problems.extend(ai_problems)
        
        # 6. ë¬¸ì œ ì„ê¸° (ì „ëµì  ì…”í”Œ)
        self._strategic_shuffle(generated_problems, generation_strategy)
        
        # 7. ê° ë¬¸ì œì— ëŒ€í•´ AI ì±—ë´‡ ìŠ¤íƒ€ì¼ í•´ì„¤ ìƒì„±
        for problem in generated_problems:
            problem["detailed_explanation"] = await self._generate_chatbot_explanation(
                problem, user.department
            )
        
        # 8. ìƒì„± ì„¸ì…˜ ê¸°ë¡
        if self.tracker and generation_strategy:
            try:
                await self.tracker.record_generation_session(
                    user_id=user.id,
                    session_id=generation_strategy["session_id"],
                    generated_problems=generated_problems,
                    strategy_used=generation_strategy
                )
            except Exception as e:
                logger.warning(f"ìƒì„± ì„¸ì…˜ ê¸°ë¡ ì‹¤íŒ¨: {e}")
        
        return {
            "success": True,
            "total_count": len(generated_problems),
            "knowledge_base_count": knowledge_base_count,
            "ai_knowledge_count": ai_knowledge_count,
            "problems": generated_problems,
            "generation_metadata": {
                "method": "7:3_ratio_generation_with_diversity",
                "department": user.department,
                "subject": subject,
                "generated_by": user.id,
                "timestamp": datetime.now().isoformat(),
                "kb_ratio": kb_ratio,
                "ai_ratio": ai_ratio,
                "diversification_applied": generation_strategy is not None,
                "diversification_level": generation_strategy["diversification_level"] if generation_strategy else 0,
                "keywords_used": effective_keywords,
                "strategy_session_id": generation_strategy["session_id"] if generation_strategy else None
            }
        }
    
    def _apply_generation_strategy(
        self, original_keywords: Optional[str], strategy: Dict[str, Any]
    ) -> str:
        """ìƒì„± ì „ëµì— ë”°ë¥¸ í‚¤ì›Œë“œ ì ìš©"""
        
        target_keywords = strategy.get("target_keywords", [])
        alternative_keywords = strategy.get("alternative_keywords", [])
        
        # ì „ëµì—ì„œ ì œì•ˆí•œ í‚¤ì›Œë“œ ìš°ì„  ì‚¬ìš©
        if target_keywords:
            if original_keywords:
                # ì›ë˜ í‚¤ì›Œë“œ + ì „ëµ í‚¤ì›Œë“œ ì¡°í•©
                combined_keywords = [original_keywords] + target_keywords[:2]
            else:
                combined_keywords = target_keywords[:3]
            
            effective_keywords = ", ".join(combined_keywords)
        else:
            effective_keywords = original_keywords or ""
        
        logger.info(f"ğŸ¯ ì „ëµ ì ìš© í‚¤ì›Œë“œ: {effective_keywords}")
        return effective_keywords
    
    async def _generate_from_knowledge_base_with_strategy(
        self,
        db: Session,
        user: User,
        subject: str,
        difficulty: str,
        question_type: str,
        count: int,
        keywords: Optional[str],
        context: Optional[str],
        strategy: Optional[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ì „ëµì´ ì ìš©ëœ ì§€ì‹ë² ì´ìŠ¤ ê¸°ë°˜ ë¬¸ì œ ìƒì„±"""
        
        problems = []
        
        try:
            # ì „ëµì— ë”°ë¥¸ ê²€ìƒ‰ ì¿¼ë¦¬ ë‹¤ì–‘í™”
            search_queries = self._create_diverse_search_queries(
                subject, keywords, user.department, strategy
            )
            
            all_docs = []
            # ë‹¤ì–‘í•œ ì¿¼ë¦¬ë¡œ ë¬¸ì„œ ê²€ìƒ‰ (í•™ê³¼ë³„ í•„í„°ë§ ì ìš©)
            for query in search_queries:
                docs = self.rag_service.similarity_search(
                    db=db,
                    query_text=query,
                    limit=count * 2,
                    similarity_threshold=0.6,
                    department_filter=user.department  # í•™ê³¼ë³„ í•„í„°ë§ ì¶”ê°€
                )
                all_docs.extend(docs)
                logger.info(f"ğŸ¯ {user.department} ì§€ì‹ë² ì´ìŠ¤ì—ì„œ '{query}' ê²€ìƒ‰: {len(docs)}ê°œ ë¬¸ì„œ")
            
            # ì¤‘ë³µ ì œê±° ë° ë‹¤ì–‘ì„± í™•ë³´
            unique_docs = self._ensure_document_diversity(all_docs, strategy)
            
            if not unique_docs:
                logger.warning("ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ AI ì§€ì‹ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                return await self._generate_from_ai_knowledge_with_strategy(
                    user, subject, difficulty, question_type, count, keywords, context, strategy
                )
            
            # ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì–‘í•œ ë¬¸ì œ ìƒì„±
            dept_concepts = self.department_concepts.get(user.department, self.department_concepts["ê°„í˜¸í•™ê³¼"])
            
            for i in range(count):
                doc = unique_docs[i % len(unique_docs)]
                
                # ì „ëµì— ë”°ë¥¸ ê°œë… ì¶”ì¶œ
                extracted_concepts = self._extract_concepts_with_strategy(
                    doc["content"], dept_concepts, strategy
                )
                
                problem = await self._create_problem_from_document_with_strategy(
                    doc, extracted_concepts, question_type, difficulty, user.department, i, strategy
                )
                
                problem["source"] = "knowledge_base"
                problem["source_document"] = doc["file_title"]
                problem["similarity_score"] = doc["similarity"]
                problem["diversification_applied"] = True
                
                problems.append(problem)
            
            logger.info(f"ğŸ“š ì „ëµ ì ìš© ì§€ì‹ë² ì´ìŠ¤ ë¬¸ì œ ìƒì„±: {len(problems)}ê°œ")
            
        except Exception as e:
            logger.error(f"ì „ëµ ì ìš© ì§€ì‹ë² ì´ìŠ¤ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´
            return await self._generate_from_knowledge_base(
                db, user, subject, difficulty, question_type, count, keywords, context
            )
        
        return problems
    
    async def _generate_from_ai_knowledge_with_strategy(
        self,
        user: User,
        subject: str,
        difficulty: str,
        question_type: str,
        count: int,
        keywords: Optional[str],
        context: Optional[str],
        strategy: Optional[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ì „ëµì´ ì ìš©ëœ AI ì§€ì‹ ê¸°ë°˜ ë¬¸ì œ ìƒì„±"""
        
        problems = []
        dept_concepts = self.department_concepts.get(user.department, self.department_concepts["ê°„í˜¸í•™ê³¼"])
        
        # ì „ëµì— ë”°ë¥¸ ê°œë… ì„ íƒ
        concepts_to_use = self._select_concepts_with_strategy(dept_concepts, strategy)
        
        for i in range(count):
            # ì „ëµì— ë”°ë¥¸ ê°œë… ì„ íƒ
            if strategy and strategy.get("target_keywords"):
                # ì „ëµ í‚¤ì›Œë“œ ìš°ì„  ì‚¬ìš©
                main_concept = strategy["target_keywords"][i % len(strategy["target_keywords"])]
            elif keywords:
                main_concept = keywords
            else:
                # ë‹¤ì–‘ì„± í™•ë³´ë¥¼ ìœ„í•œ ê°œë… ì„ íƒ
                concept_category = random.choice(list(concepts_to_use.keys()))
                main_concept = random.choice(concepts_to_use[concept_category])
            
            problem = await self._create_ai_generated_problem_with_strategy(
                main_concept, subject, question_type, difficulty, user.department, i, strategy
            )
            
            problem["source"] = "ai_knowledge"
            problem["base_concept"] = main_concept
            problem["concept_category"] = "strategic_selection"
            problem["diversification_applied"] = True
            
            problems.append(problem)
        
        logger.info(f"ğŸ¤– ì „ëµ ì ìš© AI ì§€ì‹ ë¬¸ì œ ìƒì„±: {len(problems)}ê°œ")
        return problems
    
    def _create_diverse_search_queries(
        self, subject: str, keywords: Optional[str], department: str, 
        strategy: Optional[Dict[str, Any]]
    ) -> List[str]:
        """ë‹¤ì–‘í•œ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        
        queries = [subject]
        
        if keywords:
            queries.append(keywords)
        
        # ì „ëµì—ì„œ ì œì•ˆí•œ í‚¤ì›Œë“œ ì¶”ê°€
        if strategy:
            target_keywords = strategy.get("target_keywords", [])
            alternative_keywords = strategy.get("alternative_keywords", [])
            
            queries.extend(target_keywords[:2])
            queries.extend(alternative_keywords[:1])
        
        # í•™ê³¼ë³„ ì „ë¬¸ ìš©ì–´ ì¶”ê°€ (ë‹¤ì–‘ì„± í™•ë³´)
        dept_concepts = self.department_concepts.get(department, {})
        if dept_concepts:
            for category, concepts in dept_concepts.items():
                queries.append(random.choice(concepts))
        
        # ì¤‘ë³µ ì œê±°
        unique_queries = list(set(queries))
        
        logger.info(f"ğŸ” ë‹¤ì–‘ì„± ê²€ìƒ‰ ì¿¼ë¦¬ {len(unique_queries)}ê°œ ìƒì„±")
        return unique_queries[:5]  # ìµœëŒ€ 5ê°œ ì¿¼ë¦¬
    
    def _ensure_document_diversity(
        self, all_docs: List[Dict[str, Any]], strategy: Optional[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ë¬¸ì„œ ë‹¤ì–‘ì„± í™•ë³´"""
        
        if not all_docs:
            return []
        
        # ì¤‘ë³µ ì œê±° (íŒŒì¼ëª… ê¸°ì¤€)
        seen_files = set()
        unique_docs = []
        
        for doc in all_docs:
            file_title = doc.get("file_title", "")
            if file_title not in seen_files:
                seen_files.add(file_title)
                unique_docs.append(doc)
        
        # ì „ëµì— ë”°ë¥¸ ë¬¸ì„œ ì •ë ¬
        if strategy and strategy.get("diversification_level", 0) > 70:
            # ë†’ì€ ë‹¤ì–‘ì„±: ìœ ì‚¬ë„ê°€ ë‚®ì€ ê²ƒë¶€í„° (ë” ë‹¤ì–‘í•œ ë¬¸ì„œ)
            unique_docs.sort(key=lambda x: x.get("similarity", 0))
        else:
            # ì¼ë°˜ì ì¸ ê²½ìš°: ìœ ì‚¬ë„ê°€ ë†’ì€ ê²ƒë¶€í„°
            unique_docs.sort(key=lambda x: x.get("similarity", 0), reverse=True)
        
        logger.info(f"ğŸ“Š ë¬¸ì„œ ë‹¤ì–‘ì„± í™•ë³´: {len(unique_docs)}ê°œ ê³ ìœ  ë¬¸ì„œ")
        return unique_docs
    
    def _extract_concepts_with_strategy(
        self, text: str, dept_concepts: Dict[str, List[str]], 
        strategy: Optional[Dict[str, Any]]
    ) -> List[str]:
        """ì „ëµì— ë”°ë¥¸ ê°œë… ì¶”ì¶œ"""
        
        # ê¸°ë³¸ ê°œë… ì¶”ì¶œ
        found_concepts = self._extract_concepts_from_text(text, dept_concepts)
        
        # ì „ëµ ì ìš©
        if strategy:
            avoid_patterns = strategy.get("avoid_patterns", [])
            target_keywords = strategy.get("target_keywords", [])
            
            # í”¼í•´ì•¼ í•  íŒ¨í„´ ì œê±°
            filtered_concepts = []
            for concept in found_concepts:
                should_avoid = any(
                    pattern.startswith("overused_keyword:") and concept in pattern
                    for pattern in avoid_patterns
                )
                if not should_avoid:
                    filtered_concepts.append(concept)
            
            # ì „ëµ í‚¤ì›Œë“œ ìš°ì„  ì¶”ê°€
            if target_keywords:
                for keyword in target_keywords:
                    if keyword not in filtered_concepts:
                        filtered_concepts.insert(0, keyword)
            
            found_concepts = filtered_concepts
        
        return found_concepts[:5]  # ìµœëŒ€ 5ê°œ
    
    def _select_concepts_with_strategy(
        self, dept_concepts: Dict[str, List[str]], strategy: Optional[Dict[str, Any]]
    ) -> Dict[str, List[str]]:
        """ì „ëµì— ë”°ë¥¸ ê°œë… ì„ íƒ"""
        
        if not strategy:
            return dept_concepts
        
        avoid_patterns = strategy.get("avoid_patterns", [])
        diversification_level = strategy.get("diversification_level", 50)
        
        # í”¼í•´ì•¼ í•  í‚¤ì›Œë“œ ì¶”ì¶œ
        avoid_keywords = set()
        for pattern in avoid_patterns:
            if pattern.startswith("overused_keyword:"):
                avoid_keywords.add(pattern.split(":", 1)[1])
        
        # ì „ëµì— ë”°ë¥¸ ê°œë… í•„í„°ë§
        filtered_concepts = {}
        for category, concepts in dept_concepts.items():
            filtered_concepts[category] = [
                concept for concept in concepts 
                if concept not in avoid_keywords
            ]
        
        # ë‹¤ì–‘ì„±ì´ ë†’ì„ ë•Œ ëª¨ë“  ì¹´í…Œê³ ë¦¬ ì‚¬ìš©, ë‚®ì„ ë•Œ ì¼ë¶€ë§Œ ì‚¬ìš©
        if diversification_level > 70:
            return filtered_concepts
        elif diversification_level > 40:
            # ì ˆë°˜ì˜ ì¹´í…Œê³ ë¦¬ë§Œ ì‚¬ìš©
            categories = list(filtered_concepts.keys())
            selected_categories = random.sample(categories, max(1, len(categories) // 2))
            return {cat: filtered_concepts[cat] for cat in selected_categories}
        else:
            # í•˜ë‚˜ì˜ ì¹´í…Œê³ ë¦¬ë§Œ ì§‘ì¤‘ ì‚¬ìš©
            category = random.choice(list(filtered_concepts.keys()))
            return {category: filtered_concepts[category]}
    
    async def _create_problem_from_document_with_strategy(
        self,
        doc: Dict[str, Any],
        concepts: List[str],
        question_type: str,
        difficulty: str,
        department: str,
        index: int,
        strategy: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ì „ëµì´ ì ìš©ëœ ë¬¸ì„œ ê¸°ë°˜ ë¬¸ì œ ìƒì„±"""
        
        # ì „ëµì— ë”°ë¥¸ ì ‘ê·¼ ë°©ì‹ ë‹¤ì–‘í™”
        if strategy and strategy.get("generation_guidance", {}).get("vary_question_approaches"):
            # ë‹¤ì–‘í•œ ì ‘ê·¼ ë°©ì‹ ì ìš©
            approaches = ["analytical", "practical", "comparative", "evaluative"]
            approach = random.choice(approaches)
        else:
            approach = "standard"
        
        main_concept = concepts[0] if concepts else "í•µì‹¬ ê°œë…"
        doc_content = doc["content"][:200]
        
        problem_id = f"kb_strategy_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{index}"
        
        # ì ‘ê·¼ ë°©ì‹ì— ë”°ë¥¸ ë¬¸ì œ ìƒì„±
        if question_type == "multiple_choice":
            question_text, choices, correct_answer = self._create_multiple_choice_with_approach(
                doc_content, main_concept, department, approach
            )
        elif question_type == "short_answer":
            question_text = self._create_short_answer_with_approach(
                doc_content, main_concept, approach
            )
            choices = None
            correct_answer = f"{main_concept}ì— ëŒ€í•œ {approach} ì ‘ê·¼ ë‹µì•ˆ"
        elif question_type == "essay":
            question_text = self._create_essay_with_approach(
                doc_content, main_concept, approach
            )
            choices = None
            correct_answer = f"{main_concept}ì— ëŒ€í•œ í¬ê´„ì  {approach} ë…¼ìˆ  ë‹µì•ˆ"
        else:  # true_false
            question_text = f"{main_concept}ì— ëŒ€í•œ ë‹¤ìŒ ì„¤ëª…ì´ ì˜¬ë°”ë¥¸ì§€ íŒë‹¨í•˜ì‹œì˜¤: '{doc_content[:50]}...'"
            choices = {"O": "ì°¸", "X": "ê±°ì§“"}
            correct_answer = "O"
        
        return {
            "id": problem_id,
            "question": question_text,
            "type": question_type,
            "choices": choices,
            "correct_answer": correct_answer,
            "difficulty": difficulty,
            "main_concept": main_concept,
            "related_concepts": concepts[:5],
            "approach": approach,
            "confidence_score": min(0.9, doc["similarity"] + 0.1),
            "generated_at": datetime.now().isoformat()
        }
    
    async def _create_ai_generated_problem_with_strategy(
        self,
        concept: str,
        subject: str,
        question_type: str,
        difficulty: str,
        department: str,
        index: int,
        strategy: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ì „ëµì´ ì ìš©ëœ AI ìƒì„± ë¬¸ì œ"""
        
        problem_id = f"ai_strategy_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{index}"
        
        # ì „ëµì— ë”°ë¥¸ ë¬¸ì œ ìŠ¤íƒ€ì¼ ë‹¤ì–‘í™”
        style_variations = self._get_style_variations(department, strategy)
        
        dept_styles = style_variations.get(department, style_variations["ê°„í˜¸í•™ê³¼"])
        
        if question_type == "multiple_choice":
            question_text = dept_styles.get("multiple_choice", f"{concept}ì— ëŒ€í•œ ì„¤ëª…ìœ¼ë¡œ ì˜¬ë°”ë¥¸ ê²ƒì€?")
            choices, correct_answer = self._generate_multiple_choices_with_strategy(concept, department, strategy)
        elif question_type == "short_answer":
            question_text = dept_styles.get("short_answer", f"{concept}ì— ëŒ€í•´ ì„¤ëª…í•˜ì‹œì˜¤.")
            choices = None
            correct_answer = f"{concept}ì— ëŒ€í•œ {department} ê´€ì ì˜ ì „ëµì  ë‹µì•ˆ"
        elif question_type == "essay":
            question_text = dept_styles.get("essay", f"{concept}ì— ëŒ€í•´ ë…¼ìˆ í•˜ì‹œì˜¤.")
            choices = None
            correct_answer = f"{concept}ì— ëŒ€í•œ í¬ê´„ì ì´ê³  ì „ëµì ì¸ ë…¼ìˆ  ë‹µì•ˆ"
        else:  # true_false
            question_text = f"{concept}ëŠ” {subject} ì˜ì—­ì—ì„œ í•µì‹¬ì ì¸ ê°œë…ì´ë‹¤."
            choices = {"O": "ì°¸", "X": "ê±°ì§“"}
            correct_answer = "O"
        
        return {
            "id": problem_id,
            "question": question_text,
            "type": question_type,
            "choices": choices,
            "correct_answer": correct_answer,
            "difficulty": difficulty,
            "main_concept": concept,
            "strategy_applied": True,
            "confidence_score": 0.8 + random.random() * 0.1,
            "generated_at": datetime.now().isoformat()
        }
    
    def _create_multiple_choice_with_approach(
        self, doc_content: str, concept: str, department: str, approach: str
    ) -> Tuple[str, Dict[str, str], str]:
        """ì ‘ê·¼ ë°©ì‹ì— ë”°ë¥¸ ê°ê´€ì‹ ë¬¸ì œ ìƒì„±"""
        
        approach_templates = {
            "analytical": f"ë‹¤ìŒ ìë£Œë¥¼ ë¶„ì„í•  ë•Œ {concept}ì˜ í•µì‹¬ ìš”ì†ŒëŠ”?",
            "practical": f"ë‹¤ìŒ ìƒí™©ì—ì„œ {concept}ì„ ì‹¤ì œ ì ìš©í•  ë•Œ ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€?",
            "comparative": f"ë‹¤ìŒ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ {concept}ê³¼ ê´€ë ¨ëœ ì ‘ê·¼ë²•ì„ ë¹„êµí•  ë•Œ ì˜³ì€ ê²ƒì€?",
            "evaluative": f"ë‹¤ìŒ ë‚´ìš©ì„ í‰ê°€í•  ë•Œ {concept}ì˜ íƒ€ë‹¹ì„±ì„ íŒë‹¨í•˜ëŠ” ê¸°ì¤€ì€?",
            "standard": f"ë‹¤ìŒ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ {concept}ì— ëŒ€í•œ ì„¤ëª…ìœ¼ë¡œ ê°€ì¥ ì ì ˆí•œ ê²ƒì€?"
        }
        
        question_text = approach_templates.get(approach, approach_templates["standard"])
        question_text += f"\n\n[ìë£Œ] {doc_content[:100]}..."
        
        choices, correct_answer = self._generate_multiple_choices(concept, department)
        
        return question_text, choices, correct_answer
    
    def _create_short_answer_with_approach(
        self, doc_content: str, concept: str, approach: str
    ) -> str:
        """ì ‘ê·¼ ë°©ì‹ì— ë”°ë¥¸ ë‹¨ë‹µí˜• ë¬¸ì œ ìƒì„±"""
        
        approach_templates = {
            "analytical": f"{concept}ì— ëŒ€í•´ ë‹¤ìŒ ìë£Œë¥¼ ë¶„ì„ì ìœ¼ë¡œ ê²€í† í•˜ì—¬ í•µì‹¬ ìš”ì†Œë“¤ì„ ì„¤ëª…í•˜ì‹œì˜¤.",
            "practical": f"{concept}ì˜ ì‹¤ë¬´ ì ìš© ë°©ì•ˆì„ ë‹¤ìŒ ìë£Œë¥¼ ì°¸ê³ í•˜ì—¬ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•˜ì‹œì˜¤.",
            "comparative": f"{concept}ê³¼ ê´€ë ¨ëœ ë‹¤ì–‘í•œ ì ‘ê·¼ë²•ì„ ë¹„êµí•˜ì—¬ ì„¤ëª…í•˜ì‹œì˜¤.",
            "evaluative": f"{concept}ì˜ íš¨ê³¼ì„±ì„ í‰ê°€í•˜ëŠ” ê¸°ì¤€ì„ ì œì‹œí•˜ê³  ì„¤ëª…í•˜ì‹œì˜¤.",
            "standard": f"{concept}ì— ëŒ€í•´ ë‹¤ìŒ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì„¤ëª…í•˜ì‹œì˜¤."
        }
        
        question_text = approach_templates.get(approach, approach_templates["standard"])
        question_text += f"\nì°¸ê³ : {doc_content[:100]}..."
        
        return question_text
    
    def _create_essay_with_approach(
        self, doc_content: str, concept: str, approach: str
    ) -> str:
        """ì ‘ê·¼ ë°©ì‹ì— ë”°ë¥¸ ë…¼ìˆ í˜• ë¬¸ì œ ìƒì„±"""
        
        approach_templates = {
            "analytical": f"{concept}ì— ëŒ€í•œ ë‹¤ìŒ ìë£Œë¥¼ ë¶„ì„í•˜ê³  ì´ë¡ ì  ë°°ê²½ì„ ì¢…í•©í•˜ì—¬ ë…¼ìˆ í•˜ì‹œì˜¤.",
            "practical": f"{concept}ì˜ ì‹¤ë¬´ ì ìš©ì„ ìœ„í•œ ì „ëµì„ ìˆ˜ë¦½í•˜ê³  êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ì•ˆì„ ë…¼ìˆ í•˜ì‹œì˜¤.",
            "comparative": f"{concept}ê³¼ ê´€ë ¨ëœ ë‹¤ì–‘í•œ ê´€ì ì„ ë¹„êµÂ·ë¶„ì„í•˜ì—¬ ì¢…í•©ì ìœ¼ë¡œ ë…¼ìˆ í•˜ì‹œì˜¤.",
            "evaluative": f"{concept}ì˜ í˜„ì¬ ìƒí™©ì„ í‰ê°€í•˜ê³  ê°œì„  ë°©í–¥ì„ ì œì‹œí•˜ì—¬ ë…¼ìˆ í•˜ì‹œì˜¤.",
            "standard": f"{concept}ì— ëŒ€í•œ ë‹¤ìŒ ìë£Œë¥¼ ë¶„ì„í•˜ê³  ì¢…í•©ì ìœ¼ë¡œ ë…¼ìˆ í•˜ì‹œì˜¤."
        }
        
        question_text = approach_templates.get(approach, approach_templates["standard"])
        question_text += f"\nìë£Œ: {doc_content[:150]}..."
        
        return question_text
    
    def _get_style_variations(
        self, department: str, strategy: Optional[Dict[str, Any]]
    ) -> Dict[str, Dict[str, str]]:
        """ì „ëµì— ë”°ë¥¸ ìŠ¤íƒ€ì¼ ë³€í˜•"""
        
        if not strategy or strategy.get("diversification_level", 0) < 50:
            # ê¸°ë³¸ ìŠ¤íƒ€ì¼ ì‚¬ìš©
            return {
                "ê°„í˜¸í•™ê³¼": {
                    "multiple_choice": "ë‹¤ìŒ ì¤‘ {concept}ê³¼ ê´€ë ¨ëœ ê°„í˜¸ì¤‘ì¬ë¡œ ê°€ì¥ ì ì ˆí•œ ê²ƒì€?",
                    "short_answer": "{concept} ì‹œ ê°„í˜¸ì‚¬ê°€ ìˆ˜í–‰í•´ì•¼ í•  í•µì‹¬ ì—­í• ì„ ê¸°ìˆ í•˜ì‹œì˜¤.",
                    "essay": "{concept}ì— ëŒ€í•œ ê°„í˜¸ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•˜ì‹œì˜¤."
                },
                "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": {
                    "multiple_choice": "ë‹¤ìŒ ì¤‘ {concept}ì— ëŒ€í•œ ë¬¼ë¦¬ì¹˜ë£Œì  ì ‘ê·¼ìœ¼ë¡œ ì˜³ì€ ê²ƒì€?",
                    "short_answer": "{concept} í™˜ìì˜ ê¸°ëŠ¥í‰ê°€ ë°©ë²•ì„ ì„¤ëª…í•˜ì‹œì˜¤.",
                    "essay": "{concept} í™˜ìë¥¼ ìœ„í•œ ì¬í™œì¹˜ë£Œ ê³„íšì„ ìˆ˜ë¦½í•˜ì‹œì˜¤."
                },
                "ì‘ì—…ì¹˜ë£Œí•™ê³¼": {
                    "multiple_choice": "ë‹¤ìŒ ì¤‘ {concept}ê³¼ ê´€ë ¨ëœ ì‘ì—…ì¹˜ë£Œ ì¤‘ì¬ë¡œ íš¨ê³¼ì ì¸ ê²ƒì€?",
                    "short_answer": "{concept} í–¥ìƒì„ ìœ„í•œ í™œë™ì„ ì œì‹œí•˜ì‹œì˜¤.",
                    "essay": "{concept}ê³¼ ì¼ìƒìƒí™œ ì°¸ì—¬ì˜ ê´€ê³„ë¥¼ ë…¼ìˆ í•˜ì‹œì˜¤."
                }
            }
        else:
            # ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ ë³€í˜•
            return {
                "ê°„í˜¸í•™ê³¼": {
                    "multiple_choice": "ì„ìƒ í˜„ì¥ì—ì„œ {concept} ìƒí™©ì„ ë§ˆì£¼í–ˆì„ ë•Œ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•  ìš”ì†ŒëŠ”?",
                    "short_answer": "{concept}ì— ëŒ€í•œ ê·¼ê±°ê¸°ë°˜ ì ‘ê·¼ë²•ì„ êµ¬ì²´ì  ì‚¬ë¡€ì™€ í•¨ê»˜ ì„¤ëª…í•˜ì‹œì˜¤.",
                    "essay": "{concept}ì´ í™˜ì ì•ˆì „ê³¼ ì¹˜ë£Œ íš¨ê³¼ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë‹¤ê°ë„ë¡œ ë¶„ì„í•˜ì‹œì˜¤."
                },
                "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": {
                    "multiple_choice": "{concept} ì¹˜ë£Œ ê³„íš ìˆ˜ë¦½ ì‹œ ê°œë³„ í™˜ì íŠ¹ì„±ì— ë”°ë¥¸ ìµœì ì˜ ì ‘ê·¼ì€?",
                    "short_answer": "{concept}ì˜ ê¸°ëŠ¥ì  í‰ê°€ì™€ ì¹˜ë£Œ íš¨ê³¼ ì¸¡ì • ë°©ë²•ì„ ì œì‹œí•˜ì‹œì˜¤.",
                    "essay": "{concept} ì¬í™œ ê³¼ì •ì—ì„œì˜ ë‹¤í•™ì œ í˜‘ë ¥ê³¼ í™˜ì ì¤‘ì‹¬ ì ‘ê·¼ì„ ë…¼ìˆ í•˜ì‹œì˜¤."
                },
                "ì‘ì—…ì¹˜ë£Œí•™ê³¼": {
                    "multiple_choice": "{concept} ê°œì…ì—ì„œ ì˜ë¯¸ìˆëŠ” í™œë™ ì„ íƒì˜ í•µì‹¬ ì›ì¹™ì€?",
                    "short_answer": "{concept}ê³¼ ê´€ë ¨ëœ í™˜ê²½ì  ìš”ì¸ê³¼ ê°œì¸ì  ìš”ì¸ì˜ ìƒí˜¸ì‘ìš©ì„ ì„¤ëª…í•˜ì‹œì˜¤.",
                    "essay": "{concept}ì„ í†µí•œ ì¼ìƒìƒí™œ ì°¸ì—¬ ì¦ì§„ê³¼ ì‚¶ì˜ ì§ˆ í–¥ìƒ ì „ëµì„ ë…¼ìˆ í•˜ì‹œì˜¤."
                }
            }
    
    def _generate_multiple_choices_with_strategy(
        self, concept: str, department: str, strategy: Optional[Dict[str, Any]]
    ) -> Tuple[Dict[str, str], str]:
        """ì „ëµì— ë”°ë¥¸ ê°ê´€ì‹ ì„ íƒì§€ ìƒì„± (ì •ë‹µ ìœ„ì¹˜ ëœë¤í™”)"""
        
        # ì „ëµ ì ìš©ìœ¼ë¡œ ì„ íƒì§€ ë‹¤ì–‘í™”
        if strategy and strategy.get("diversification_level", 0) > 60:
            # ë” ì •êµí•˜ê³  ë‹¤ì–‘í•œ ì„ íƒì§€ ìƒì„±
            advanced_patterns = self._get_advanced_choice_patterns(department)
            dept_pattern = advanced_patterns.get(department, advanced_patterns["ê°„í˜¸í•™ê³¼"])
            
            correct_option = random.choice(dept_pattern["advanced_correct"]).format(concept=concept)
            incorrect_options = [opt.format(concept=concept) for opt in random.sample(dept_pattern["advanced_incorrect"], 3)]
            
            # ëª¨ë“  ì„ íƒì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ê¸°
            all_options = [correct_option] + incorrect_options
            
            # ì„ íƒì§€ ì„ê¸°
            random.shuffle(all_options)
            
            # ì •ë‹µì´ ìœ„ì¹˜í•œ ì¸ë±ìŠ¤ ì°¾ê¸°
            correct_index = all_options.index(correct_option)
            
            # ì„ íƒì§€ ë²ˆí˜¸ ë§¤í•‘
            choice_labels = ["1", "2", "3", "4"]
            choices = {}
            for i, option in enumerate(all_options):
                choices[choice_labels[i]] = option
            
            # ì •ë‹µ ë²ˆí˜¸ ê²°ì •
            correct_answer = choice_labels[correct_index]
            
            logger.info(f"ğŸ¯ ê³ ê¸‰ ì „ëµ ì •ë‹µ ë‹¤ì–‘í™”: '{concept}' ë¬¸ì œì˜ ì •ë‹µì´ {correct_answer}ë²ˆì— ë°°ì¹˜ë¨")
            
            return choices, correct_answer
        else:
            # ê¸°ë³¸ ì„ íƒì§€ ìƒì„± (ì´ë¯¸ ì •ë‹µ ìœ„ì¹˜ê°€ ëœë¤í™”ë¨)
            return self._generate_multiple_choices(concept, department)
    
    def _get_advanced_choice_patterns(self, department: str) -> Dict[str, Dict[str, List[str]]]:
        """ê³ ê¸‰ ì„ íƒì§€ íŒ¨í„´"""
        
        return {
            "ê°„í˜¸í•™ê³¼": {
                "advanced_correct": [
                    "{concept}ëŠ” í™˜ìì˜ ê°œë³„ì  íŠ¹ì„±ê³¼ ë¬¸í™”ì  ë°°ê²½ì„ ê³ ë ¤í•œ ì „ì¸ì  ì ‘ê·¼ì´ í•µì‹¬ì´ë‹¤",
                    "{concept} ì ìš© ì‹œ ìµœì‹  ê·¼ê±°ì™€ ì„ìƒ ê°€ì´ë“œë¼ì¸ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ë¹„íŒì  ì‚¬ê³ ê°€ í•„ìš”í•˜ë‹¤",
                    "{concept}ëŠ” ë‹¤í•™ì œíŒ€ í˜‘ë ¥ê³¼ ì§€ì†ì ì¸ ì§ˆ ê°œì„ ì„ í†µí•´ ìµœì í™”ë  ìˆ˜ ìˆë‹¤"
                ],
                "advanced_incorrect": [
                    "{concept}ëŠ” í‘œì¤€í™”ëœ í”„ë¡œí† ì½œë§Œ ì—„ê²©íˆ ë”°ë¥´ë©´ ì¶©ë¶„í•˜ë‹¤",
                    "{concept} ì ìš©ì—ì„œ í™˜ìì˜ ì£¼ê´€ì  ê²½í—˜ì€ ê°ê´€ì  ë°ì´í„°ë³´ë‹¤ ëœ ì¤‘ìš”í•˜ë‹¤",
                    "{concept}ëŠ” ì˜ë£Œì§„ ì¤‘ì‹¬ì˜ íš¨ìœ¨ì„±ì„ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•œë‹¤"
                ]
            },
            "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": {
                "advanced_correct": [
                    "{concept}ëŠ” í™˜ìì˜ ê¸°ëŠ¥ì  ëª©í‘œì™€ ìƒí™œ íŒ¨í„´ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ì ‘ê·¼ì´ í•„ìˆ˜ì ì´ë‹¤",
                    "{concept} ì¹˜ë£ŒëŠ” ì •ëŸ‰ì  í‰ê°€ì™€ ì •ì„±ì  ê´€ì°°ì„ ì¢…í•©í•œ í†µí•©ì  íŒë‹¨ì— ê¸°ë°˜í•´ì•¼ í•œë‹¤",
                    "{concept}ëŠ” í™˜ìì˜ ëŠ¥ë™ì  ì°¸ì—¬ì™€ ìê¸°íš¨ëŠ¥ê° ì¦ì§„ì„ í†µí•´ íš¨ê³¼ê°€ ê·¹ëŒ€í™”ëœë‹¤"
                ],
                "advanced_incorrect": [
                    "{concept}ëŠ” ì¹˜ë£Œì‚¬ì˜ ê²½í—˜ê³¼ ì§ê´€ì—ë§Œ ì˜ì¡´í•˜ì—¬ ì ìš©í•˜ëŠ” ê²ƒì´ ê°€ì¥ íš¨ê³¼ì ì´ë‹¤",
                    "{concept} ì¹˜ë£Œì—ì„œ í™˜ìì˜ í†µì¦ í˜¸ì†ŒëŠ” ì¹˜ë£Œ ì§„í–‰ì— ë°©í•´ê°€ ë˜ë¯€ë¡œ ë¬´ì‹œí•´ì•¼ í•œë‹¤",
                    "{concept}ëŠ” ë‹¨ê¸°ê°„ ì§‘ì¤‘ ì¹˜ë£Œë¡œë§Œ ì¶©ë¶„í•œ íš¨ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤"
                ]
            },
            "ì‘ì—…ì¹˜ë£Œí•™ê³¼": {
                "advanced_correct": [
                    "{concept}ëŠ” ê°œì¸ì˜ ê°€ì¹˜ì™€ í¥ë¯¸ë¥¼ ë°˜ì˜í•œ ì˜ë¯¸ìˆëŠ” í™œë™ì„ í†µí•´ êµ¬í˜„ë˜ì–´ì•¼ í•œë‹¤",
                    "{concept} ê°œì…ì€ í™˜ê²½ì  ë§¥ë½ê³¼ ì‚¬íšŒì  ì§€ì› ì²´ê³„ë¥¼ í†µí•©ì ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•œë‹¤",
                    "{concept}ëŠ” í´ë¼ì´ì–¸íŠ¸ì˜ ììœ¨ì„±ê³¼ ì„ íƒê¶Œì„ ì¡´ì¤‘í•˜ëŠ” í˜‘ë ¥ì  ê´€ê³„ì—ì„œ íš¨ê³¼ì ì´ë‹¤"
                ],
                "advanced_incorrect": [
                    "{concept}ëŠ” ì¹˜ë£Œì‚¬ê°€ ì •í•œ í™œë™ì„ í´ë¼ì´ì–¸íŠ¸ê°€ ìˆ˜ë™ì ìœ¼ë¡œ ë”°ë¥´ëŠ” ê²ƒì´ ìµœì„ ì´ë‹¤",
                    "{concept} ê°œì…ì—ì„œ ê°œì¸ì˜ ì„ í˜¸ë³´ë‹¤ëŠ” ê°ê´€ì  ê¸°ëŠ¥ í–¥ìƒë§Œì„ ëª©í‘œë¡œ í•´ì•¼ í•œë‹¤",
                    "{concept}ëŠ” ì¹˜ë£Œì‹¤ í™˜ê²½ì—ì„œë§Œ í›ˆë ¨í•˜ë©´ ì¼ìƒìƒí™œì— ìë™ìœ¼ë¡œ ì „ì´ëœë‹¤"
                ]
            }
        }
    
    def _strategic_shuffle(
        self, problems: List[Dict[str, Any]], strategy: Optional[Dict[str, Any]]
    ) -> None:
        """ì „ëµì  ë¬¸ì œ ì„ê¸°"""
        
        if not strategy:
            random.shuffle(problems)
            return
        
        diversification_level = strategy.get("diversification_level", 50)
        
        if diversification_level > 70:
            # ë†’ì€ ë‹¤ì–‘ì„±: ì¶œì²˜ë³„ë¡œ ê· ë“±í•˜ê²Œ ë¶„ì‚°
            kb_problems = [p for p in problems if p.get("source") == "knowledge_base"]
            ai_problems = [p for p in problems if p.get("source") == "ai_knowledge"]
            
            # êµëŒ€ë¡œ ë°°ì¹˜
            shuffled = []
            for i in range(max(len(kb_problems), len(ai_problems))):
                if i < len(kb_problems):
                    shuffled.append(kb_problems[i])
                if i < len(ai_problems):
                    shuffled.append(ai_problems[i])
            
            problems[:] = shuffled
        else:
            # ì¼ë°˜ì ì¸ ì…”í”Œ
            random.shuffle(problems)

    async def _generate_chatbot_explanation(
        self,
        problem: Dict[str, Any],
        department: str
    ) -> str:
        """AI ì±—ë´‡ ìŠ¤íƒ€ì¼ ìƒì„¸ í•´ì„¤ ìƒì„±"""
        
        question = problem["question"]
        correct_answer = problem["correct_answer"]
        main_concept = problem.get("main_concept", "í•µì‹¬ ê°œë…")
        difficulty = problem["difficulty"]
        question_type = problem["type"]
        
        # ì±—ë´‡ ìŠ¤íƒ€ì¼ í•´ì„¤ í…œí”Œë¦¿
        explanation_parts = []
        
        # 1. ì¸ì‚¬ ë° ë¬¸ì œ ë¶„ì„
        explanation_parts.append(f"ì•ˆë…•í•˜ì„¸ìš”! ì´ ë¬¸ì œì— ëŒ€í•´ ìƒì„¸íˆ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ğŸ˜Š")
        explanation_parts.append(f"\n**ğŸ“‹ ë¬¸ì œ ë¶„ì„**")
        explanation_parts.append(f"ì´ ë¬¸ì œëŠ” {department}ì˜ '{main_concept}' ì˜ì—­ì—ì„œ ì¶œì œëœ {self._get_difficulty_korean(difficulty)} ë¬¸ì œì…ë‹ˆë‹¤.")
        
        # 2. ë¬¸ì œ ì¶œì œ ì˜ë„
        explanation_parts.append(f"\n**ğŸ¯ ì¶œì œ ì˜ë„**")
        intent = await self._generate_question_intent(main_concept, department, question_type)
        explanation_parts.append(intent)
        
        # 3. ì •ë‹µ í•´ì„¤
        explanation_parts.append(f"\n**âœ… ì •ë‹µ í•´ì„¤**")
        if question_type == "multiple_choice":
            explanation_parts.append(f"ì •ë‹µ: **{correct_answer}**")
            explanation_parts.append(f"\n{await self._generate_correct_answer_explanation(question, correct_answer, main_concept, department)}")
            
            # ì˜¤ë‹µ í•´ì„¤
            if problem.get("choices"):
                explanation_parts.append(f"\n**âŒ ì˜¤ë‹µ ë¶„ì„**")
                wrong_analysis = await self._generate_wrong_answer_analysis(problem["choices"], correct_answer, main_concept, department)
                explanation_parts.append(wrong_analysis)
        else:
            explanation_parts.append(await self._generate_subjective_answer_guide(question, main_concept, department))
        
        # 4. í•µì‹¬ ê°œë… ì •ë¦¬
        explanation_parts.append(f"\n**ğŸ“š í•µì‹¬ ê°œë… ì •ë¦¬**")
        key_concepts = await self._generate_key_concepts_summary(main_concept, department)
        explanation_parts.append(key_concepts)
        
        # 5. ì‹¤ë¬´ ì ìš©
        explanation_parts.append(f"\n**ğŸ¥ ì‹¤ë¬´ ì ìš©**")
        practical_application = await self._generate_practical_application(main_concept, department)
        explanation_parts.append(practical_application)
        
        # 6. ì¶”ê°€ í•™ìŠµ ê°€ì´ë“œ
        explanation_parts.append(f"\n**ğŸ“– ì¶”ê°€ í•™ìŠµ ê°€ì´ë“œ**")
        study_guide = await self._generate_study_guide(main_concept, department)
        explanation_parts.append(study_guide)
        
        # 7. ë§ˆë¬´ë¦¬
        explanation_parts.append(f"\n**ğŸ’ª í•™ìŠµ íŒ**")
        explanation_parts.append(f"ì´ëŸ° ìœ í˜•ì˜ ë¬¸ì œë¥¼ ì˜ í’€ê¸° ìœ„í•´ì„œëŠ” {main_concept}ì˜ ê¸°ë³¸ ì›ë¦¬ë¥¼ í™•ì‹¤íˆ ì´í•´í•˜ê³ , ì‹¤ì œ ì‚¬ë¡€ì— ì ìš©í•´ë³´ëŠ” ì—°ìŠµì´ ì¤‘ìš”í•©ë‹ˆë‹¤!")
        explanation_parts.append(f"\nê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ì§ˆë¬¸í•´ ì£¼ì„¸ìš”! í™”ì´íŒ…! ğŸ“âœ¨")
        
        return "\n".join(explanation_parts)
    
    def _build_search_query(self, subject: str, keywords: Optional[str], department: str) -> str:
        """ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        query_parts = [subject]
        
        if keywords:
            query_parts.append(keywords)
        
        # í•™ê³¼ë³„ ì „ë¬¸ ìš©ì–´ ì¶”ê°€
        dept_concepts = self.department_concepts.get(department, {})
        if dept_concepts.get("core_concepts"):
            query_parts.extend(random.sample(dept_concepts["core_concepts"], min(2, len(dept_concepts["core_concepts"]))))
        
        return " ".join(query_parts)
    
    def _extract_concepts_from_text(self, text: str, dept_concepts: Dict[str, List[str]]) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í•™ê³¼ë³„ ê°œë… ì¶”ì¶œ"""
        found_concepts = []
        
        for category, concepts in dept_concepts.items():
            for concept in concepts:
                if concept in text:
                    found_concepts.append(concept)
        
        # ì°¾ì€ ê°œë…ì´ ì—†ìœ¼ë©´ ëœë¤ ì„ íƒ
        if not found_concepts:
            all_concepts = []
            for concepts in dept_concepts.values():
                all_concepts.extend(concepts)
            found_concepts = random.sample(all_concepts, min(3, len(all_concepts)))
        
        return found_concepts[:5]  # ìµœëŒ€ 5ê°œ
    
    def _create_multiple_choice_from_doc(
        self, doc_content: str, concept: str, department: str
    ) -> Tuple[str, Dict[str, str], str]:
        """ë¬¸ì„œ ê¸°ë°˜ ê°ê´€ì‹ ë¬¸ì œ ìƒì„±"""
        
        question_text = f"ë‹¤ìŒ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ {concept}ì— ëŒ€í•œ ì„¤ëª…ìœ¼ë¡œ ê°€ì¥ ì ì ˆí•œ ê²ƒì€?\n\n[ìë£Œ] {doc_content[:100]}..."
        
        choices, correct_answer = self._generate_multiple_choices(concept, department)
        
        return question_text, choices, correct_answer
    
    def _generate_multiple_choices(self, concept: str, department: str) -> Tuple[Dict[str, str], str]:
        """ê°ê´€ì‹ ì„ íƒì§€ ìƒì„± (ì •ë‹µ ìœ„ì¹˜ ëœë¤í™”)"""
        
        # í•™ê³¼ë³„ ì •ë‹µ/ì˜¤ë‹µ íŒ¨í„´
        dept_patterns = {
            "ê°„í˜¸í•™ê³¼": {
                "correct": [
                    f"{concept}ëŠ” í™˜ì ì•ˆì „ì„ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ì‹œí–‰í•œë‹¤",
                    f"{concept} ì‹œ ê·¼ê±°ê¸°ë°˜ ì‹¤ë¬´ë¥¼ ì ìš©í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ ì ‘ê·¼í•œë‹¤",
                    f"{concept}ëŠ” ê°œë³„ í™˜ìì˜ íŠ¹ì„±ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ì ‘ê·¼ì´ í•„ìš”í•˜ë‹¤",
                    f"{concept}ì—ì„œëŠ” ì „ì¸ì  ê°„í˜¸ ê´€ì ì„ ì ìš©í•œ ì²´ê³„ì  ì ‘ê·¼ì´ í•„ìš”í•˜ë‹¤",
                    f"{concept} ìˆ˜í–‰ ì‹œ í™˜ìì˜ ììœ¨ì„±ê³¼ ì¡´ì—„ì„±ì„ ì¡´ì¤‘í•´ì•¼ í•œë‹¤"
                ],
                "incorrect": [
                    f"{concept}ëŠ” íšì¼ì ì¸ ë°©ë²•ìœ¼ë¡œ ëª¨ë“  í™˜ìì—ê²Œ ë™ì¼í•˜ê²Œ ì ìš©í•œë‹¤",
                    f"{concept} ì‹œ í™˜ìì˜ ì£¼ê´€ì  í˜¸ì†ŒëŠ” ì¤‘ìš”í•˜ì§€ ì•Šë‹¤",
                    f"{concept}ëŠ” ì˜ë£Œì§„ì˜ í¸ì˜ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•œë‹¤",
                    f"{concept}ì—ì„œëŠ” í‘œì¤€í™”ëœ í”„ë¡œí† ì½œë§Œ ì¤€ìˆ˜í•˜ë©´ ì¶©ë¶„í•˜ë‹¤",
                    f"{concept} ì‹œ ë¹„ìš© íš¨ìœ¨ì„±ì´ í™˜ì ì•ˆì „ë³´ë‹¤ ìš°ì„ ì‹œë˜ì–´ì•¼ í•œë‹¤",
                    f"{concept}ëŠ” ì˜ë£Œì§„ì˜ ê²½í—˜ì—ë§Œ ì˜ì¡´í•˜ì—¬ ìˆ˜í–‰í•œë‹¤"
                ]
            },
            "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": {
                "correct": [
                    f"{concept}ëŠ” ê°œë³„ í™˜ìì˜ ê¸°ëŠ¥ì  ëª©í‘œì— ë§ì¶˜ ì¹˜ë£Œ ê³„íšì´ í•„ìš”í•˜ë‹¤",
                    f"{concept} ì¹˜ë£Œ ì‹œ ê·¼ê±°ì¤‘ì‹¬ì˜ í‰ê°€ë¥¼ í†µí•´ ì ì ˆí•œ ì¤‘ì¬ë¥¼ ì„ íƒí•œë‹¤",
                    f"{concept}ëŠ” ì ì§„ì ì´ê³  ì²´ê³„ì ì¸ ì ‘ê·¼ì„ í†µí•´ ê¸°ëŠ¥ í–¥ìƒì„ ë„ëª¨í•œë‹¤",
                    f"{concept}ì—ì„œëŠ” í™˜ìì˜ ê¸°ëŠ¥ì  ë…ë¦½ì„± í–¥ìƒì„ ìµœìš°ì„  ëª©í‘œë¡œ í•œë‹¤",
                    f"{concept} ì ìš© ì‹œ ìƒì²´ì—­í•™ì  ì›ë¦¬ì™€ ìš´ë™í•™ìŠµ ì´ë¡ ì„ ê³ ë ¤í•œë‹¤"
                ],
                "incorrect": [
                    f"{concept}ëŠ” ëª¨ë“  í™˜ìì—ê²Œ ë™ì¼í•œ ì¹˜ë£Œ í”„ë¡œí† ì½œì„ ì ìš©í•œë‹¤",
                    f"{concept} ì¹˜ë£ŒëŠ” ì¦ìƒ ì™„í™”ì—ë§Œ ì§‘ì¤‘í•˜ë©´ ì¶©ë¶„í•˜ë‹¤",
                    f"{concept}ëŠ” í™˜ìì˜ í˜‘ì¡° ì—†ì´ë„ ì¹˜ë£Œ íš¨ê³¼ë¥¼ ê¸°ëŒ€í•  ìˆ˜ ìˆë‹¤",
                    f"{concept}ì—ì„œëŠ” ì¹˜ë£Œì‚¬ì˜ ì§ê°ì—ë§Œ ì˜ì¡´í•˜ì—¬ ì¤‘ì¬ë¥¼ ì„ íƒí•œë‹¤",
                    f"{concept} ì‹œ í†µì¦ ì™„í™”ë³´ë‹¤ëŠ” ìš´ë™ëŸ‰ ì¦ê°€ê°€ ë” ì¤‘ìš”í•˜ë‹¤",
                    f"{concept}ëŠ” ì¥ê¸°ì  ëª©í‘œë³´ë‹¤ëŠ” ì¦‰ê°ì  íš¨ê³¼ë§Œ ì¶”êµ¬í•œë‹¤"
                ]
            },
            "ì‘ì—…ì¹˜ë£Œí•™ê³¼": {
                "correct": [
                    f"{concept}ëŠ” ì˜ë¯¸ìˆëŠ” í™œë™ì„ í†µí•´ ê¸°ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤",
                    f"{concept} ê°œì… ì‹œ í™˜ê²½ì  ìš”ì¸ì„ ê³ ë ¤í•œ í†µí•©ì  ì ‘ê·¼ì´ í•„ìš”í•˜ë‹¤",
                    f"{concept}ëŠ” ì¼ìƒìƒí™œ ì°¸ì—¬ë¥¼ ìµœëŒ€í™”í•˜ëŠ” ëª©í‘œ ì„¤ì •ì´ ì¤‘ìš”í•˜ë‹¤",
                    f"{concept}ì—ì„œëŠ” ê°œì¸ì˜ ê°€ì¹˜ì™€ í¥ë¯¸ë¥¼ ë°˜ì˜í•œ í™œë™ ì„ íƒì´ í•„ìˆ˜ì ì´ë‹¤",
                    f"{concept} ì ìš© ì‹œ ì‘ì—…ìˆ˜í–‰ì˜ ë§¥ë½ì  ìš”ì†Œë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•œë‹¤"
                ],
                "incorrect": [
                    f"{concept}ëŠ” ë‹¨ìˆœ ë°˜ë³µ í›ˆë ¨ë§Œìœ¼ë¡œ ì¶©ë¶„í•œ íš¨ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤",
                    f"{concept} ì¹˜ë£Œì—ì„œ ê°œì¸ì˜ í¥ë¯¸ë‚˜ ê°€ì¹˜ëŠ” ê³ ë ¤í•  í•„ìš”ê°€ ì—†ë‹¤",
                    f"{concept}ëŠ” ê¸°ëŠ¥ í–¥ìƒë³´ë‹¤ëŠ” ì¦ìƒ ì™„í™”ê°€ ìš°ì„ ì´ë‹¤",
                    f"{concept}ì—ì„œëŠ” í‘œì¤€í™”ëœ í™œë™ë§Œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ íš¨ê³¼ì ì´ë‹¤",
                    f"{concept} ì‹œ í™˜ê²½ì  ì œì•½ì€ ì¹˜ë£Œ ê³¼ì •ì—ì„œ ë°°ì œí•´ì•¼ í•œë‹¤",
                    f"{concept}ëŠ” ì¹˜ë£Œì‹¤ ë‚´ì—ì„œë§Œ ì´ë£¨ì–´ì§€ë©´ ì¶©ë¶„í•˜ë‹¤"
                ]
            }
        }
        
        dept_pattern = dept_patterns.get(department, dept_patterns["ê°„í˜¸í•™ê³¼"])
        
        # ì •ë‹µê³¼ ì˜¤ë‹µ ì„ íƒ
        correct_option = random.choice(dept_pattern["correct"])
        incorrect_options = random.sample(dept_pattern["incorrect"], 3)
        
        # ëª¨ë“  ì„ íƒì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ê¸°
        all_options = [correct_option] + incorrect_options
        
        # ì„ íƒì§€ ì„ê¸°
        random.shuffle(all_options)
        
        # ì •ë‹µì´ ìœ„ì¹˜í•œ ì¸ë±ìŠ¤ ì°¾ê¸°
        correct_index = all_options.index(correct_option)
        
        # ì„ íƒì§€ ë²ˆí˜¸ ë§¤í•‘
        choice_labels = ["1", "2", "3", "4"]
        choices = {}
        for i, option in enumerate(all_options):
            choices[choice_labels[i]] = option
        
        # ì •ë‹µ ë²ˆí˜¸ ê²°ì •
        correct_answer = choice_labels[correct_index]
        
        logger.info(f"ğŸ¯ ì •ë‹µ ë‹¤ì–‘í™”: '{concept}' ë¬¸ì œì˜ ì •ë‹µì´ {correct_answer}ë²ˆì— ë°°ì¹˜ë¨")
        
        return choices, correct_answer
    
    def _get_difficulty_korean(self, difficulty: str) -> str:
        """ë‚œì´ë„ í•œê¸€ ë³€í™˜"""
        mapping = {
            "easy": "ì‰¬ìš´",
            "medium": "ë³´í†µ",
            "hard": "ì–´ë ¤ìš´"
        }
        return mapping.get(difficulty, "ë³´í†µ")
    
    async def _generate_question_intent(self, concept: str, department: str, question_type: str) -> str:
        """ë¬¸ì œ ì¶œì œ ì˜ë„ ìƒì„±"""
        
        type_intents = {
            "multiple_choice": "ê°ê´€ì  ì§€ì‹ì˜ ì •í™•í•œ ì´í•´ì™€ ì ìš© ëŠ¥ë ¥ì„ í‰ê°€",
            "short_answer": "í•µì‹¬ ê°œë…ì— ëŒ€í•œ ì²´ê³„ì  ì´í•´ì™€ ì„¤ëª… ëŠ¥ë ¥ì„ í‰ê°€",
            "essay": "ì¢…í•©ì  ì‚¬ê³ ë ¥ê³¼ ë…¼ë¦¬ì  ì„œìˆ  ëŠ¥ë ¥ì„ í‰ê°€",
            "true_false": "ê¸°ë³¸ ê°œë…ì— ëŒ€í•œ ëª…í™•í•œ ì´í•´ë¥¼ í‰ê°€"
        }
        
        dept_focuses = {
            "ê°„í˜¸í•™ê³¼": "ì„ìƒ ìƒí™©ì—ì„œì˜ ì „ë¬¸ì  íŒë‹¨ë ¥ê³¼ ê·¼ê±°ê¸°ë°˜ ê°„í˜¸ì‹¤ë¬´ ëŠ¥ë ¥",
            "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": "ê¸°ëŠ¥ì  í‰ê°€ì™€ ì¹˜ë£Œì  ì¤‘ì¬ ì„ íƒ ëŠ¥ë ¥",
            "ì‘ì—…ì¹˜ë£Œí•™ê³¼": "ì‘ì—…ìˆ˜í–‰ê³¼ ì¼ìƒìƒí™œ ì°¸ì—¬ í–¥ìƒì„ ìœ„í•œ ì „ë¬¸ì  ì ‘ê·¼ ëŠ¥ë ¥"
        }
        
        intent = f"ì´ ë¬¸ì œëŠ” '{concept}'ì— ëŒ€í•œ {type_intents.get(question_type, 'ì´í•´')}ì„ ëª©ì ìœ¼ë¡œ í•©ë‹ˆë‹¤.\n"
        intent += f"íŠ¹íˆ {department}ì˜ í•µì‹¬ ì—­ëŸ‰ì¸ {dept_focuses.get(department, 'ì „ë¬¸ì  ì§€ì‹')}ì„ í™•ì¸í•˜ê³ ì ì¶œì œë˜ì—ˆìŠµë‹ˆë‹¤."
        
        return intent
    
    async def _generate_correct_answer_explanation(self, question: str, correct_answer: str, concept: str, department: str) -> str:
        """ì •ë‹µ í•´ì„¤ ìƒì„±"""
        
        explanations = {
            "ê°„í˜¸í•™ê³¼": f"ì´ ë‹µì´ ì •ë‹µì¸ ì´ìœ ëŠ” '{concept}'ì˜ ê°„í˜¸í•™ì  ì ‘ê·¼ì—ì„œ í™˜ì ì¤‘ì‹¬ì˜ ì „ì¸ì  ì¼€ì–´ë¥¼ ê°•ì¡°í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ê·¼ê±°ê¸°ë°˜ ì‹¤ë¬´ì™€ í™˜ì ì•ˆì „ì´ í•µì‹¬ ì›ì¹™ìœ¼ë¡œ ì‘ìš©í•©ë‹ˆë‹¤.",
            "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": f"ì´ ë‹µì´ ì •ë‹µì¸ ì´ìœ ëŠ” '{concept}'ì˜ ë¬¼ë¦¬ì¹˜ë£Œì  ì ‘ê·¼ì—ì„œ ê°œë³„í™”ëœ í‰ê°€ì™€ ê¸°ëŠ¥ ì¤‘ì‹¬ì˜ ì¹˜ë£Œê°€ ì¤‘ìš”í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ê·¼ê±°ì¤‘ì‹¬ì˜ ì¹˜ë£Œì™€ ì ì§„ì  ì ‘ê·¼ì´ í•µì‹¬ì…ë‹ˆë‹¤.",
            "ì‘ì—…ì¹˜ë£Œí•™ê³¼": f"ì´ ë‹µì´ ì •ë‹µì¸ ì´ìœ ëŠ” '{concept}'ì˜ ì‘ì—…ì¹˜ë£Œì  ì ‘ê·¼ì—ì„œ ì˜ë¯¸ìˆëŠ” í™œë™ê³¼ í™˜ê²½ì  ë§¥ë½ì„ ê³ ë ¤í•œ í†µí•©ì  ê°œì…ì´ ì¤‘ìš”í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤."
        }
        
        return explanations.get(department, f"'{concept}'ì— ëŒ€í•œ ì „ë¬¸ì  ì´í•´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì ì ˆí•œ ë‹µë³€ì…ë‹ˆë‹¤.")
    
    async def _generate_wrong_answer_analysis(self, choices: Dict[str, str], correct_answer: str, concept: str, department: str) -> str:
        """ì˜¤ë‹µ ë¶„ì„ ìƒì„±"""
        
        analysis = []
        for key, choice in choices.items():
            if key != correct_answer:
                analysis.append(f"**{key}ë²ˆ**: {choice}")
                analysis.append(f"â†’ ì´ ì„ íƒì§€ê°€ í‹€ë¦° ì´ìœ : {concept}ì˜ ê¸°ë³¸ ì›ì¹™ì— ë¶€í•©í•˜ì§€ ì•Šìœ¼ë©°, {department}ì˜ ì „ë¬¸ì  ì ‘ê·¼ë²•ê³¼ ìƒë°˜ë©ë‹ˆë‹¤.\n")
        
        return "\n".join(analysis)
    
    async def _generate_subjective_answer_guide(self, question: str, concept: str, department: str) -> str:
        """ì£¼ê´€ì‹ ë‹µì•ˆ ê°€ì´ë“œ ìƒì„±"""
        
        guides = {
            "ê°„nursing": f"'{concept}'ì— ëŒ€í•´ ë‹µí•  ë•ŒëŠ” ë‹¤ìŒ ìš”ì†Œë“¤ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:\nâ€¢ ì •ì˜ì™€ íŠ¹ì„±\nâ€¢ ê°„í˜¸í•™ì  ì¤‘ìš”ì„±\nâ€¢ ì‹¤ë¬´ ì ìš© ë°©ì•ˆ\nâ€¢ í™˜ì ì•ˆì „ê³¼ì˜ ì—°ê´€ì„±",
            "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": f"'{concept}'ì— ëŒ€í•´ ë‹µí•  ë•ŒëŠ” ë‹¤ìŒ ìš”ì†Œë“¤ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:\nâ€¢ í•´ë¶€í•™ì /ìƒë¦¬í•™ì  ê¸°ì´ˆ\nâ€¢ í‰ê°€ ë°©ë²•\nâ€¢ ì¹˜ë£Œì  ì ‘ê·¼ë²•\nâ€¢ ê¸°ëŠ¥ì  ëª©í‘œ",
            "ì‘ì—…ì¹˜ë£Œí•™ê³¼": f"'{concept}'ì— ëŒ€í•´ ë‹µí•  ë•ŒëŠ” ë‹¤ìŒ ìš”ì†Œë“¤ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:\nâ€¢ ì‘ì—…ìˆ˜í–‰ì— ë¯¸ì¹˜ëŠ” ì˜í–¥\nâ€¢ í‰ê°€ ë„êµ¬ì™€ ë°©ë²•\nâ€¢ ì¤‘ì¬ ì „ëµ\nâ€¢ ì¼ìƒìƒí™œê³¼ì˜ ì—°ê´€ì„±"
        }
        
        return guides.get(department, f"'{concept}'ì— ëŒ€í•œ ì „ë¬¸ì ì´ê³  ì²´ê³„ì ì¸ ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    
    async def _generate_key_concepts_summary(self, concept: str, department: str) -> str:
        """í•µì‹¬ ê°œë… ì •ë¦¬"""
        
        summaries = {
            "ê°„í˜¸í•™ê³¼": f"**{concept}ì˜ ê°„í˜¸í•™ì  í•µì‹¬:**\nâ€¢ í™˜ì ì¤‘ì‹¬ ì ‘ê·¼\nâ€¢ ê·¼ê±°ê¸°ë°˜ ì‹¤ë¬´\nâ€¢ ì „ì¸ì  ì¼€ì–´\nâ€¢ ì•ˆì „í•œ ê°„í˜¸ ì œê³µ\nâ€¢ ì§€ì†ì  í‰ê°€ì™€ ê°œì„ ",
            "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": f"**{concept}ì˜ ë¬¼ë¦¬ì¹˜ë£Œí•™ì  í•µì‹¬:**\nâ€¢ ê¸°ëŠ¥ ì¤‘ì‹¬ í‰ê°€\nâ€¢ ê°œë³„í™”ëœ ì¹˜ë£Œ\nâ€¢ ì ì§„ì  ì ‘ê·¼\nâ€¢ ê·¼ê±°ì¤‘ì‹¬ ì¹˜ë£Œ\nâ€¢ ê¸°ëŠ¥ì  ëª©í‘œ ë‹¬ì„±",
            "ì‘ì—…ì¹˜ë£Œí•™ê³¼": f"**{concept}ì˜ ì‘ì—…ì¹˜ë£Œí•™ì  í•µì‹¬:**\nâ€¢ ì˜ë¯¸ìˆëŠ” í™œë™\nâ€¢ í™˜ê²½ì  ê³ ë ¤\nâ€¢ ì°¸ì—¬ ì¤‘ì‹¬ ì ‘ê·¼\nâ€¢ ê°œë³„ì  ëª©í‘œ\nâ€¢ í†µí•©ì  ê°œì…"
        }
        
        return summaries.get(department, f"**{concept}ì˜ í•µì‹¬ ìš”ì†Œë“¤**")
    
    async def _generate_practical_application(self, concept: str, department: str) -> str:
        """ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ"""
        
        applications = {
            "ê°„í˜¸í•™ê³¼": f"**ì„ìƒ í˜„ì¥ì—ì„œ {concept} ì ìš© ì‹œ:**\nâ€¢ í™˜ì ìƒíƒœ ì§€ì† ëª¨ë‹ˆí„°ë§\nâ€¢ ë‹¤í•™ì œíŒ€ê³¼ì˜ í˜‘ë ¥\nâ€¢ ê°€ì¡± êµìœ¡ ë° ì§€ì§€\nâ€¢ ê°ì—¼ê´€ë¦¬ ì›ì¹™ ì¤€ìˆ˜\nâ€¢ ë¬¸ì„œí™” ë° ë³´ê³ ì²´ê³„ í™œìš©",
            "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": f"**ì¹˜ë£Œ í˜„ì¥ì—ì„œ {concept} ì ìš© ì‹œ:**\nâ€¢ ì²´ê³„ì  í‰ê°€ ì‹¤ì‹œ\nâ€¢ ê°œë³„ ì¹˜ë£Œ ê³„íš ìˆ˜ë¦½\nâ€¢ ì§„í–‰ìƒí™© ì§€ì†ì  ëª¨ë‹ˆí„°ë§\nâ€¢ í™˜ì êµìœ¡ ë° í™ˆí”„ë¡œê·¸ë¨ ì œê³µ\nâ€¢ ë‹¤í•™ì œíŒ€ê³¼ì˜ ì˜ì‚¬ì†Œí†µ",
            "ì‘ì—…ì¹˜ë£Œí•™ê³¼": f"**ì‘ì—…ì¹˜ë£Œ í˜„ì¥ì—ì„œ {concept} ì ìš© ì‹œ:**\nâ€¢ ì‘ì—… ë¶„ì„ ë° í™˜ê²½ í‰ê°€\nâ€¢ ì˜ë¯¸ìˆëŠ” í™œë™ ì„ ì •\nâ€¢ ë³´ì¡°ê¸°êµ¬ ë° í™˜ê²½ ìˆ˜ì •\nâ€¢ ê°€ì¡± ë° ëŒë´„ì êµìœ¡\nâ€¢ ì§€ì—­ì‚¬íšŒ ìì› ì—°ê³„"
        }
        
        return applications.get(department, f"**{concept}ì˜ ì‹¤ë¬´ ì ìš© ë°©ì•ˆ**")
    
    async def _generate_study_guide(self, concept: str, department: str) -> str:
        """ì¶”ê°€ í•™ìŠµ ê°€ì´ë“œ"""
        
        guides = {
            "ê°„í˜¸í•™ê³¼": f"**{concept} ì¶”ê°€ í•™ìŠµ ë°©í–¥:**\nâ€¢ ê´€ë ¨ ê°„í˜¸ì§„ë‹¨ ë° ì¤‘ì¬ ì—°ê²°\nâ€¢ ìµœì‹  ì—°êµ¬ ë…¼ë¬¸ ë° ê°€ì´ë“œë¼ì¸ ê²€í† \nâ€¢ ì‹œë®¬ë ˆì´ì…˜ ë° ì‚¬ë¡€ ì—°êµ¬\nâ€¢ ìœ¤ë¦¬ì  ê³ ë ¤ì‚¬í•­ í•™ìŠµ",
            "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": f"**{concept} ì¶”ê°€ í•™ìŠµ ë°©í–¥:**\nâ€¢ ê´€ë ¨ í•´ë¶€í•™/ìƒë¦¬í•™ ë³µìŠµ\nâ€¢ ìµœì‹  ì¹˜ë£Œ ê¸°ë²• ë° ì—°êµ¬ ë™í–¥\nâ€¢ í‰ê°€ ë„êµ¬ ì‹¤ìŠµ\nâ€¢ ì‚¬ë¡€ ê¸°ë°˜ í•™ìŠµ",
            "ì‘ì—…ì¹˜ë£Œí•™ê³¼": f"**{concept} ì¶”ê°€ í•™ìŠµ ë°©í–¥:**\nâ€¢ ì‘ì—…ê³¼í•™ ì´ë¡ ì  ë°°ê²½\nâ€¢ í‰ê°€ ë„êµ¬ í™œìš©ë²•\nâ€¢ ë‹¤ì–‘í•œ ì¤‘ì¬ ê¸°ë²•\nâ€¢ ì§€ì—­ì‚¬íšŒ ê¸°ë°˜ ì„œë¹„ìŠ¤ ì´í•´"
        }
        
        return guides.get(department, f"**{concept}ì— ëŒ€í•œ ì‹¬í™” í•™ìŠµ ê¶Œì¥ì‚¬í•­**")


# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
enhanced_generator = EnhancedProblemGenerator()