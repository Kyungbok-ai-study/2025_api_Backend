"""
AI í•™ìŠµ ê¸°ë°˜ ë¬¸ì œ ìƒì„± ì„œë¹„ìŠ¤ (ì¤‘ë³µ ë°©ì§€ í¬í•¨)
"""
import json
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
from pathlib import Path
from sqlalchemy.orm import Session
from .duplicate_prevention_service import duplicate_prevention_service
from .problem_generation_tracker import generation_tracker

logger = logging.getLogger(__name__)

class EnhancedProblemGenerator:
    """AI í•™ìŠµ ê¸°ë°˜ ê°•í™”ëœ ë¬¸ì œ ìƒì„± ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.learning_data = self._load_learning_data()
        
    def _load_learning_data(self) -> Dict[str, Any]:
        """í•™ìŠµ ë°ì´í„° ë¡œë“œ"""
        try:
            data_path = Path("data")
            learning_data = {}
            
            # ê°•í™” ë¶„ì„ ë°ì´í„° ë¡œë“œ
            for dept, file_name in [
                ("ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼", "enhanced_evaluator_analysis.json"),
                ("ì‘ì—…ì¹˜ë£Œí•™ê³¼", "enhanced_evaluator_analysis_ot.json")
            ]:
                file_path = data_path / file_name
                if file_path.exists():
                    with open(file_path, 'r', encoding='utf-8') as f:
                        learning_data[dept] = json.load(f)
            
            logger.info(f"ğŸ¤– AI í•™ìŠµ ë°ì´í„° ë¡œë“œ: {len(learning_data)}ê°œ í•™ê³¼")
            return learning_data
        except Exception as e:
            logger.error(f"í•™ìŠµ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}
    
    async def generate_unique_problems(
        self,
        db: Session,
        user_id: int,
        department: str,
        subject: str,
        difficulty: str,
        question_type: str = "multiple_choice",
        count: int = 5,
        keywords: Optional[str] = None
    ) -> Dict[str, Any]:
        """ì¤‘ë³µ ì—†ëŠ” ë¬¸ì œ ìƒì„±"""
        
        logger.info(f"ğŸš€ AI ê¸°ë°˜ ë¬¸ì œ ìƒì„±: {department} {subject}")
        
        try:
            # 1. ìƒì„± ì „ëµ ìˆ˜ë¦½
            strategy = await generation_tracker.get_next_generation_strategy(
                db, user_id, subject, difficulty, question_type, keywords, count
            )
            
            # 2. AI í•™ìŠµ íŒ¨í„´ ë¶„ì„
            learned_patterns = self._analyze_learned_patterns(department, difficulty)
            
            # 3. ì¤‘ë³µ ë°©ì§€ ê°€ì´ë“œ ìƒì„±
            uniqueness_guide = await duplicate_prevention_service.generate_unique_question_guidance(
                db, subject, difficulty, department, strategy.get("target_keywords", [])
            )
            
            # 4. í†µí•© ê°€ì´ë“œ ìƒì„±
            generation_guide = {
                **strategy,
                "ai_patterns": learned_patterns,
                "uniqueness_guide": uniqueness_guide,
                "department": department
            }
            
            # 5. ìƒ˜í”Œ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ë° ê²€ì¦
            scenarios = await self._create_and_validate_scenarios(
                db, generation_guide, count, department
            )
            
            # 6. ê²°ê³¼ ë°˜í™˜
            return {
                "success": True,
                "department": department,
                "total_scenarios": len(scenarios),
                "unique_scenarios": len([s for s in scenarios if s.get("is_unique", False)]),
                "scenarios": scenarios,
                "ai_learning_applied": True,
                "session_id": generation_guide.get("session_id")
            }
            
        except Exception as e:
            logger.error(f"ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def _analyze_learned_patterns(self, department: str, difficulty: str) -> Dict[str, Any]:
        """í•™ìŠµëœ íŒ¨í„´ ë¶„ì„"""
        
        dept_data = self.learning_data.get(department, {})
        if not dept_data:
            return {"patterns": [], "insights": []}
        
        patterns = {"difficulty_distribution": {}, "areas": {}}
        
        # ì—°ë„ë³„ ë°ì´í„°ì—ì„œ íŒ¨í„´ ì¶”ì¶œ
        for year, year_data in dept_data.items():
            if year.isdigit():
                for q_data in year_data.values():
                    if isinstance(q_data, dict):
                        q_diff = q_data.get("consensus_difficulty", "ì¤‘")
                        patterns["difficulty_distribution"][q_diff] = \
                            patterns["difficulty_distribution"].get(q_diff, 0) + 1
                        
                        area = q_data.get("primary_area", "ì¼ë°˜")
                        patterns["areas"][area] = patterns["areas"].get(area, 0) + 1
        
        return {
            "patterns": patterns,
            "target_difficulty_ratio": patterns["difficulty_distribution"].get(difficulty, 0),
            "recommended_areas": list(patterns["areas"].keys())[:5]
        }
    
    async def _create_and_validate_scenarios(
        self, db: Session, guide: Dict[str, Any], count: int, department: str
    ) -> List[Dict[str, Any]]:
        """ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ë° ê²€ì¦"""
        
        scenarios = []
        ai_areas = guide.get("ai_patterns", {}).get("recommended_areas", [])
        keywords = guide.get("target_keywords", [])
        
        for i in range(count):
            # í‚¤ì›Œë“œ ì„ íƒ
            if i < len(ai_areas):
                primary_concept = ai_areas[i]
            elif i < len(keywords):
                primary_concept = keywords[i]
        else:
                primary_concept = f"í†µí•©ê°œë…_{i}"
            
            # ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
            scenario = {
                "id": f"scenario_{i+1}",
                "primary_concept": primary_concept,
                "content": f"[{department}] {primary_concept} ê´€ë ¨ ë¬¸ì œ",
                "ai_enhanced": True
            }
            
            # ì¤‘ë³µ ê²€ì‚¬
            duplicate_check = await duplicate_prevention_service.check_duplicate_against_national_exams(
                db, scenario["content"], department
            )
            
            scenario["is_unique"] = not duplicate_check.is_duplicate
            scenario["similarity_score"] = duplicate_check.similarity_score
            scenario["duplicate_reason"] = duplicate_check.reason
            
            scenarios.append(scenario)
        
        return scenarios

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
enhanced_problem_generator = EnhancedProblemGenerator()