"""
ë‚œì´ë„ ë° ë¶„ì•¼ ìë™ ë§¤í•‘ ì‹œìŠ¤í…œ
êµìˆ˜ë‹˜ë“¤ì˜ í‰ê°€ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ìƒˆë¡œìš´ ë¬¸ì œì˜ ë‚œì´ë„ì™€ ë¶„ì•¼ë¥¼ ìë™ ë¶„ë¥˜
"""
import os
import json
import pandas as pd
import logging
from typing import Dict, List, Tuple, Optional
from pathlib import Path
from datetime import datetime
import asyncio
import google.generativeai as genai
from openai import AsyncOpenAI

logger = logging.getLogger(__name__)

class DifficultyDomainMapper:
    """
    ë‚œì´ë„ ë° ë¶„ì•¼ ìë™ ë§¤í•‘ ì‹œìŠ¤í…œ
    
    ê¸°ëŠ¥:
    1. êµìˆ˜ë‹˜ë“¤ì˜ í‰ê°€ ë°ì´í„° í•™ìŠµ
    2. ìƒˆë¡œìš´ ë¬¸ì œì˜ ë‚œì´ë„/ë¶„ì•¼ ìë™ ë¶„ë¥˜
    3. í•™ê³¼ë³„ íŠ¹ì„±í™”ëœ ë¶„ë¥˜ ëª¨ë¸
    4. ìƒìš©í™”ë¥¼ ìœ„í•œ ë™ì  í™•ì¥ ì§€ì›
    """
    
    def __init__(self):
        self.training_data = {}  # í•™ê³¼ë³„ í•™ìŠµ ë°ì´í„°
        self.domain_keywords = {}  # í•™ê³¼ë³„ ë¶„ì•¼ í‚¤ì›Œë“œ
        self.difficulty_patterns = {}  # í•™ê³¼ë³„ ë‚œì´ë„ íŒ¨í„´
        self.professor_weights = {}  # êµìˆ˜ë³„ ê°€ì¤‘ì¹˜
        
        # API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.openai_client = None
        self.gemini_model = None
        self._init_ai_clients()
    
    def _init_ai_clients(self):
        """AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            # OpenAI í´ë¼ì´ì–¸íŠ¸
            openai_api_key = os.getenv("OPENAI_API_KEY")
            if openai_api_key:
                self.openai_client = AsyncOpenAI(api_key=openai_api_key)
            
            # Gemini í´ë¼ì´ì–¸íŠ¸
            gemini_api_key = os.getenv("GEMINI_API_KEY")
            if gemini_api_key:
                genai.configure(api_key=gemini_api_key)
                self.gemini_model = genai.GenerativeModel('gemini-pro')
                
        except Exception as e:
            logger.error(f"AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    async def load_professor_evaluation_data(self, data_path: str = "data/í‰ê°€ìœ„ì› ìˆ˜í–‰ê²°ê³¼"):
        """
        êµìˆ˜ë‹˜ë“¤ì˜ í‰ê°€ ë°ì´í„° ë¡œë“œ ë° í•™ìŠµ
        
        Args:
            data_path: í‰ê°€ ë°ì´í„° ê²½ë¡œ
        """
        logger.info("ğŸ“ êµìˆ˜ë‹˜ë“¤ì˜ í‰ê°€ ë°ì´í„° í•™ìŠµ ì‹œì‘")
        
        try:
            base_path = Path(data_path)
            
            # í•™ê³¼ë³„ ë°ì´í„° ì²˜ë¦¬
            for department_dir in base_path.iterdir():
                if department_dir.is_dir():
                    department = self._extract_department_name(department_dir.name)
                    logger.info(f"ğŸ“š {department} í•™ê³¼ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
                    
                    await self._process_department_data(department, department_dir)
            
            # í•™ìŠµ ë°ì´í„° í†µí•© ë° íŒ¨í„´ ë¶„ì„
            await self._analyze_patterns()
            
            # í•™ìŠµ ê²°ê³¼ ì €ì¥
            await self._save_training_results()
            
            logger.info("âœ… êµìˆ˜ë‹˜ë“¤ì˜ í‰ê°€ ë°ì´í„° í•™ìŠµ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ í‰ê°€ ë°ì´í„° í•™ìŠµ ì‹¤íŒ¨: {e}")
            raise
    
    def _extract_department_name(self, dir_name: str) -> str:
        """ë””ë ‰í† ë¦¬ëª…ì—ì„œ í•™ê³¼ëª… ì¶”ì¶œ"""
        if "ì‘ì—…ì¹˜ë£Œ" in dir_name:
            return "ì‘ì—…ì¹˜ë£Œí•™ê³¼"
        elif "ë¬¼ë¦¬ì¹˜ë£Œ" in dir_name:
            return "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼"
        else:
            return dir_name.replace("í‰ê°€ìœ„ì› ìˆ˜í–‰ê²°ê³¼_", "")
    
    async def _process_department_data(self, department: str, department_dir: Path):
        """í•™ê³¼ë³„ ë°ì´í„° ì²˜ë¦¬"""
        
        department_data = []
        professor_evaluations = {}
        
        # ê° êµìˆ˜ë‹˜ì˜ ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬
        for excel_file in department_dir.glob("*.xlsx"):
            professor_name = self._extract_professor_name(excel_file.name)
            logger.info(f"   ğŸ‘¨â€ğŸ« {professor_name} êµìˆ˜ë‹˜ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
            
            try:
                # ì—‘ì…€ íŒŒì¼ ì½ê¸° (pandas ì‚¬ìš©)
                df = pd.read_excel(excel_file)
                
                # ë°ì´í„° ì •ì œ ë° êµ¬ì¡°í™”
                professor_data = await self._parse_excel_data(df, professor_name)
                professor_evaluations[professor_name] = professor_data
                department_data.extend(professor_data)
                
            except Exception as e:
                logger.warning(f"âš ï¸ {professor_name} êµìˆ˜ë‹˜ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        # í•™ê³¼ë³„ ë°ì´í„° ì €ì¥
        self.training_data[department] = {
            "combined_data": department_data,
            "professor_evaluations": professor_evaluations,
            "total_questions": len(department_data)
        }
        
        logger.info(f"âœ… {department} ì´ {len(department_data)}ê°œ ë¬¸ì œ ë°ì´í„° ìˆ˜ì§‘")
    
    def _extract_professor_name(self, filename: str) -> str:
        """íŒŒì¼ëª…ì—ì„œ êµìˆ˜ëª… ì¶”ì¶œ"""
        # "2. ì‹ ì¥í›ˆ_ì‘ì¹˜_ë§ˆìŠ¤í„°ì½”ë”©ì§€.xlsx" -> "ì‹ ì¥í›ˆ"
        parts = filename.split("_")
        if len(parts) >= 2:
            name_part = parts[0].replace("2. ", "").strip()
            return name_part
        return filename.split(".")[0]
    
    async def _parse_excel_data(self, df: pd.DataFrame, professor_name: str) -> List[Dict]:
        """ì—‘ì…€ ë°ì´í„° íŒŒì‹± ë° êµ¬ì¡°í™”"""
        
        parsed_data = []
        
        try:
            # ì—‘ì…€ êµ¬ì¡° ë¶„ì„ (ì¼ë°˜ì ì¸ ì»¬ëŸ¼ëª…ë“¤)
            possible_columns = {
                "question": ["ë¬¸ì œ", "ë¬¸í•­", "question", "ë¬¸ì œë‚´ìš©", "ë‚´ìš©"],
                "answer": ["ì •ë‹µ", "ë‹µ", "answer", "correct_answer", "ê°€ë‹µì•ˆ"],
                "difficulty": ["ë‚œì´ë„", "difficulty", "ìˆ˜ì¤€", "ë ˆë²¨"],
                "domain": ["ë¶„ì•¼", "ì˜ì—­", "ìœ í˜•", "domain", "category", "ë¶„ë¥˜"]
            }
            
            # ì‹¤ì œ ì»¬ëŸ¼ ë§¤í•‘
            column_mapping = {}
            for key, candidates in possible_columns.items():
                for col in df.columns:
                    if any(candidate in str(col).lower() for candidate in candidates):
                        column_mapping[key] = col
                        break
            
            logger.info(f"   ğŸ“Š ì»¬ëŸ¼ ë§¤í•‘: {column_mapping}")
            
            # ë°ì´í„° ì¶”ì¶œ
            for idx, row in df.iterrows():
                try:
                    question_data = {
                        "professor": professor_name,
                        "question_number": idx + 1,
                        "question": str(row.get(column_mapping.get("question", ""), "")).strip(),
                        "answer": str(row.get(column_mapping.get("answer", ""), "")).strip(),
                        "difficulty": str(row.get(column_mapping.get("difficulty", ""), "")).strip(),
                        "domain": str(row.get(column_mapping.get("domain", ""), "")).strip(),
                        "raw_data": row.to_dict()
                    }
                    
                    # ë¹ˆ ë°ì´í„° í•„í„°ë§
                    if question_data["question"] and len(question_data["question"]) > 10:
                        parsed_data.append(question_data)
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ í–‰ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue
            
        except Exception as e:
            logger.error(f"âŒ ì—‘ì…€ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        return parsed_data
    
    async def _analyze_patterns(self):
        """í•™ìŠµ ë°ì´í„° íŒ¨í„´ ë¶„ì„"""
        
        logger.info("ğŸ” í•™ìŠµ ë°ì´í„° íŒ¨í„´ ë¶„ì„ ì‹œì‘")
        
        for department, data in self.training_data.items():
            logger.info(f"ğŸ“Š {department} íŒ¨í„´ ë¶„ì„ ì¤‘...")
            
            # 1. ë‚œì´ë„ ë¶„í¬ ë¶„ì„
            difficulty_analysis = await self._analyze_difficulty_patterns(data["combined_data"])
            
            # 2. ë¶„ì•¼ í‚¤ì›Œë“œ ì¶”ì¶œ
            domain_analysis = await self._extract_domain_keywords(data["combined_data"])
            
            # 3. êµìˆ˜ë³„ ì¼ì¹˜ë„ ë¶„ì„
            consistency_analysis = await self._analyze_professor_consistency(data["professor_evaluations"])
            
            # ê²°ê³¼ ì €ì¥
            self.difficulty_patterns[department] = difficulty_analysis
            self.domain_keywords[department] = domain_analysis
            self.professor_weights[department] = consistency_analysis
            
            logger.info(f"âœ… {department} íŒ¨í„´ ë¶„ì„ ì™„ë£Œ")
    
    async def _analyze_difficulty_patterns(self, questions: List[Dict]) -> Dict:
        """ë‚œì´ë„ íŒ¨í„´ ë¶„ì„"""
        
        difficulty_patterns = {
            "í•˜": {"keywords": [], "characteristics": []},
            "ì¤‘": {"keywords": [], "characteristics": []},
            "ìƒ": {"keywords": [], "characteristics": []}
        }
        
        # ë‚œì´ë„ë³„ ë¬¸ì œ ê·¸ë£¹í™”
        by_difficulty = {}
        for q in questions:
            diff = q.get("difficulty", "").strip()
            if diff in ["í•˜", "ì¤‘", "ìƒ"]:
                if diff not in by_difficulty:
                    by_difficulty[diff] = []
                by_difficulty[diff].append(q["question"])
        
        # AIë¥¼ ì‚¬ìš©í•œ íŒ¨í„´ ë¶„ì„
        for difficulty, question_list in by_difficulty.items():
            if len(question_list) >= 3:  # ìµœì†Œ 3ê°œ ì´ìƒì˜ ë¬¸ì œê°€ ìˆì„ ë•Œë§Œ ë¶„ì„
                patterns = await self._extract_difficulty_characteristics(question_list, difficulty)
                difficulty_patterns[difficulty] = patterns
        
        return difficulty_patterns
    
    async def _extract_domain_keywords(self, questions: List[Dict]) -> Dict:
        """ë¶„ì•¼ë³„ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        
        domain_keywords = {}
        
        # ë¶„ì•¼ë³„ ë¬¸ì œ ê·¸ë£¹í™”
        by_domain = {}
        for q in questions:
            domain = q.get("domain", "").strip()
            if domain and domain != "":
                if domain not in by_domain:
                    by_domain[domain] = []
                by_domain[domain].append(q["question"])
        
        # AIë¥¼ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
        for domain, question_list in by_domain.items():
            if len(question_list) >= 2:  # ìµœì†Œ 2ê°œ ì´ìƒì˜ ë¬¸ì œê°€ ìˆì„ ë•Œë§Œ ë¶„ì„
                keywords = await self._extract_domain_characteristics(question_list, domain)
                domain_keywords[domain] = keywords
        
        return domain_keywords
    
    async def _analyze_professor_consistency(self, professor_evaluations: Dict) -> Dict:
        """êµìˆ˜ë³„ í‰ê°€ ì¼ì¹˜ë„ ë¶„ì„ ë° ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        
        consistency_scores = {}
        
        # ê°™ì€ ë¬¸ì œì— ëŒ€í•œ êµìˆ˜ë³„ í‰ê°€ ë¹„êµ (í–¥í›„ êµ¬í˜„)
        # í˜„ì¬ëŠ” ê· ë“± ê°€ì¤‘ì¹˜ ì ìš©
        for professor in professor_evaluations.keys():
            consistency_scores[professor] = 1.0  # ê· ë“± ê°€ì¤‘ì¹˜
        
        return consistency_scores
    
    async def _extract_difficulty_characteristics(self, questions: List[str], difficulty: str) -> Dict:
        """AIë¥¼ ì‚¬ìš©í•œ ë‚œì´ë„ë³„ íŠ¹ì„± ì¶”ì¶œ"""
        
        try:
            # ë¬¸ì œë“¤ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
            combined_text = "\n".join(questions[:10])  # ìµœëŒ€ 10ê°œ ë¬¸ì œë§Œ ë¶„ì„
            
            prompt = f"""
ë‹¤ìŒì€ '{difficulty}' ë‚œì´ë„ë¡œ ë¶„ë¥˜ëœ ë¬¸ì œë“¤ì…ë‹ˆë‹¤.
ì´ ë¬¸ì œë“¤ì˜ ê³µí†µì ì¸ íŠ¹ì„±ê³¼ í‚¤ì›Œë“œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë¬¸ì œë“¤:
{combined_text}

ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"],
    "characteristics": ["íŠ¹ì„±1", "íŠ¹ì„±2", "íŠ¹ì„±3"],
    "complexity_indicators": ["ë³µì¡ë„ì§€í‘œ1", "ë³µì¡ë„ì§€í‘œ2"]
}}
"""
            
            # Gemini API í˜¸ì¶œ
            if self.gemini_model:
                response = await self._call_gemini_async(prompt)
                try:
                    # í†µí•© JSON íŒŒì„œ ì‚¬ìš©
                    from app.services.question_parser import QuestionParser
                    result = QuestionParser.parse_ai_json_response(response)
                    if "error" not in result:
                        return result
                except:
                    pass
            
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "keywords": [],
                "characteristics": [],
                "complexity_indicators": []
            }
            
        except Exception as e:
            logger.warning(f"âš ï¸ ë‚œì´ë„ íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {"keywords": [], "characteristics": [], "complexity_indicators": []}
    
    async def _extract_domain_characteristics(self, questions: List[str], domain: str) -> Dict:
        """AIë¥¼ ì‚¬ìš©í•œ ë¶„ì•¼ë³„ íŠ¹ì„± ì¶”ì¶œ"""
        
        try:
            combined_text = "\n".join(questions[:10])
            
            prompt = f"""
ë‹¤ìŒì€ '{domain}' ë¶„ì•¼ë¡œ ë¶„ë¥˜ëœ ë¬¸ì œë“¤ì…ë‹ˆë‹¤.
ì´ ë¶„ì•¼ì˜ í•µì‹¬ í‚¤ì›Œë“œì™€ íŠ¹ì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë¬¸ì œë“¤:
{combined_text}

ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "core_keywords": ["í•µì‹¬í‚¤ì›Œë“œ1", "í•µì‹¬í‚¤ì›Œë“œ2"],
    "technical_terms": ["ì „ë¬¸ìš©ì–´1", "ì „ë¬¸ìš©ì–´2"],
    "topic_indicators": ["ì£¼ì œì§€í‘œ1", "ì£¼ì œì§€í‘œ2"]
}}
"""
            
            if self.gemini_model:
                response = await self._call_gemini_async(prompt)
                try:
                    from app.services.question_parser import QuestionParser
                    result = QuestionParser.parse_ai_json_response(response)
                    if "error" not in result:
                        return result
                except:
                    pass
            
            return {
                "core_keywords": [],
                "technical_terms": [],
                "topic_indicators": []
            }
            
        except Exception as e:
            logger.warning(f"âš ï¸ ë¶„ì•¼ íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {"core_keywords": [], "technical_terms": [], "topic_indicators": []}
    
    async def _call_gemini_async(self, prompt: str) -> str:
        """Gemini API ë¹„ë™ê¸° í˜¸ì¶œ"""
        try:
            response = self.gemini_model.generate_content(prompt)
            return response.text
        except Exception as e:
            logger.error(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    async def _save_training_results(self):
        """í•™ìŠµ ê²°ê³¼ ì €ì¥"""
        
        try:
            save_path = Path("data/llm_training")
            save_path.mkdir(exist_ok=True)
            
            # í•™ìŠµ ê²°ê³¼ ì €ì¥
            training_results = {
                "timestamp": datetime.now().isoformat(),
                "difficulty_patterns": self.difficulty_patterns,
                "domain_keywords": self.domain_keywords,
                "professor_weights": self.professor_weights,
                "training_summary": {
                    dept: {
                        "total_questions": data["total_questions"],
                        "professors": list(data["professor_evaluations"].keys())
                    }
                    for dept, data in self.training_data.items()
                }
            }
            
            with open(save_path / "training_results.json", "w", encoding="utf-8") as f:
                json.dump(training_results, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… í•™ìŠµ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {save_path / 'training_results.json'}")
            
        except Exception as e:
            logger.error(f"âŒ í•™ìŠµ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    async def predict_difficulty_and_domain(self, question: str, department: str) -> Dict:
        """
        ìƒˆë¡œìš´ ë¬¸ì œì˜ ë‚œì´ë„ì™€ ë¶„ì•¼ ì˜ˆì¸¡
        
        Args:
            question: ë¶„ì„í•  ë¬¸ì œ í…ìŠ¤íŠ¸
            department: í•™ê³¼ëª…
            
        Returns:
            ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        
        try:
            # í•™ìŠµ ë°ì´í„° ë¡œë“œ
            await self._load_training_results()
            
            # í•™ê³¼ë³„ íŒ¨í„´ ì ìš©
            if department not in self.difficulty_patterns:
                department = "ì‘ì—…ì¹˜ë£Œí•™ê³¼"  # ê¸°ë³¸ê°’
            
            # AI ê¸°ë°˜ ì˜ˆì¸¡
            prediction = await self._ai_predict(question, department)
            
            return {
                "difficulty": prediction.get("difficulty", "ì¤‘"),
                "domain": prediction.get("domain", "ì¼ë°˜"),
                "confidence": prediction.get("confidence", 0.7),
                "reasoning": prediction.get("reasoning", "AI ë¶„ì„ ê²°ê³¼")
            }
            
        except Exception as e:
            logger.error(f"âŒ ë‚œì´ë„/ë¶„ì•¼ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return {
                "difficulty": "ì¤‘",
                "domain": "ì¼ë°˜",
                "confidence": 0.5,
                "reasoning": "ê¸°ë³¸ê°’ ì ìš©"
            }
    
    async def _load_training_results(self):
        """ì €ì¥ëœ í•™ìŠµ ê²°ê³¼ ë¡œë“œ"""
        
        try:
            results_path = Path("data/llm_training/training_results.json")
            if results_path.exists():
                with open(results_path, "r", encoding="utf-8") as f:
                    results = json.load(f)
                
                self.difficulty_patterns = results.get("difficulty_patterns", {})
                self.domain_keywords = results.get("domain_keywords", {})
                self.professor_weights = results.get("professor_weights", {})
                
        except Exception as e:
            logger.warning(f"âš ï¸ í•™ìŠµ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    async def _ai_predict(self, question: str, department: str) -> Dict:
        """AI ê¸°ë°˜ ë‚œì´ë„/ë¶„ì•¼ ì˜ˆì¸¡"""
        
        try:
            # í•™ê³¼ë³„ í•™ìŠµ íŒ¨í„´ ì •ë³´ êµ¬ì„±
            dept_patterns = self.difficulty_patterns.get(department, {})
            dept_domains = self.domain_keywords.get(department, {})
            
            prompt = f"""
ë‹¤ìŒ ë¬¸ì œì˜ ë‚œì´ë„ì™€ ë¶„ì•¼ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë¬¸ì œ: {question}

í•™ê³¼: {department}

í•™ìŠµëœ íŒ¨í„´ ì •ë³´:
- ë‚œì´ë„ íŒ¨í„´: {json.dumps(dept_patterns, ensure_ascii=False)}
- ë¶„ì•¼ í‚¤ì›Œë“œ: {json.dumps(dept_domains, ensure_ascii=False)}

ë¶„ì„ ê¸°ì¤€:
1. ë‚œì´ë„: í•˜(ê¸°ì´ˆê°œë…, ë‹¨ìˆœì•”ê¸°), ì¤‘(ì‘ìš©, ì´í•´), ìƒ(ì¢…í•©ë¶„ì„, ê³ ì°¨ì›ì‚¬ê³ )
2. ë¶„ì•¼: í•™ìŠµëœ ë¶„ì•¼ ì¤‘ì—ì„œ ê°€ì¥ ì í•©í•œ ê²ƒ ì„ íƒ

ê²°ê³¼ë¥¼ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "difficulty": "í•˜|ì¤‘|ìƒ",
    "domain": "ë¶„ì•¼ëª…",
    "confidence": 0.0-1.0,
    "reasoning": "ë¶„ì„ ê·¼ê±°"
}}
"""
            
            if self.gemini_model:
                response = await self._call_gemini_async(prompt)
                try:
                    from app.services.question_parser import QuestionParser
                    result = QuestionParser.parse_ai_json_response(response)
                    if "error" not in result:
                        return result
                except:
                    pass
            
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "difficulty": "ì¤‘",
                "domain": "ì¼ë°˜",
                "confidence": 0.6,
                "reasoning": "ê¸°ë³¸ ë¶„ì„ ê²°ê³¼"
            }
            
        except Exception as e:
            logger.error(f"âŒ AI ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return {
                "difficulty": "ì¤‘",
                "domain": "ì¼ë°˜",
                "confidence": 0.5,
                "reasoning": "ì˜ˆì¸¡ ì‹¤íŒ¨ë¡œ ê¸°ë³¸ê°’ ì ìš©"
            }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
difficulty_domain_mapper = DifficultyDomainMapper() 