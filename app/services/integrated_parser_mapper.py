"""
í†µí•© íŒŒì‹± ë° ë§¤í•‘ ì‹œìŠ¤í…œ
ì‹¤ì œ ë¬¸ì œì§€/ë‹µì•ˆì§€ + êµìˆ˜ë‹˜ë“¤ì˜ í‰ê°€ ë°ì´í„° ë§¤í•‘í•˜ì—¬ ì™„ì „í•œ ë°ì´í„°ì…‹ ìƒì„±
"""
import os
import json
import logging
import asyncio
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from datetime import datetime
import re

from app.services.question_parser import QuestionParser
from app.services.difficulty_domain_mapper import difficulty_domain_mapper

logger = logging.getLogger(__name__)

class IntegratedParserMapper:
    """
    í†µí•© íŒŒì‹± ë° ë§¤í•‘ ì‹œìŠ¤í…œ
    
    ê¸°ëŠ¥:
    1. uploads/questions í´ë”ì˜ ì‹¤ì œ ë¬¸ì œì§€/ë‹µì•ˆì§€ íŒŒì‹±
    2. data/í‰ê°€ìœ„ì› ìˆ˜í–‰ê²°ê³¼ì˜ êµìˆ˜ë‹˜ í‰ê°€ ë°ì´í„°ì™€ ë§¤í•‘
    3. ì™„ì „í•œ í†µí•© ë°ì´í„°ì…‹ì„ data/save_parserì— ì €ì¥
    """
    
    def __init__(self):
        # API í‚¤ ì§ì ‘ ì „ë‹¬í•˜ì—¬ íŒŒì„œ ì´ˆê¸°í™”
        gemini_api_key = "AIzaSyAU_5m68cNAMIBn7m1uQPrYKNFR0oPO3QA"
        self.parser = QuestionParser(api_key=gemini_api_key)
        self.questions_dir = Path("uploads/questions")
        self.evaluation_dir = Path("data/í‰ê°€ìœ„ì› ìˆ˜í–‰ê²°ê³¼")
        self.output_dir = Path("data/save_parser")
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_dir.mkdir(exist_ok=True, parents=True)
    
    async def process_all_files(self) -> Dict[str, Any]:
        """
        ëª¨ë“  íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  í†µí•© ë°ì´í„°ì…‹ ìƒì„±
        
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½
        """
        
        logger.info("ğŸš€ í†µí•© íŒŒì‹± ë° ë§¤í•‘ ì‹œìŠ¤í…œ ì‹œì‘")
        logger.info("="*80)
        
        try:
            # 1. ì—…ë¡œë“œëœ íŒŒì¼ë“¤ ë¶„ì„
            logger.info("ğŸ“‚ 1ë‹¨ê³„: ì—…ë¡œë“œëœ íŒŒì¼ë“¤ ë¶„ì„")
            file_groups = await self._analyze_uploaded_files()
            
            # 2. êµìˆ˜ë‹˜ í‰ê°€ ë°ì´í„° ë¡œë“œ
            logger.info("ğŸ“ 2ë‹¨ê³„: êµìˆ˜ë‹˜ í‰ê°€ ë°ì´í„° ë¡œë“œ")
            await difficulty_domain_mapper.load_professor_evaluation_data()
            
            # 3. ê° ì—°ë„/í•™ê³¼ë³„ íŒŒì¼ ì²˜ë¦¬
            logger.info("âš™ï¸ 3ë‹¨ê³„: íŒŒì¼ë³„ íŒŒì‹± ë° ë§¤í•‘")
            integrated_datasets = {}
            
            for key, files in file_groups.items():
                logger.info(f"ğŸ“Š {key} ì²˜ë¦¬ ì¤‘...")
                dataset = await self._process_file_group(key, files)
                if dataset:
                    integrated_datasets[key] = dataset
            
            # 4. í†µí•© ë°ì´í„°ì…‹ ì €ì¥
            logger.info("ğŸ’¾ 4ë‹¨ê³„: í†µí•© ë°ì´í„°ì…‹ ì €ì¥")
            saved_files = await self._save_integrated_datasets(integrated_datasets)
            
            # 5. ê²°ê³¼ ìš”ì•½
            summary = self._generate_summary(integrated_datasets, saved_files)
            
            logger.info("="*80)
            logger.info("âœ… í†µí•© íŒŒì‹± ë° ë§¤í•‘ ì‹œìŠ¤í…œ ì™„ë£Œ!")
            
            return summary
            
        except Exception as e:
            logger.error(f"âŒ í†µí•© íŒŒì‹± ë° ë§¤í•‘ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    async def _analyze_uploaded_files(self) -> Dict[str, Dict[str, Path]]:
        """
        ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì„ ì—°ë„/í•™ê³¼ë³„ë¡œ ê·¸ë£¹í™”
        
        Returns:
            íŒŒì¼ ê·¸ë£¹ ë”•ì…”ë„ˆë¦¬
        """
        
        file_groups = {}
        
        if not self.questions_dir.exists():
            logger.error(f"âŒ ë¬¸ì œ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {self.questions_dir}")
            return file_groups
        
        # íŒŒì¼ íŒ¨í„´ ë¶„ì„
        for file_path in self.questions_dir.iterdir():
            if file_path.is_file() and file_path.suffix.lower() == '.pdf':
                # ìˆ¨ê¹€ íŒŒì¼ ì œì™¸
                if file_path.name.startswith('._'):
                    continue
                
                # íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ
                info = self._extract_file_info(file_path.name)
                if info:
                    year, department, file_type = info
                    key = f"{year}_{department}"
                    
                    if key not in file_groups:
                        file_groups[key] = {}
                    
                    file_groups[key][file_type] = file_path
                    
                    logger.info(f"   ğŸ“„ {file_path.name}")
                    logger.info(f"      â†’ {year}ë…„ {department} {file_type}")
        
        logger.info(f"ğŸ“Š ì´ {len(file_groups)}ê°œ ê·¸ë£¹ ë°œê²¬:")
        for key, files in file_groups.items():
            logger.info(f"   {key}: {list(files.keys())}")
        
        return file_groups
    
    def _extract_file_info(self, filename: str) -> Optional[Tuple[str, str, str]]:
        """
        íŒŒì¼ëª…ì—ì„œ ì—°ë„, í•™ê³¼, íŒŒì¼ íƒ€ì… ì¶”ì¶œ
        
        Args:
            filename: íŒŒì¼ëª…
            
        Returns:
            (ì—°ë„, í•™ê³¼, íŒŒì¼íƒ€ì…) ë˜ëŠ” None
        """
        
        # ì—°ë„ ì¶”ì¶œ
        year_match = re.search(r'(20\d{2})', filename)
        if not year_match:
            return None
        year = year_match.group(1)
        
        # í•™ê³¼ ì¶”ì¶œ
        if 'ë¬¼ë¦¬ì¹˜ë£Œì‚¬' in filename:
            department = 'ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼'
        elif 'ì‘ì—…ì¹˜ë£Œì‚¬' in filename:
            department = 'ì‘ì—…ì¹˜ë£Œí•™ê³¼'
        else:
            return None
        
        # íŒŒì¼ íƒ€ì… ì¶”ì¶œ
        if 'ê¸°ì¶œë¬¸ì œ' in filename or '1êµì‹œ' in filename:
            file_type = 'questions'
        elif 'ë‹µì•ˆ' in filename or 'ê°€ë‹µì•ˆ' in filename:
            file_type = 'answers'
        else:
            return None
        
        return year, department, file_type
    
    async def _process_file_group(self, group_key: str, files: Dict[str, Path]) -> Optional[Dict[str, Any]]:
        """
        íŒŒì¼ ê·¸ë£¹ ì²˜ë¦¬ (ë¬¸ì œì§€ + ë‹µì•ˆì§€ + í‰ê°€ ë°ì´í„°)
        
        Args:
            group_key: ê·¸ë£¹ í‚¤ (ì˜ˆ: "2024_ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼")
            files: íŒŒì¼ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            í†µí•© ë°ì´í„°ì…‹
        """
        
        try:
            year, department = group_key.split('_')
            
            # ë¬¸ì œì§€ì™€ ë‹µì•ˆì§€ê°€ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸
            if 'questions' not in files or 'answers' not in files:
                logger.warning(f"âš ï¸ {group_key}: ë¬¸ì œì§€ ë˜ëŠ” ë‹µì•ˆì§€ ëˆ„ë½")
                logger.warning(f"   ë³´ìœ  íŒŒì¼: {list(files.keys())}")
                return None
            
            questions_file = files['questions']
            answers_file = files['answers']
            
            logger.info(f"   ğŸ“– ë¬¸ì œì§€ íŒŒì‹±: {questions_file.name}")
            
            # ë¬¸ì œì§€ íŒŒì‹±
            questions_result = await self.parser.parse_any_file(
                str(questions_file), 
                "questions", 
                department
            )
            
            if questions_result.get("error"):
                logger.error(f"   âŒ ë¬¸ì œì§€ íŒŒì‹± ì‹¤íŒ¨: {questions_result['error']}")
                return None
            
            questions_data = questions_result.get("data", [])
            logger.info(f"   âœ… {len(questions_data)}ê°œ ë¬¸ì œ íŒŒì‹± ì™„ë£Œ")
            
            logger.info(f"   ğŸ“ ë‹µì•ˆì§€ íŒŒì‹±: {answers_file.name}")
            
            # ë‹µì•ˆì§€ íŒŒì‹±
            answers_result = await self.parser.parse_any_file(
                str(answers_file), 
                "answers", 
                department
            )
            
            if answers_result.get("error"):
                logger.error(f"   âŒ ë‹µì•ˆì§€ íŒŒì‹± ì‹¤íŒ¨: {answers_result['error']}")
                return None
            
            answers_data = answers_result.get("data", [])
            logger.info(f"   âœ… {len(answers_data)}ê°œ ë‹µì•ˆ íŒŒì‹± ì™„ë£Œ")
            
            # ë¬¸ì œì™€ ë‹µì•ˆ ë§¤ì¹­
            logger.info(f"   ğŸ”— ë¬¸ì œ-ë‹µì•ˆ ë§¤ì¹­ ì¤‘...")
            matched_data = self._match_questions_and_answers(questions_data, answers_data)
            logger.info(f"   âœ… {len(matched_data)}ê°œ ë¬¸ì œ-ë‹µì•ˆ ë§¤ì¹­ ì™„ë£Œ")
            
            # êµìˆ˜ë‹˜ í‰ê°€ ë°ì´í„°ì™€ ë§¤í•‘
            logger.info(f"   ğŸ¯ êµìˆ˜ë‹˜ í‰ê°€ ë°ì´í„° ë§¤í•‘ ì¤‘...")
            enhanced_data = await self._apply_professor_evaluations(matched_data, year, department)
            logger.info(f"   âœ… êµìˆ˜ë‹˜ í‰ê°€ ë°ì´í„° ë§¤í•‘ ì™„ë£Œ")
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            dataset = {
                "metadata": {
                    "year": year,
                    "department": department,
                    "questions_file": questions_file.name,
                    "answers_file": answers_file.name,
                    "processed_at": datetime.now().isoformat(),
                    "total_questions": len(enhanced_data)
                },
                "questions": enhanced_data
            }
            
            return dataset
            
        except Exception as e:
            logger.error(f"âŒ {group_key} íŒŒì¼ ê·¸ë£¹ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _match_questions_and_answers(self, questions_data: List[Dict], answers_data: List[Dict]) -> List[Dict]:
        """
        ë¬¸ì œì™€ ë‹µì•ˆ ë§¤ì¹­
        
        Args:
            questions_data: íŒŒì‹±ëœ ë¬¸ì œ ë°ì´í„°
            answers_data: íŒŒì‹±ëœ ë‹µì•ˆ ë°ì´í„°
            
        Returns:
            ë§¤ì¹­ëœ ë°ì´í„°
        """
        
        matched_data = []
        
        # ë‹µì•ˆì„ ë¬¸ì œ ë²ˆí˜¸ë³„ë¡œ ì¸ë±ì‹±
        answers_by_number = {}
        for answer in answers_data:
            q_num = answer.get('question_number')
            if q_num:
                answers_by_number[q_num] = answer
        
        # ë¬¸ì œì™€ ë‹µì•ˆ ë§¤ì¹­
        for question in questions_data:
            q_num = question.get('question_number')
            if q_num and q_num in answers_by_number:
                answer = answers_by_number[q_num]
                
                # ë¬¸ì œ ë°ì´í„°ì— ë‹µì•ˆ ì •ë³´ ë³‘í•©
                merged = {**question}  # ë¬¸ì œ ë°ì´í„° ë³µì‚¬
                
                # ë‹µì•ˆ ì •ë³´ ì¶”ê°€
                merged['correct_answer'] = answer.get('correct_answer', '')
                
                # ë‹µì•ˆì§€ì—ì„œ ì¶”ê°€ ì •ë³´ê°€ ìˆìœ¼ë©´ ë³‘í•©
                if answer.get('subject'):
                    merged['subject'] = answer['subject']
                if answer.get('area_name'):
                    merged['area_name'] = answer['area_name']
                if answer.get('difficulty'):
                    merged['difficulty'] = answer['difficulty']
                
                matched_data.append(merged)
            else:
                # ë‹µì•ˆì´ ì—†ëŠ” ë¬¸ì œë„ í¬í•¨
                matched_data.append(question)
        
        return matched_data
    
    async def _apply_professor_evaluations(self, matched_data: List[Dict], year: str, department: str) -> List[Dict]:
        """
        êµìˆ˜ë‹˜ í‰ê°€ ë°ì´í„° ì ìš©
        
        Args:
            matched_data: ë§¤ì¹­ëœ ë¬¸ì œ-ë‹µì•ˆ ë°ì´í„°
            year: ì—°ë„
            department: í•™ê³¼
            
        Returns:
            êµìˆ˜ë‹˜ í‰ê°€ê°€ ì ìš©ëœ ë°ì´í„°
        """
        
        enhanced_data = []
        
        for question in matched_data:
            try:
                # ê¸°ë³¸ ë°ì´í„° ë³µì‚¬
                enhanced = {**question}
                
                # ë¬¸ì œ ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ AI ì˜ˆì¸¡ ì ìš©
                question_content = question.get('content', '')
                if question_content and len(question_content) > 10:
                    
                    # AI ê¸°ë°˜ ë‚œì´ë„/ë¶„ì•¼ ì˜ˆì¸¡
                    prediction = await difficulty_domain_mapper.predict_difficulty_and_domain(
                        question_content, department
                    )
                    
                    # ê¸°ì¡´ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ê¸°ë³¸ê°’ì¸ ê²½ìš° AI ì˜ˆì¸¡ ì ìš©
                    if not enhanced.get('difficulty') or enhanced.get('difficulty') in ['', 'ì¤‘', None]:
                        enhanced['difficulty'] = prediction.get('difficulty', 'ì¤‘')
                        enhanced['ai_difficulty_applied'] = True
                        enhanced['ai_difficulty_confidence'] = prediction.get('confidence', 0.7)
                    
                    if not enhanced.get('area_name') or enhanced.get('area_name') in ['', 'ì¼ë°˜', None]:
                        enhanced['area_name'] = prediction.get('domain', 'ì¼ë°˜')
                        enhanced['ai_domain_applied'] = True
                        enhanced['ai_domain_confidence'] = prediction.get('confidence', 0.7)
                    
                    # AI ë¶„ì„ ì •ë³´ ì¶”ê°€
                    enhanced['ai_analysis'] = {
                        'reasoning': prediction.get('reasoning', 'AI ìë™ ë¶„ì„'),
                        'department': department,
                        'year': year,
                        'mapped_at': datetime.now().isoformat()
                    }
                
                # êµìˆ˜ë‹˜ í‰ê°€ ë°ì´í„° ë§¤í•‘
                professor_evaluations = await self._get_professor_evaluations_for_question(
                    question, year, department
                )
                if professor_evaluations:
                    enhanced['professor_evaluations'] = professor_evaluations
                
                enhanced_data.append(enhanced)
                
            except Exception as e:
                logger.warning(f"âš ï¸ ë¬¸ì œ {question.get('question_number', '?')} í‰ê°€ ë§¤í•‘ ì‹¤íŒ¨: {e}")
                enhanced_data.append(question)  # ì›ë³¸ ë°ì´í„° ìœ ì§€
                continue
        
        return enhanced_data
    
    async def _get_professor_evaluations_for_question(self, question: Dict, year: str, department: str) -> Optional[List[Dict]]:
        """
        íŠ¹ì • ë¬¸ì œì— ëŒ€í•œ êµìˆ˜ë‹˜ í‰ê°€ ë°ì´í„° ì¡°íšŒ
        
        Args:
            question: ë¬¸ì œ ë°ì´í„°
            year: ì—°ë„
            department: í•™ê³¼
            
        Returns:
            êµìˆ˜ë‹˜ í‰ê°€ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        
        try:
            # í•™ìŠµëœ êµìˆ˜ë‹˜ í‰ê°€ ë°ì´í„°ì—ì„œ í•´ë‹¹ ë¬¸ì œ ë²ˆí˜¸ì˜ í‰ê°€ ì°¾ê¸°
            question_number = question.get('question_number')
            if not question_number:
                return None
            
            # difficulty_domain_mapperì˜ í•™ìŠµ ë°ì´í„°ì—ì„œ í•´ë‹¹ ë¬¸ì œ í‰ê°€ ì°¾ê¸°
            training_data = difficulty_domain_mapper.training_data.get(department, {})
            professor_evaluations = training_data.get('professor_evaluations', {})
            
            evaluations = []
            for professor, prof_data in professor_evaluations.items():
                for eval_question in prof_data:
                    if eval_question.get('question_number') == question_number:
                        evaluations.append({
                            'professor': professor,
                            'difficulty': eval_question.get('difficulty'),
                            'domain': eval_question.get('domain'),
                            'year': year
                        })
            
            return evaluations if evaluations else None
            
        except Exception as e:
            logger.warning(f"âš ï¸ êµìˆ˜ë‹˜ í‰ê°€ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    async def _save_integrated_datasets(self, datasets: Dict[str, Dict]) -> List[str]:
        """
        í†µí•© ë°ì´í„°ì…‹ë“¤ì„ JSON íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            datasets: í†µí•© ë°ì´í„°ì…‹ë“¤
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ëª©ë¡
        """
        
        saved_files = []
        
        for key, dataset in datasets.items():
            try:
                # íŒŒì¼ëª… ìƒì„±
                filename = f"integrated_{key}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                filepath = self.output_dir / filename
                
                # JSONìœ¼ë¡œ ì €ì¥
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(dataset, f, ensure_ascii=False, indent=2)
                
                saved_files.append(str(filepath))
                logger.info(f"   ğŸ’¾ ì €ì¥ë¨: {filename}")
                logger.info(f"      ğŸ“Š ì´ {dataset['metadata']['total_questions']}ê°œ ë¬¸ì œ")
                
            except Exception as e:
                logger.error(f"âŒ {key} ë°ì´í„°ì…‹ ì €ì¥ ì‹¤íŒ¨: {e}")
                continue
        
        return saved_files
    
    def _generate_summary(self, datasets: Dict[str, Dict], saved_files: List[str]) -> Dict[str, Any]:
        """
        ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ìƒì„±
        
        Args:
            datasets: ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ë“¤
            saved_files: ì €ì¥ëœ íŒŒì¼ ëª©ë¡
            
        Returns:
            ìš”ì•½ ì •ë³´
        """
        
        total_questions = sum(dataset['metadata']['total_questions'] for dataset in datasets.values())
        
        summary = {
            'success': True,
            'processed_datasets': len(datasets),
            'total_questions': total_questions,
            'saved_files': saved_files,
            'datasets_summary': {}
        }
        
        for key, dataset in datasets.items():
            metadata = dataset['metadata']
            summary['datasets_summary'][key] = {
                'year': metadata['year'],
                'department': metadata['department'],
                'total_questions': metadata['total_questions'],
                'questions_file': metadata['questions_file'],
                'answers_file': metadata['answers_file']
            }
        
        return summary

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
integrated_parser_mapper = IntegratedParserMapper() 