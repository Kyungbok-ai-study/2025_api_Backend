"""
ë”¥ì‹œí¬ AI ê¸°ë°˜ ë‚œì´ë„ ë° ìœ í˜• ìë™ ë¶„ì„ ì„œë¹„ìŠ¤
í‰ê°€ìœ„ì› 6ëª…ì˜ ë‚œì´ë„ íŒ¨í„´ì„ í‰ê· í™”í•˜ì—¬ AI í•™ìŠµ í›„ ìë™ ì˜ˆì¸¡
"""
import json
import os
import re
import logging
from typing import Dict, List, Optional, Tuple
from pathlib import Path
from collections import defaultdict, Counter
import statistics

import requests
from sqlalchemy.orm import Session

from ..models.question import Question
from ..core.config import settings

logger = logging.getLogger(__name__)

class DifficultyAnalyzer:
    """AI ê¸°ë°˜ ë‚œì´ë„ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.evaluation_data_path = "app/data/detailed_evaluator_analysis.json"
        self.learning_patterns = {}
        self.ollama_url = "http://localhost:11434/api/generate"  # Ollama API
        
        # í‰ê°€ìœ„ì› ë‚œì´ë„ íŒ¨í„´ ë¡œë“œ
        self.load_evaluator_patterns()
        
        # í‰ê· í™”ëœ ë‚œì´ë„ íŒ¨í„´ ìƒì„±
        self.generate_averaged_patterns()
    
    def load_evaluator_patterns(self):
        """í‰ê°€ìœ„ì›ë³„ ë‚œì´ë„ íŒ¨í„´ ë¡œë“œ"""
        try:
            if os.path.exists(self.evaluation_data_path):
                with open(self.evaluation_data_path, 'r', encoding='utf-8') as f:
                    self.evaluation_data = json.load(f)
                    logger.info("âœ… í‰ê°€ìœ„ì› ë‚œì´ë„ íŒ¨í„´ ë¡œë“œ ì™„ë£Œ")
            else:
                logger.warning("âŒ í‰ê°€ìœ„ì› ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
                self.evaluation_data = {}
        except Exception as e:
            logger.error(f"âŒ í‰ê°€ìœ„ì› ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.evaluation_data = {}
    
    def generate_averaged_patterns(self):
        """6ëª… í‰ê°€ìœ„ì›ì˜ ë‚œì´ë„ íŒ¨í„´ í‰ê· í™”"""
        self.learning_patterns = {
            "ë¬¼ë¦¬ì¹˜ë£Œ": {
                "question_difficulty_map": {},  # ë¬¸ì œë²ˆí˜¸ë³„ í‰ê·  ë‚œì´ë„
                "difficulty_distribution": {},  # ì „ì²´ ë‚œì´ë„ ë¶„í¬
                "subject_patterns": {},         # ê³¼ëª©ë³„ ë‚œì´ë„ íŒ¨í„´
                "year_trends": {}              # ë…„ë„ë³„ íŠ¸ë Œë“œ
            },
            "ì‘ì—…ì¹˜ë£Œ": {
                "question_difficulty_map": {},
                "difficulty_distribution": {},
                "subject_patterns": {},
                "year_trends": {}
            }
        }
        
        for dept, dept_data in self.evaluation_data.get("departments", {}).items():
            self.analyze_department_patterns(dept, dept_data)
        
        logger.info("âœ… í‰ê°€ìœ„ì› íŒ¨í„´ í‰ê· í™” ì™„ë£Œ")
    
    def analyze_department_patterns(self, dept: str, dept_data: dict):
        """í•™ê³¼ë³„ í‰ê°€ìœ„ì› íŒ¨í„´ ë¶„ì„"""
        evaluators = dept_data.get("evaluators", {})
        
        # ë¬¸ì œë²ˆí˜¸ë³„ ë‚œì´ë„ ìˆ˜ì§‘ (1-22ë²ˆ)
        question_difficulties = defaultdict(list)  # {ë¬¸ì œë²ˆí˜¸: [ë‚œì´ë„1, ë‚œì´ë„2, ...]}
        all_difficulties = []
        
        for evaluator_name, eval_data in evaluators.items():
            for year, year_detail in eval_data.get("years_detail", {}).items():
                difficulty_by_question = year_detail.get("difficulty_by_question", {})
                
                for q_num, difficulty in difficulty_by_question.items():
                    if q_num.isdigit() and int(q_num) <= 22:  # 1-22ë²ˆ ë¬¸ì œë§Œ
                        question_difficulties[int(q_num)].append(difficulty)
                        all_difficulties.append(difficulty)
        
        # ë¬¸ì œë²ˆí˜¸ë³„ í‰ê·  ë‚œì´ë„ ê³„ì‚°
        question_avg_difficulty = {}
        for q_num in range(1, 23):  # 1-22ë²ˆ
            if q_num in question_difficulties:
                difficulties = question_difficulties[q_num]
                # ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ë‚œì´ë„ë¥¼ í‰ê· ìœ¼ë¡œ ì‚¬ìš©
                avg_difficulty = Counter(difficulties).most_common(1)[0][0]
                question_avg_difficulty[q_num] = avg_difficulty
        
        # ì „ì²´ ë‚œì´ë„ ë¶„í¬
        difficulty_distribution = Counter(all_difficulties)
        
        # í•™ìŠµ íŒ¨í„´ ì €ì¥
        self.learning_patterns[dept]["question_difficulty_map"] = question_avg_difficulty
        self.learning_patterns[dept]["difficulty_distribution"] = dict(difficulty_distribution)
        
        logger.info(f"ğŸ“Š {dept}í•™ê³¼ íŒ¨í„´ ë¶„ì„ ì™„ë£Œ: {len(question_avg_difficulty)}ê°œ ë¬¸ì œ ë§¤í•‘")
    
    def predict_difficulty_by_position(self, question_number: int, department: str) -> str:
        """ë¬¸ì œ ë²ˆí˜¸ ê¸°ë°˜ ë‚œì´ë„ ì˜ˆì¸¡"""
        dept_patterns = self.learning_patterns.get(department, {})
        question_map = dept_patterns.get("question_difficulty_map", {})
        
        # í•´ë‹¹ ë¬¸ì œ ë²ˆí˜¸ì˜ í‰ê·  ë‚œì´ë„ ë°˜í™˜
        if question_number in question_map:
            return question_map[question_number]
        
        # ì—†ìœ¼ë©´ ë¶„í¬ ê¸°ë°˜ ì˜ˆì¸¡
        difficulty_dist = dept_patterns.get("difficulty_distribution", {})
        if difficulty_dist:
            # ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ë‚œì´ë„ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ
            return max(difficulty_dist.items(), key=lambda x: x[1])[0]
        
        return "ì¤‘"  # ê¸°ë³¸ê°’
    
    def analyze_with_deepseek(self, question_content: str, department: str) -> Dict[str, str]:
        """ë”¥ì‹œí¬ AIë¥¼ í†µí•œ ë¬¸ì œ ë‚´ìš© ê¸°ë°˜ ë‚œì´ë„ ë° ìœ í˜• ë¶„ì„"""
        try:
            # í•™ê³¼ë³„ í•™ìŠµ íŒ¨í„´ ì •ë³´
            dept_patterns = self.learning_patterns.get(department, {})
            difficulty_dist = dept_patterns.get("difficulty_distribution", {})
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.create_analysis_prompt(question_content, department, difficulty_dist)
            
            # Ollama ë”¥ì‹œí¬ í˜¸ì¶œ
            response = self.call_ollama_deepseek(prompt)
            
            if response:
                return self.parse_analysis_response(response)
            else:
                return self.get_fallback_analysis(department)
                
        except Exception as e:
            logger.error(f"âŒ ë”¥ì‹œí¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self.get_fallback_analysis(department)
    
    def create_analysis_prompt(self, question_content: str, department: str, difficulty_dist: dict) -> str:
        """ë”¥ì‹œí¬ ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        # í•™ê³¼ë³„ íŠ¹ì„±í™”ëœ í”„ë¡¬í”„íŠ¸
        dept_context = {
            "ë¬¼ë¦¬ì¹˜ë£Œ": "ë¬¼ë¦¬ì¹˜ë£Œì‚¬ êµ­ê°€ê³ ì‹œ ë¬¸ì œë¡œ, í•´ë¶€í•™, ìƒë¦¬í•™, ìš´ë™ì¹˜ë£Œí•™, ë¬¼ë¦¬ì¹˜ë£Œì§„ë‹¨í•™ ë“±ì˜ ì˜ì—­",
            "ì‘ì—…ì¹˜ë£Œ": "ì‘ì—…ì¹˜ë£Œì‚¬ êµ­ê°€ê³ ì‹œ ë¬¸ì œë¡œ, í•´ë¶€í•™, ìƒë¦¬í•™, ì‘ì—…ì¹˜ë£Œí•™, ì¸ì§€ì¬í™œí•™ ë“±ì˜ ì˜ì—­"
        }
        
        context = dept_context.get(department, "ë³´ê±´ì˜ë£Œ ê´€ë ¨ êµ­ê°€ê³ ì‹œ ë¬¸ì œ")
        
        # í‰ê°€ìœ„ì› ë‚œì´ë„ ë¶„í¬ ì •ë³´
        dist_info = ""
        if difficulty_dist:
            total = sum(difficulty_dist.values())
            percentages = {k: f"{(v/total*100):.1f}%" for k, v in difficulty_dist.items()}
            dist_info = f"ê¸°ì¡´ í‰ê°€ìœ„ì› 6ëª…ì˜ ë‚œì´ë„ ë¶„í¬: {percentages}"
        
        prompt = f"""
ë‹¹ì‹ ì€ {department}í•™ê³¼ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¬¸ì œì˜ ë‚œì´ë„ì™€ ìœ í˜•ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

**ë¶„ì„ ëŒ€ìƒ ë¬¸ì œ:**
{question_content}

**ë¬¸ì œ íŠ¹ì„±:**
- {context}
- 22ë¬¸ì œ ì¤‘ í•˜ë‚˜ë¡œ êµ¬ì„±
- {dist_info}

**ë¶„ì„ ìš”ì²­:**
1. ë‚œì´ë„: "í•˜", "ì¤‘", "ìƒ" ì¤‘ í•˜ë‚˜
2. ë¬¸ì œìœ í˜•: "ê°ê´€ì‹", "ë‹¨ë‹µí˜•", "ì„œìˆ í˜•", "ê³„ì‚°í˜•", "ì„ìƒí˜•" ì¤‘ í•˜ë‚˜

**ë¶„ì„ ê¸°ì¤€:**
- í•˜: ê¸°ë³¸ ê°œë…, ë‹¨ìˆœ ì•”ê¸° ë¬¸ì œ
- ì¤‘: ì‘ìš© ì´í•´, ì—°ê´€ì„± íŒŒì•… ë¬¸ì œ  
- ìƒ: ì¢…í•© ë¶„ì„, ì„ìƒ ì ìš© ë¬¸ì œ

**ì‘ë‹µ í˜•ì‹ (JSON):**
{{
  "difficulty": "ì¤‘",
  "question_type": "ê°ê´€ì‹",
  "reasoning": "ë¶„ì„ ê·¼ê±°"
}}
"""
        return prompt
    
    def call_ollama_deepseek(self, prompt: str) -> Optional[str]:
        """Ollamaë¥¼ í†µí•œ ë”¥ì‹œí¬ í˜¸ì¶œ"""
        try:
            headers = {
                "Content-Type": "application/json"
            }
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ í•©ì¹˜ê¸°
            full_prompt = f"""ë‹¹ì‹ ì€ êµ­ê°€ê³ ì‹œ ë¬¸ì œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì •í™•í•˜ê³  ê°ê´€ì ì¸ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.

{prompt}"""
            
            data = {
                "model": "deepseek-r1:8b",
                "prompt": full_prompt,
                "stream": False,
                "options": {
                    "temperature": 0.1,
                    "num_predict": 1000
                }
            }
            
            response = requests.post(
                self.ollama_url,
                headers=headers,
                json=data,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get("response", "")
            else:
                logger.warning(f"âš ï¸ Ollama ì—°ê²° ì‹¤íŒ¨: {response.status_code}")
                return None
                
        except requests.exceptions.ConnectionError:
            logger.warning("âš ï¸ Ollamaê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ. íŒ¨í„´ ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ ëŒ€ì²´")
            return None
        except Exception as e:
            logger.warning(f"âš ï¸ Ollama í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def parse_analysis_response(self, response: str) -> Dict[str, str]:
        """ë”¥ì‹œí¬ ì‘ë‹µ íŒŒì‹±"""
        try:
            # JSON ì¶”ì¶œ ì‹œë„
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                analysis = json.loads(json_str)
                
                difficulty = analysis.get("difficulty", "ì¤‘")
                question_type = analysis.get("question_type", "ê°ê´€ì‹")
                reasoning = analysis.get("reasoning", "AI ë¶„ì„ ê²°ê³¼")
                
                # ìœ íš¨ì„± ê²€ì¦
                valid_difficulties = ["í•˜", "ì¤‘", "ìƒ"]
                valid_types = ["ê°ê´€ì‹", "ë‹¨ë‹µí˜•", "ì„œìˆ í˜•", "ê³„ì‚°í˜•", "ì„ìƒí˜•"]
                
                if difficulty not in valid_difficulties:
                    difficulty = "ì¤‘"
                if question_type not in valid_types:
                    question_type = "ê°ê´€ì‹"
                
                return {
                    "difficulty": difficulty,
                    "question_type": question_type,
                    "ai_reasoning": reasoning
                }
            
        except Exception as e:
            logger.error(f"âŒ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        # íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’
        return {
            "difficulty": "ì¤‘",
            "question_type": "ê°ê´€ì‹", 
            "ai_reasoning": "AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
        }
    
    def get_fallback_analysis(self, department: str) -> Dict[str, str]:
        """ë¡œì»¬ ë”¥ì‹œí¬ ë¶„ì„ ì‹¤íŒ¨ì‹œ ëŒ€ì²´ ë¶„ì„"""
        # í‰ê°€ìœ„ì› íŒ¨í„´ ê¸°ë°˜ ê¸°ë³¸ê°’
        dept_patterns = self.learning_patterns.get(department, {})
        difficulty_dist = dept_patterns.get("difficulty_distribution", {})
        
        # ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ë‚œì´ë„ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ
        default_difficulty = "ì¤‘"
        if difficulty_dist:
            default_difficulty = max(difficulty_dist.items(), key=lambda x: x[1])[0]
        
        return {
            "difficulty": default_difficulty,
            "question_type": "ê°ê´€ì‹",
            "ai_reasoning": "í‰ê°€ìœ„ì› 6ëª… íŒ¨í„´ ê¸°ë°˜ ë¶„ì„ (Ollama ë¯¸ì‹¤í–‰)"
        }
    
    def analyze_question_auto(self, question_content: str, question_number: int, department: str) -> Dict[str, str]:
        """ìë™ ë¬¸ì œ ë¶„ì„ (ë²ˆí˜¸ ê¸°ë°˜ + AI ë‚´ìš© ë¶„ì„ ì¡°í•©)"""
        logger.info(f"ğŸ¤– AI ë‚œì´ë„ ë¶„ì„ ì‹œì‘: {department}í•™ê³¼ {question_number}ë²ˆ ë¬¸ì œ")
        
        # 1. ë¬¸ì œ ë²ˆí˜¸ ê¸°ë°˜ ì˜ˆì¸¡
        position_difficulty = self.predict_difficulty_by_position(question_number, department)
        
        # 2. ë”¥ì‹œí¬ AI ë‚´ìš© ë¶„ì„
        ai_analysis = self.analyze_with_deepseek(question_content, department)
        
        # 3. ê²°ê³¼ ì¡°í•© (ìœ„ì¹˜ ê¸°ë°˜ì„ ìš°ì„ ìœ¼ë¡œ, AI ë¶„ì„ìœ¼ë¡œ ë³´ì •)
        final_difficulty = ai_analysis.get("difficulty", position_difficulty)
        question_type = ai_analysis.get("question_type", "ê°ê´€ì‹")
        ai_reasoning = ai_analysis.get("ai_reasoning", "ìë™ ë¶„ì„ ì™„ë£Œ")
        
        result = {
            "difficulty": final_difficulty,
            "question_type": question_type,
            "ai_reasoning": ai_reasoning,
            "position_based": position_difficulty,
            "ai_suggested": ai_analysis.get("difficulty", "ì¤‘"),
            "confidence": "high" if final_difficulty == position_difficulty else "medium"
        }
        
        logger.info(f"âœ… AI ë¶„ì„ ì™„ë£Œ: ë‚œì´ë„={final_difficulty}, ìœ í˜•={question_type}")
        return result
    
    def get_learning_summary(self) -> Dict:
        """í•™ìŠµëœ íŒ¨í„´ ìš”ì•½ ì •ë³´"""
        summary = {
            "total_patterns": len(self.learning_patterns),
            "departments": {}
        }
        
        for dept, patterns in self.learning_patterns.items():
            dept_summary = {
                "question_mappings": len(patterns.get("question_difficulty_map", {})),
                "difficulty_distribution": patterns.get("difficulty_distribution", {}),
                "total_evaluators": 6,
                "pattern_confidence": "high"
            }
            summary["departments"][dept] = dept_summary
        
        return summary

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
difficulty_analyzer = DifficultyAnalyzer() 