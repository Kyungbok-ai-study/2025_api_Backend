"""
ğŸ¢ ëŒ€ê¸°ì—…ê¸‰ í†µí•© RAG ì‹œìŠ¤í…œ ì„œë¹„ìŠ¤
ê¸°ì¡´ RAG ì‹œìŠ¤í…œë“¤ì„ í†µí•©í•˜ê³  ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ê¸°ëŠ¥ ì¶”ê°€
"""
import os
import json
import logging
import asyncio
from typing import List, Dict, Any, Optional, Tuple, Union
from datetime import datetime, timedelta
from pathlib import Path
import uuid
import hashlib
from collections import defaultdict
from dataclasses import dataclass
from enum import Enum

from sqlalchemy.orm import Session
from sqlalchemy import text, func, and_, or_

from ..models.question import Question
from ..models.user import User
# deepseek_service import ì œê±°ë¨ (Exaoneìœ¼ë¡œ ì „í™˜)
from ..services.qdrant_service import qdrant_service
from ..services.rag_system import rag_service
from ..services.rag_integration_service import rag_integration_service
from ..services.advanced_rag_service import advanced_rag_service

logger = logging.getLogger(__name__)

class RAGSearchStrategy(Enum):
    """RAG ê²€ìƒ‰ ì „ëµ"""
    BASIC = "basic"              # ê¸°ë³¸ ì‹œë§¨í‹± ê²€ìƒ‰
    HYBRID = "hybrid"            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í‚¤ì›Œë“œ+ì‹œë§¨í‹±)
    FUSION = "fusion"            # RAG Fusion (ë‹¤ì¤‘ ì¿¼ë¦¬)
    MULTIMODAL = "multimodal"    # ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰
    ADAPTIVE = "adaptive"        # ì ì‘í˜• ê²€ìƒ‰ (ìƒí™©ë³„ ìµœì í™”)

class RAGQualityLevel(Enum):
    """RAG í’ˆì§ˆ ìˆ˜ì¤€"""
    STANDARD = "standard"        # í‘œì¤€ í’ˆì§ˆ
    PREMIUM = "premium"          # í”„ë¦¬ë¯¸ì—„ í’ˆì§ˆ
    ENTERPRISE = "enterprise"    # ì—”í„°í”„ë¼ì´ì¦ˆ í’ˆì§ˆ

@dataclass
class RAGRequest:
    """í†µí•© RAG ìš”ì²­ ëª¨ë¸"""
    query: str
    strategy: RAGSearchStrategy = RAGSearchStrategy.ADAPTIVE
    quality_level: RAGQualityLevel = RAGQualityLevel.ENTERPRISE
    user_id: Optional[int] = None
    department: str = "ê°„í˜¸í•™ê³¼"
    context_limit: int = 10
    enable_learning: bool = True
    include_analytics: bool = True

@dataclass
class RAGResponse:
    """í†µí•© RAG ì‘ë‹µ ëª¨ë¸"""
    success: bool
    query: str
    strategy_used: str
    results: List[Dict[str, Any]]
    total_results: int
    processing_time: float
    quality_score: float
    analytics: Optional[Dict] = None
    learning_applied: bool = False
    error: Optional[str] = None

class EnterpriseRAGService:
    """ğŸ¢ ëŒ€ê¸°ì—…ê¸‰ í†µí•© RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        # ê¸°ì¡´ ì„œë¹„ìŠ¤ë“¤ í†µí•©
        self.basic_rag = rag_service
        self.integration_rag = rag_integration_service
        self.advanced_rag = advanced_rag_service
        
        # ì—”í„°í”„ë¼ì´ì¦ˆ ê¸°ëŠ¥
        # deepseek_service ì œê±°ë¨ (Exaoneìœ¼ë¡œ ì „í™˜ ì˜ˆì •)
        self.exaone = None  # TODO: Exaone ì„œë¹„ìŠ¤ êµ¬í˜„ í›„ ì´ˆê¸°í™”
        self.vector_db = qdrant_service
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.performance_tracker = defaultdict(list)
        self.quality_metrics = defaultdict(float)
        self.user_analytics = defaultdict(dict)
        
        # ìºì‹œ ë° ìµœì í™”
        self.result_cache = {}
        self.strategy_optimizer = {}
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        self.system_health = {
            "status": "operational",
            "last_check": datetime.now(),
            "components": {}
        }
        
        logger.info("ğŸ¢ ëŒ€ê¸°ì—…ê¸‰ í†µí•© RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # ============ 1. í†µí•© RAG ì—”ì§„ ============
    
    async def unified_rag_search(
        self,
        db: Session,
        request: RAGRequest
    ) -> RAGResponse:
        """í†µí•© RAG ê²€ìƒ‰ ì—”ì§„ - ëª¨ë“  ê¸°ëŠ¥ í†µí•©"""
        start_time = datetime.now()
        
        try:
            logger.info(f"ğŸ¯ í†µí•© RAG ê²€ìƒ‰ ì‹œì‘: {request.query} (ì „ëµ: {request.strategy.value})")
            
            # 1. ì „ëµ ìë™ ìµœì í™” (Adaptiveì¼ ê²½ìš°)
            if request.strategy == RAGSearchStrategy.ADAPTIVE:
                request.strategy = await self._optimize_search_strategy(db, request)
            
            # 2. ì‚¬ìš©ì ê°œì¸í™” ì ìš©
            if request.enable_learning and request.user_id:
                request = await self._apply_personalization(request)
            
            # 3. ìºì‹œ í™•ì¸
            cache_key = self._generate_cache_key(request)
            if cache_key in self.result_cache:
                cached_result = self.result_cache[cache_key]
                logger.info(f"ğŸ’¨ ìºì‹œ íˆíŠ¸: {request.query}")
                return cached_result
            
            # 4. ì „ëµë³„ ê²€ìƒ‰ ì‹¤í–‰
            search_results = await self._execute_search_strategy(db, request)
            
            # 5. í’ˆì§ˆ í‰ê°€ ë° í›„ì²˜ë¦¬
            processed_results = await self._enhance_results_quality(search_results, request)
            
            # 6. ë¶„ì„ ì •ë³´ ìƒì„±
            analytics = await self._generate_analytics(request, processed_results) if request.include_analytics else None
            
            # 7. ì‘ë‹µ êµ¬ì„±
            processing_time = (datetime.now() - start_time).total_seconds()
            quality_score = await self._calculate_quality_score(processed_results)
            
            response = RAGResponse(
                success=True,
                query=request.query,
                strategy_used=request.strategy.value,
                results=processed_results[:request.context_limit],
                total_results=len(processed_results),
                processing_time=round(processing_time, 3),
                quality_score=quality_score,
                analytics=analytics,
                learning_applied=request.enable_learning and request.user_id is not None
            )
            
            # 8. ìºì‹œ ì €ì¥
            self.result_cache[cache_key] = response
            
            # 9. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡
            self._record_performance_metrics(request, response)
            
            logger.info(f"âœ… í†µí•© RAG ê²€ìƒ‰ ì™„ë£Œ: {len(processed_results)}ê°œ ê²°ê³¼ ({processing_time:.3f}ì´ˆ)")
            return response
            
        except Exception as e:
            logger.error(f"âŒ í†µí•© RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return RAGResponse(
                success=False,
                query=request.query,
                strategy_used=request.strategy.value,
                results=[],
                total_results=0,
                processing_time=(datetime.now() - start_time).total_seconds(),
                quality_score=0.0,
                error=str(e)
            )
    
    async def _optimize_search_strategy(
        self,
        db: Session,
        request: RAGRequest
    ) -> RAGSearchStrategy:
        """ì ì‘í˜• ê²€ìƒ‰ ì „ëµ ìµœì í™”"""
        try:
            # ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„
            query_complexity = await self._analyze_query_complexity(request.query)
            
            # ì‚¬ìš©ì ì´ë ¥ ê¸°ë°˜ ìµœì í™”
            user_preferences = self._get_user_preferences(request.user_id) if request.user_id else {}
            
            # ì „ëµ ì„ íƒ ë¡œì§
            if query_complexity["has_multimodal_intent"]:
                return RAGSearchStrategy.MULTIMODAL
            elif query_complexity["complexity_score"] > 0.8:
                return RAGSearchStrategy.FUSION
            elif query_complexity["has_specific_keywords"]:
                return RAGSearchStrategy.HYBRID
            else:
                return RAGSearchStrategy.BASIC
                
        except Exception as e:
            logger.error(f"âŒ ì „ëµ ìµœì í™” ì‹¤íŒ¨: {e}")
            return RAGSearchStrategy.HYBRID  # ê¸°ë³¸ê°’
    
    async def _analyze_query_complexity(self, query: str) -> Dict[str, Any]:
        """ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„"""
        try:
            analysis_prompt = f"""
ë‹¤ìŒ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:

ì¿¼ë¦¬: "{query}"

ë¶„ì„ í•­ëª©:
1. complexity_score: ì¿¼ë¦¬ ë³µì¡ë„ (0.0-1.0)
2. has_specific_keywords: êµ¬ì²´ì  í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€
3. has_multimodal_intent: ì´ë¯¸ì§€/í‘œ ê´€ë ¨ ì˜ë„ ì—¬ë¶€
4. requires_context: ë§¥ë½ ì •ë³´ í•„ìš” ì—¬ë¶€
5. domain_specificity: ì „ë¬¸ ì˜ì—­ íŠ¹í™”ë„ (0.0-1.0)

JSON í˜•ì‹:
{{
    "complexity_score": 0.5,
    "has_specific_keywords": true,
    "has_multimodal_intent": false,
    "requires_context": true,
    "domain_specificity": 0.7
}}
"""
            
            result = await self.deepseek.chat_completion(
                messages=[{"role": "user", "content": analysis_prompt}],
                temperature=0.1
            )
            
            if result["success"]:
                try:
                    return json.loads(result["content"])
                except json.JSONDecodeError:
                    pass
            
            # í´ë°± ë¶„ì„
            return {
                "complexity_score": len(query.split()) / 20.0,  # ë‹¨ì–´ ìˆ˜ ê¸°ë°˜
                "has_specific_keywords": any(keyword in query.lower() for keyword in ["êµ¬ì²´ì ", "ì •í™•í•œ", "ìƒì„¸í•œ"]),
                "has_multimodal_intent": any(keyword in query.lower() for keyword in ["ì´ë¯¸ì§€", "ê·¸ë¦¼", "í‘œ", "ì°¨íŠ¸"]),
                "requires_context": len(query.split()) > 5,
                "domain_specificity": 0.5
            }
            
        except Exception as e:
            logger.error(f"âŒ ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"complexity_score": 0.5, "has_specific_keywords": False, "has_multimodal_intent": False, "requires_context": True, "domain_specificity": 0.5}
    
    async def _execute_search_strategy(
        self,
        db: Session,
        request: RAGRequest
    ) -> List[Dict[str, Any]]:
        """ì „ëµë³„ ê²€ìƒ‰ ì‹¤í–‰"""
        try:
            if request.strategy == RAGSearchStrategy.BASIC:
                return await self._execute_basic_search(db, request)
            elif request.strategy == RAGSearchStrategy.HYBRID:
                return await self._execute_hybrid_search(db, request)
            elif request.strategy == RAGSearchStrategy.FUSION:
                return await self._execute_fusion_search(db, request)
            elif request.strategy == RAGSearchStrategy.MULTIMODAL:
                return await self._execute_multimodal_search(db, request)
            else:
                return await self._execute_hybrid_search(db, request)  # ê¸°ë³¸ê°’
                
        except Exception as e:
            logger.error(f"âŒ ê²€ìƒ‰ ì „ëµ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return []
    
    async def _execute_basic_search(
        self,
        db: Session,
        request: RAGRequest
    ) -> List[Dict[str, Any]]:
        """ê¸°ë³¸ ì‹œë§¨í‹± ê²€ìƒ‰"""
        try:
            results = await self.basic_rag.similarity_search(
                db=db,
                query_text=request.query,
                limit=request.context_limit * 2,
                similarity_threshold=0.6
            )
            
            return [
                {
                    "content": result["content"],
                    "score": result["similarity"],
                    "source": "basic_semantic",
                    "metadata": {
                        "document_title": result.get("document_title", ""),
                        "subject": result.get("subject", ""),
                        "area_name": result.get("area_name", "")
                    }
                }
                for result in results
            ]
            
        except Exception as e:
            logger.error(f"âŒ ê¸°ë³¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    async def _execute_hybrid_search(
        self,
        db: Session,
        request: RAGRequest
    ) -> List[Dict[str, Any]]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í‚¤ì›Œë“œ+ì‹œë§¨í‹±)"""
        try:
            search_result = await self.advanced_rag.hybrid_search(
                db=db,
                query=request.query,
                search_mode="hybrid",
                limit=request.context_limit * 2
            )
            
            if search_result["success"]:
                return search_result["data"]["results"]
            else:
                return []
                
        except Exception as e:
            logger.error(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    async def _execute_fusion_search(
        self,
        db: Session,
        request: RAGRequest
    ) -> List[Dict[str, Any]]:
        """RAG Fusion ê²€ìƒ‰ (ë‹¤ì¤‘ ì¿¼ë¦¬)"""
        try:
            fusion_result = await self.advanced_rag.rag_fusion_search(
                db=db,
                original_query=request.query,
                num_queries=5,
                fusion_method="rrf"
            )
            
            if fusion_result["success"]:
                return fusion_result["final_results"]
            else:
                return []
                
        except Exception as e:
            logger.error(f"âŒ Fusion ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    async def _execute_multimodal_search(
        self,
        db: Session,
        request: RAGRequest
    ) -> List[Dict[str, Any]]:
        """ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ (í…ìŠ¤íŠ¸+ì´ë¯¸ì§€+í‘œ)"""
        try:
            # í˜„ì¬ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´, í–¥í›„ ë©€í‹°ëª¨ë‹¬ í™•ì¥
            return await self._execute_hybrid_search(db, request)
            
        except Exception as e:
            logger.error(f"âŒ ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    # ============ 2. í’ˆì§ˆ í–¥ìƒ ì‹œìŠ¤í…œ ============
    
    async def _enhance_results_quality(
        self,
        results: List[Dict[str, Any]],
        request: RAGRequest
    ) -> List[Dict[str, Any]]:
        """ê²°ê³¼ í’ˆì§ˆ í–¥ìƒ ì²˜ë¦¬"""
        try:
            if not results:
                return results
            
            enhanced_results = []
            
            for result in results:
                # í’ˆì§ˆ ìˆ˜ì¤€ë³„ í–¥ìƒ ì²˜ë¦¬
                if request.quality_level == RAGQualityLevel.ENTERPRISE:
                    enhanced_result = await self._apply_enterprise_enhancement(result, request)
                elif request.quality_level == RAGQualityLevel.PREMIUM:
                    enhanced_result = await self._apply_premium_enhancement(result, request)
                else:
                    enhanced_result = result
                
                enhanced_results.append(enhanced_result)
            
            # ì¤‘ë³µ ì œê±° ë° í’ˆì§ˆ ì •ë ¬
            unique_results = self._remove_duplicates(enhanced_results)
            sorted_results = sorted(unique_results, key=lambda x: x.get("enhanced_score", x.get("score", 0)), reverse=True)
            
            return sorted_results
            
        except Exception as e:
            logger.error(f"âŒ í’ˆì§ˆ í–¥ìƒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return results
    
    async def _apply_enterprise_enhancement(
        self,
        result: Dict[str, Any],
        request: RAGRequest
    ) -> Dict[str, Any]:
        """ì—”í„°í”„ë¼ì´ì¦ˆ í’ˆì§ˆ í–¥ìƒ"""
        try:
            enhanced_result = result.copy()
            
            # 1. AI ê¸°ë°˜ ìš”ì•½ ìƒì„±
            summary = await self._generate_ai_summary(result["content"], request.query)
            enhanced_result["ai_summary"] = summary
            
            # 2. ê´€ë ¨ë„ ì¬ê³„ì‚°
            relevance_score = await self._calculate_advanced_relevance(result["content"], request.query)
            enhanced_result["enhanced_score"] = relevance_score
            
            # 3. ì‹ ë¢°ë„ ì ìˆ˜ ì¶”ê°€
            credibility_score = self._calculate_credibility_score(result)
            enhanced_result["credibility"] = credibility_score
            
            # 4. í•™ê³¼ë³„ ë§ì¶¤í™”
            department_relevance = self._calculate_department_relevance(result, request.department)
            enhanced_result["department_relevance"] = department_relevance
            
            return enhanced_result
            
        except Exception as e:
            logger.error(f"âŒ ì—”í„°í”„ë¼ì´ì¦ˆ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return result
    
    async def _generate_ai_summary(self, content: str, query: str) -> str:
        """AI ê¸°ë°˜ ë§ì¶¤í˜• ìš”ì•½ ìƒì„±"""
        try:
            if len(content) < 200:
                return content[:100] + "..."
            
            summary_prompt = f"""
ë‹¤ìŒ ë‚´ìš©ì„ ì§ˆë¬¸ê³¼ ê´€ë ¨í•˜ì—¬ í•µì‹¬ë§Œ ê°„ë‹¨íˆ ìš”ì•½í•˜ì„¸ìš” (2-3ë¬¸ì¥):

ì§ˆë¬¸: {query}
ë‚´ìš©: {content[:500]}...

ìš”ì•½:
"""
            
            result = await self.deepseek.chat_completion(
                messages=[{"role": "user", "content": summary_prompt}],
                temperature=0.3
            )
            
            if result["success"]:
                return result["content"].strip()
            else:
                return content[:100] + "..."
                
        except Exception as e:
            logger.error(f"âŒ AI ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return content[:100] + "..."
    
    async def _calculate_advanced_relevance(self, content: str, query: str) -> float:
        """ê³ ê¸‰ ê´€ë ¨ë„ ê³„ì‚°"""
        try:
            # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜
            query_words = set(query.lower().split())
            content_words = set(content.lower().split())
            keyword_overlap = len(query_words.intersection(content_words)) / len(query_words) if query_words else 0
            
            # ì˜ë¯¸ì  ìœ ì‚¬ë„ (ê¸°ë³¸ ì ìˆ˜ ê¸°ë°˜)
            semantic_score = 0.7  # ì‹¤ì œë¡œëŠ” ì„ë² ë”© ìœ ì‚¬ë„ ì‚¬ìš©
            
            # ì¢…í•© ì ìˆ˜
            final_score = (keyword_overlap * 0.4) + (semantic_score * 0.6)
            return min(final_score, 1.0)
            
        except Exception as e:
            logger.error(f"âŒ ê³ ê¸‰ ê´€ë ¨ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_credibility_score(self, result: Dict[str, Any]) -> float:
        """ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        try:
            score = 0.5  # ê¸°ë³¸ ì ìˆ˜
            
            metadata = result.get("metadata", {})
            
            # ì†ŒìŠ¤ ì‹ ë¢°ë„
            if metadata.get("document_title"):
                score += 0.2
            
            # ìŠ¹ì¸ëœ ì»¨í…ì¸  ì—¬ë¶€
            if metadata.get("approval_status") == "approved":
                score += 0.2
            
            # êµìˆ˜ ê²€ì¦ ì—¬ë¶€
            if metadata.get("approved_by"):
                score += 0.1
            
            return min(score, 1.0)
            
        except Exception as e:
            logger.error(f"âŒ ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_department_relevance(self, result: Dict[str, Any], department: str) -> float:
        """í•™ê³¼ë³„ ê´€ë ¨ë„ ê³„ì‚°"""
        try:
            metadata = result.get("metadata", {})
            result_department = metadata.get("department", "")
            
            if result_department == department:
                return 1.0
            elif department in result_department or result_department in department:
                return 0.8
            else:
                return 0.6
                
        except Exception as e:
            logger.error(f"âŒ í•™ê³¼ ê´€ë ¨ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.6
    
    # ============ 3. í†µí•© ë¬¸ì„œ ì²˜ë¦¬ ============
    
    async def process_enterprise_document(
        self,
        db: Session,
        file_path: str,
        document_title: str,
        user_id: int,
        processing_options: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ë¬¸ì„œ ì²˜ë¦¬"""
        try:
            if processing_options is None:
                processing_options = {}
            
            logger.info(f"ğŸ¢ ì—”í„°í”„ë¼ì´ì¦ˆ ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘: {document_title}")
            
            processing_results = {
                "document_title": document_title,
                "processing_steps": {},
                "quality_metrics": {},
                "integration_status": {}
            }
            
            # 1. ê¸°ë³¸ RAG ì²˜ë¦¬
            basic_result = await self.basic_rag.upload_and_process_document(
                db=db,
                file_path=file_path,
                document_title=document_title,
                user_id=user_id
            )
            processing_results["processing_steps"]["basic_rag"] = basic_result
            
            # 2. ê³ ê¸‰ ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ (ì„ íƒì )
            if processing_options.get("enable_multimodal", True):
                multimodal_result = await self.advanced_rag.process_multimodal_document(
                    db=db,
                    file_path=file_path,
                    document_title=document_title,
                    user_id=user_id,
                    extract_images=processing_options.get("extract_images", True),
                    extract_tables=processing_options.get("extract_tables", True)
                )
                processing_results["processing_steps"]["multimodal"] = multimodal_result
            
            # 3. í’ˆì§ˆ ê²€ì¦
            quality_score = await self._validate_document_quality(file_path, document_title)
            processing_results["quality_metrics"]["overall_score"] = quality_score
            
            # 4. ìë™ ë¶„ë¥˜ ë° íƒœê¹…
            classification = await self._auto_classify_document(file_path, document_title)
            processing_results["quality_metrics"]["classification"] = classification
            
            # 5. í†µí•© ìƒíƒœ í™•ì¸
            integration_status = await self._check_integration_status(document_title)
            processing_results["integration_status"] = integration_status
            
            logger.info(f"âœ… ì—”í„°í”„ë¼ì´ì¦ˆ ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ: {document_title}")
            return {"success": True, "results": processing_results}
            
        except Exception as e:
            logger.error(f"âŒ ì—”í„°í”„ë¼ì´ì¦ˆ ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    # ============ 4. ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ============
    
    async def get_enterprise_analytics(self) -> Dict[str, Any]:
        """ì—”í„°í”„ë¼ì´ì¦ˆ ë¶„ì„ ëŒ€ì‹œë³´ë“œ"""
        try:
            analytics = {
                "system_overview": await self._get_system_overview(),
                "performance_metrics": await self._get_performance_metrics(),
                "quality_analytics": await self._get_quality_analytics(),
                "user_insights": await self._get_user_insights(),
                "component_health": await self._get_component_health(),
                "recommendations": await self._generate_recommendations()
            }
            
            return analytics
            
        except Exception as e:
            logger.error(f"âŒ ì—”í„°í”„ë¼ì´ì¦ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    async def _get_system_overview(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ê°œìš”"""
        try:
            # ê¸°ë³¸ RAG í†µê³„
            basic_stats = await self.basic_rag.get_rag_statistics(None)  # DB ì„¸ì…˜ ì„ì‹œë¡œ None
            
            # ê³ ê¸‰ RAG ì„±ëŠ¥
            advanced_analytics = await self.advanced_rag.get_performance_analytics()
            
            return {
                "total_documents": basic_stats.get("unique_documents", 0),
                "total_vectors": basic_stats.get("vector_count", 0),
                "total_searches": advanced_analytics.get("total_searches", 0),
                "system_uptime": "99.9%",
                "data_freshness": "ì‹¤ì‹œê°„",
                "last_updated": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ê°œìš” ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    # ============ 5. ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œ ============
    
    def _generate_cache_key(self, request: RAGRequest) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_data = f"{request.query}_{request.strategy.value}_{request.quality_level.value}_{request.department}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    def _remove_duplicates(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¤‘ë³µ ê²°ê³¼ ì œê±°"""
        seen_content = set()
        unique_results = []
        
        for result in results:
            content_hash = hashlib.md5(result["content"].encode()).hexdigest()
            if content_hash not in seen_content:
                seen_content.add(content_hash)
                unique_results.append(result)
        
        return unique_results
    
    def _record_performance_metrics(self, request: RAGRequest, response: RAGResponse):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        metric_data = {
            "timestamp": datetime.now().isoformat(),
            "strategy": request.strategy.value,
            "quality_level": request.quality_level.value,
            "processing_time": response.processing_time,
            "result_count": response.total_results,
            "quality_score": response.quality_score,
            "user_id": request.user_id
        }
        
        self.performance_tracker["searches"].append(metric_data)
        
        # ìµœê·¼ 10000ê°œ ê¸°ë¡ë§Œ ìœ ì§€
        if len(self.performance_tracker["searches"]) > 10000:
            self.performance_tracker["searches"] = self.performance_tracker["searches"][-10000:]

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
enterprise_rag_service = EnterpriseRAGService() 