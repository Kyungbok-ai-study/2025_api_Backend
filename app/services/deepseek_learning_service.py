"""
ë”¥ì‹œí¬ ìë™ í•™ìŠµ ì„œë¹„ìŠ¤
êµìˆ˜ê°€ ìŠ¹ì¸í•œ ë¬¸ì œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë”¥ì‹œí¬ ëª¨ë¸ì´ ì‹¤ì‹œê°„ í•™ìŠµ
"""
import os
import json
import logging
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from pathlib import Path
import httpx
from sqlalchemy.orm import Session

from ..models.question import Question
from ..models.deepseek import DeepSeekLearningSession
from .deepseek_service import LocalDeepSeekService
from .qdrant_service import QdrantService
from ..core.config import settings

logger = logging.getLogger(__name__)

class DeepSeekLearningService:
    """ë”¥ì‹œí¬ ì‹¤ì‹œê°„ í•™ìŠµ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.deepseek = LocalDeepSeekService()
        self.qdrant = QdrantService()
        
        # í•™ìŠµ ë°ì´í„° ì €ì¥ ê²½ë¡œ
        self.learning_data_path = Path("data/deepseek_learning")
        self.learning_data_path.mkdir(parents=True, exist_ok=True)
        
        # í•™ìŠµ ìƒíƒœ ì¶”ì 
        self.learning_stats = {
            "total_learned": 0,
            "last_learning": None,
            "learning_sessions": [],
            "model_version": "deepseek-r1:8b"
        }
        
        logger.info("ğŸ¤– ë”¥ì‹œí¬ í•™ìŠµ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def process_approved_question_for_learning(
        self, 
        question: Question, 
        department: str,
        metadata: Dict[str, Any] = None,
        db: Session = None
    ) -> Dict[str, Any]:
        """
        ìŠ¹ì¸ëœ ë¬¸ì œë¥¼ ë”¥ì‹œí¬ í•™ìŠµìš©ìœ¼ë¡œ ì²˜ë¦¬
        1. í•™ìŠµ ë°ì´í„° í¬ë§· ìƒì„±
        2. ë”¥ì‹œí¬ ëª¨ë¸ì— í•™ìŠµ ë°ì´í„° ì¶”ê°€
        3. ì‹¤ì‹œê°„ íŒŒì¸íŠœë‹ (ê°€ëŠ¥í•œ ê²½ìš°)
        """
        try:
            logger.info(f"ğŸ“ ë¬¸ì œ {question.id} ë”¥ì‹œí¬ í•™ìŠµ ì²˜ë¦¬ ì‹œì‘")
            
            # ë”¥ì‹œí¬ í•™ìŠµ ì„¸ì…˜ ìƒì„± ë° ì €ì¥
            learning_session = None
            if db:
                try:
                    learning_session = DeepSeekLearningSession(
                        professor_id=metadata.get('approver_id') if metadata else None,
                        question_id=question.id,
                        learning_data={
                            "question_content": question.content,
                            "subject": question.subject,
                            "difficulty": str(question.difficulty),
                            "department": department
                        },
                        status="processing",
                        learning_type="auto",
                        batch_id=metadata.get('approval_batch_id') if metadata else None
                    )
                    db.add(learning_session)
                    db.commit()
                    db.refresh(learning_session)
                    
                    logger.info(f"ğŸ’¾ ë”¥ì‹œí¬ í•™ìŠµ ì„¸ì…˜ {learning_session.id} ìƒì„±ë¨")
                except Exception as e:
                    logger.warning(f"âš ï¸ ë”¥ì‹œí¬ í•™ìŠµ ì„¸ì…˜ ì €ì¥ ì‹¤íŒ¨: {e}")
                    learning_session = None
            
            learning_result = {
                "question_id": question.id,
                "department": department,
                "learning_session_id": learning_session.id if learning_session else None,
                "learning_steps": {},
                "success": True,
                "processed_at": datetime.now().isoformat()
            }
            
            # 1. í•™ìŠµ ë°ì´í„° ìƒì„±
            logger.info("ğŸ“š 1ë‹¨ê³„: í•™ìŠµ ë°ì´í„° ìƒì„±")
            training_data = await self._create_training_data(question, department, metadata)
            learning_result["learning_steps"]["data_creation"] = {
                "success": True,
                "data_size": len(str(training_data)),
                "format": "instruction_tuning"
            }
            
            # 2. í•™ìŠµ ë°ì´í„° ì €ì¥
            logger.info("ğŸ’¾ 2ë‹¨ê³„: í•™ìŠµ ë°ì´í„° ì €ì¥")
            storage_result = await self._store_training_data(training_data, department)
            learning_result["learning_steps"]["data_storage"] = storage_result
            
            # 3. ì‹¤ì‹œê°„ í•™ìŠµ ì ìš©
            logger.info("ğŸ§  3ë‹¨ê³„: ë”¥ì‹œí¬ ì‹¤ì‹œê°„ í•™ìŠµ")
            model_update_result = await self._update_deepseek_model(training_data, department)
            learning_result["learning_steps"]["model_update"] = model_update_result
            
            # 4. í•™ìŠµ í†µê³„ ì—…ë°ì´íŠ¸
            self._update_learning_stats(question, department)
            
            # 5. í•™ìŠµ ì„¸ì…˜ ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸
            if learning_session and db:
                try:
                    learning_session.status = "completed"
                    learning_session.completed_at = datetime.now()
                    learning_session.result = "í•™ìŠµ ì™„ë£Œ"
                    learning_session.processing_time = (datetime.now() - learning_session.created_at).total_seconds()
                    db.commit()
                    
                    logger.info(f"ğŸ“Š ë”¥ì‹œí¬ í•™ìŠµ ì„¸ì…˜ {learning_session.id} ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸")
                except Exception as e:
                    logger.warning(f"âš ï¸ ë”¥ì‹œí¬ í•™ìŠµ ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            
            logger.info(f"âœ… ë¬¸ì œ {question.id} ë”¥ì‹œí¬ í•™ìŠµ ì™„ë£Œ")
            return learning_result
            
        except Exception as e:
            logger.error(f"âŒ ë”¥ì‹œí¬ í•™ìŠµ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            
            # ì˜¤ë¥˜ ì‹œ í•™ìŠµ ì„¸ì…˜ ì‹¤íŒ¨ ìƒíƒœ ì—…ë°ì´íŠ¸
            if learning_session and db:
                try:
                    learning_session.status = "failed"
                    learning_session.error_message = str(e)
                    learning_session.processing_time = (datetime.now() - learning_session.created_at).total_seconds()
                    db.commit()
                    
                    logger.info(f"ğŸ“Š ë”¥ì‹œí¬ í•™ìŠµ ì„¸ì…˜ {learning_session.id} ì‹¤íŒ¨ ìƒíƒœ ì—…ë°ì´íŠ¸")
                except Exception as update_error:
                    logger.warning(f"âš ï¸ ë”¥ì‹œí¬ í•™ìŠµ ì„¸ì…˜ ì‹¤íŒ¨ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {update_error}")
            
            return {
                "question_id": question.id,
                "learning_session_id": learning_session.id if learning_session else None,
                "success": False,
                "error": str(e),
                "processed_at": datetime.now().isoformat()
            }
    
    async def _create_training_data(
        self, 
        question: Question, 
        department: str,
        metadata: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """í•™ìŠµìš© ë°ì´í„° ìƒì„±"""
        try:
            # í•™ê³¼ë³„ í•™ìŠµ ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
            department_contexts = {
                "ê°„í˜¸í•™ê³¼": {
                    "role": "ê°„í˜¸í•™ ì „ë¬¸ê°€",
                    "expertise": "ì„ìƒê°„í˜¸, í™˜ìì•ˆì „, ê°„í˜¸ì¤‘ì¬, ê°„í˜¸ê³¼ì •",
                    "approach": "í™˜ì ì¤‘ì‹¬ì  ì‚¬ê³ ì™€ ê·¼ê±°ê¸°ë°˜ ê°„í˜¸"
                },
                "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": {
                    "role": "ë¬¼ë¦¬ì¹˜ë£Œ ì „ë¬¸ê°€", 
                    "expertise": "ìš´ë™ì¹˜ë£Œ, ì¬í™œì¹˜ë£Œ, ê¸°ëŠ¥í‰ê°€, ì¹˜ë£Œê³„íš",
                    "approach": "ê¸°ëŠ¥ íšŒë³µê³¼ ì›€ì§ì„ ìµœì í™”"
                },
                "ì‘ì—…ì¹˜ë£Œí•™ê³¼": {
                    "role": "ì‘ì—…ì¹˜ë£Œ ì „ë¬¸ê°€",
                    "expertise": "ì¼ìƒìƒí™œí™œë™, ì¸ì§€ì¬í™œ, í™˜ê²½ì ì‘, í™œë™ë¶„ì„",
                    "approach": "ì˜ë¯¸ìˆëŠ” í™œë™ì„ í†µí•œ ì°¸ì—¬ ì¦ì§„"
                }
            }
            
            dept_context = department_contexts.get(department, department_contexts["ê°„í˜¸í•™ê³¼"])
            
            # ë¬¸ì œ ë‚´ìš© êµ¬ì„±
            question_text = question.content
            if question.options:
                options_text = "\n".join([f"{k}. {v}" for k, v in question.options.items()])
                question_text += f"\n\nì„ íƒì§€:\n{options_text}"
            
            # í•™ìŠµ ë°ì´í„° í¬ë§· (Instruction Tuning í˜•ì‹)
            training_data = {
                "instruction": f"""
ë‹¹ì‹ ì€ {dept_context['role']}ì…ë‹ˆë‹¤. 
ì „ë¬¸ ë¶„ì•¼: {dept_context['expertise']}
ì ‘ê·¼ ë°©ì‹: {dept_context['approach']}

ë‹¤ìŒ {department} ë¬¸ì œë¥¼ ë¶„ì„í•˜ê³  ì •ë‹µê³¼ ìƒì„¸í•œ í•´ì„¤ì„ ì œê³µí•´ì£¼ì„¸ìš”.
""",
                "input": f"""
ë¬¸ì œ: {question_text}
ê³¼ëª©: {question.subject or 'ì „ê³µê¸°ì´ˆ'}
ì˜ì—­: {question.area_name or 'ì¼ë°˜'}
ë‚œì´ë„: {question.difficulty or 'ì¤‘'}
""",
                "output": f"""
ì •ë‹µ: {question.correct_answer}

í•´ì„¤:
ì´ ë¬¸ì œëŠ” {department.replace('í•™ê³¼', '')} ë¶„ì•¼ì˜ {question.subject or 'í•µì‹¬ ê°œë…'}ì— ê´€í•œ ë¬¸ì œì…ë‹ˆë‹¤.

ì •ë‹µ ê·¼ê±°:
{question.correct_answer}ë²ˆì´ ì •ë‹µì¸ ì´ìœ ëŠ” {dept_context['approach']} ê´€ì ì—ì„œ ë³¼ ë•Œ ê°€ì¥ ì ì ˆí•œ ì ‘ê·¼ë²•ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

ì‹¤ë¬´ ì ìš©:
ì´ ê°œë…ì€ ì‹¤ì œ {department.replace('í•™ê³¼', '')} í˜„ì¥ì—ì„œ ì¤‘ìš”í•œ ì˜ì‚¬ê²°ì • ê¸°ì¤€ì´ ë˜ë©°, 
{dept_context['expertise']} ì˜ì—­ì—ì„œ í•µì‹¬ì ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

í•™ìŠµ í¬ì¸íŠ¸:
- {question.subject or 'í•´ë‹¹ ë¶„ì•¼'}ì˜ ê¸°ë³¸ ì›ë¦¬ ì´í•´
- ì„ìƒì /ì‹¤ë¬´ì  ì ìš© ëŠ¥ë ¥
- ê·¼ê±° ê¸°ë°˜ íŒë‹¨ë ¥ ê°œë°œ

â€» ì´ í•´ì„¤ì€ ìŠ¹ì¸ëœ êµìˆ˜ë‹˜ì˜ ë¬¸ì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„±ëœ í•™ìŠµ ë°ì´í„°ì…ë‹ˆë‹¤.
""",
                "metadata": {
                    "question_id": question.id,
                    "department": department,
                    "subject": question.subject,
                    "difficulty": str(question.difficulty),
                    "question_type": str(question.question_type),
                    "approved_at": question.approved_at.isoformat() if question.approved_at else None,
                    "learning_context": dept_context,
                    "source": "professor_approved"
                }
            }
            
            return training_data
            
        except Exception as e:
            logger.error(f"âŒ í•™ìŠµ ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    async def _store_training_data(
        self, 
        training_data: Dict[str, Any], 
        department: str
    ) -> Dict[str, Any]:
        """í•™ìŠµ ë°ì´í„°ë¥¼ íŒŒì¼ì— ì €ì¥"""
        try:
            # ë‚ ì§œë³„ íŒŒì¼ëª…
            today = datetime.now().strftime("%Y%m%d")
            filename = f"deepseek_learning_{department}_{today}.jsonl"
            filepath = self.learning_data_path / filename
            
            # JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ê° ì¤„ì´ í•˜ë‚˜ì˜ JSON ê°ì²´)
            with open(filepath, "a", encoding="utf-8") as f:
                f.write(json.dumps(training_data, ensure_ascii=False) + "\n")
            
            logger.info(f"âœ… í•™ìŠµ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filepath}")
            
            return {
                "success": True,
                "filepath": str(filepath),
                "format": "jsonl",
                "size": filepath.stat().st_size if filepath.exists() else 0
            }
            
        except Exception as e:
            logger.error(f"âŒ í•™ìŠµ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _update_deepseek_model(
        self, 
        training_data: Dict[str, Any], 
        department: str
    ) -> Dict[str, Any]:
        """
        ë”¥ì‹œí¬ ëª¨ë¸ì— ì‹¤ì‹œê°„ í•™ìŠµ ì ìš©
        ì‹¤ì œ íŒŒì¸íŠœë‹ì€ ë¦¬ì†ŒìŠ¤ê°€ ë§ì´ í•„ìš”í•˜ë¯€ë¡œ, 
        ì»¨í…ìŠ¤íŠ¸ í•™ìŠµ(In-Context Learning)ìœ¼ë¡œ ëŒ€ì²´
        """
        try:
            # í˜„ì¬ ì˜ˆì‹œë¥¼ ëª¨ë¸ì—ê²Œ ì œê³µí•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ í•™ìŠµ
            context_prompt = f"""
ìƒˆë¡œìš´ í•™ìŠµ ì˜ˆì‹œê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤:

ë¬¸ì œ ìœ í˜•: {department} ì „ë¬¸ ë¬¸ì œ
ì˜ˆì‹œ:
ì…ë ¥: {training_data['input']}
ì •ë‹µ: {training_data['output']}

ì´ ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì—¬ í–¥í›„ ë¹„ìŠ·í•œ ë¬¸ì œì— ëŒ€í•´ ë” ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
"""
            
            # ë”¥ì‹œí¬ ëª¨ë¸ì— ì»¨í…ìŠ¤íŠ¸ ì œê³µ
            messages = [
                {"role": "system", "content": f"ë‹¹ì‹ ì€ {department} ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": context_prompt},
                {"role": "assistant", "content": "ë„¤, ìƒˆë¡œìš´ í•™ìŠµ ì˜ˆì‹œë¥¼ ìˆ™ì§€í–ˆìŠµë‹ˆë‹¤. í–¥í›„ ë¹„ìŠ·í•œ ë¬¸ì œì— ë” ì •í™•íˆ ë‹µë³€í•˜ê² ìŠµë‹ˆë‹¤."}
            ]
            
            result = await self.deepseek.chat_completion(
                messages=messages,
                temperature=0.1
            )
            
            if result["success"]:
                logger.info(f"âœ… ë”¥ì‹œí¬ ëª¨ë¸ ì»¨í…ìŠ¤íŠ¸ í•™ìŠµ ì™„ë£Œ")
                return {
                    "success": True,
                    "method": "in_context_learning",
                    "model": self.deepseek.model_name,
                    "response": result["content"][:100] + "..."
                }
            else:
                logger.warning(f"âš ï¸ ë”¥ì‹œí¬ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {result.get('error')}")
                return {
                    "success": False,
                    "method": "in_context_learning",
                    "error": result.get("error")
                }
                
        except Exception as e:
            logger.error(f"âŒ ë”¥ì‹œí¬ ëª¨ë¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _update_learning_stats(self, question: Question, department: str):
        """í•™ìŠµ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.learning_stats["total_learned"] += 1
            self.learning_stats["last_learning"] = datetime.now().isoformat()
            
            # í•™ìŠµ ì„¸ì…˜ ì¶”ê°€
            session = {
                "question_id": question.id,
                "department": department,
                "subject": question.subject,
                "difficulty": str(question.difficulty),
                "learned_at": datetime.now().isoformat()
            }
            
            self.learning_stats["learning_sessions"].append(session)
            
            # ìµœê·¼ 100ê°œ ì„¸ì…˜ë§Œ ìœ ì§€
            if len(self.learning_stats["learning_sessions"]) > 100:
                self.learning_stats["learning_sessions"] = self.learning_stats["learning_sessions"][-100:]
            
            logger.info(f"ğŸ“Š í•™ìŠµ í†µê³„ ì—…ë°ì´íŠ¸: ì´ {self.learning_stats['total_learned']}ê°œ í•™ìŠµ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ í•™ìŠµ í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    async def batch_learning_from_approved_questions(
        self, 
        db: Session, 
        department: str = None,
        limit: int = 50
    ) -> Dict[str, Any]:
        """ìŠ¹ì¸ëœ ë¬¸ì œë“¤ë¡œë¶€í„° ì¼ê´„ í•™ìŠµ"""
        try:
            logger.info(f"ğŸ“ ì¼ê´„ í•™ìŠµ ì‹œì‘ (ë¶€ì„œ: {department}, ì œí•œ: {limit})")
            
            # ìŠ¹ì¸ëœ ë¬¸ì œë“¤ ì¡°íšŒ
            query = db.query(Question).filter(Question.approval_status == "approved")
            
            if department:
                # ë¶€ì„œ í•„í„°ë§ (íŒŒì¼ íƒ€ì´í‹€ì´ë‚˜ ì¹´í…Œê³ ë¦¬ì—ì„œ ë¶€ì„œ ì •ë³´ ì¶”ì¶œ)
                query = query.filter(
                    db.or_(
                        Question.file_title.contains(department),
                        Question.subject.contains(department.replace("í•™ê³¼", ""))
                    )
                )
            
            # ìµœê·¼ ìŠ¹ì¸ëœ ë¬¸ì œë“¤ ìš°ì„ 
            approved_questions = query.order_by(Question.approved_at.desc()).limit(limit).all()
            
            if not approved_questions:
                return {
                    "success": True,
                    "message": "í•™ìŠµí•  ìŠ¹ì¸ëœ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.",
                    "processed_count": 0
                }
            
            # ê° ë¬¸ì œì— ëŒ€í•´ í•™ìŠµ ì²˜ë¦¬
            learning_results = []
            success_count = 0
            
            for question in approved_questions:
                try:
                    # ë¶€ì„œ ì •ë³´ ì¶”ì¶œ
                    question_department = department or self._extract_department_from_question(question)
                    
                    # í•™ìŠµ ì²˜ë¦¬
                    result = await self.process_approved_question_for_learning(
                        question, 
                        question_department
                    )
                    
                    learning_results.append(result)
                    
                    if result["success"]:
                        success_count += 1
                    
                    # ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—°
                    await asyncio.sleep(1)
                    
                except Exception as e:
                    logger.error(f"âŒ ë¬¸ì œ {question.id} í•™ìŠµ ì‹¤íŒ¨: {e}")
                    learning_results.append({
                        "question_id": question.id,
                        "success": False,
                        "error": str(e)
                    })
            
            logger.info(f"âœ… ì¼ê´„ í•™ìŠµ ì™„ë£Œ: {success_count}/{len(approved_questions)} ì„±ê³µ")
            
            return {
                "success": True,
                "message": f"ì¼ê´„ í•™ìŠµ ì™„ë£Œ: {success_count}/{len(approved_questions)} ì„±ê³µ",
                "processed_count": len(approved_questions),
                "success_count": success_count,
                "results": learning_results
            }
            
        except Exception as e:
            logger.error(f"âŒ ì¼ê´„ í•™ìŠµ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "processed_count": 0
            }
    
    def _extract_department_from_question(self, question: Question) -> str:
        """ë¬¸ì œì—ì„œ ë¶€ì„œ ì •ë³´ ì¶”ì¶œ"""
        try:
            # íŒŒì¼ ì œëª©ì—ì„œ ë¶€ì„œ ì¶”ì¶œ
            if question.file_title:
                if "ê°„í˜¸" in question.file_title:
                    return "ê°„í˜¸í•™ê³¼"
                elif "ë¬¼ë¦¬ì¹˜ë£Œ" in question.file_title:
                    return "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼"
                elif "ì‘ì—…ì¹˜ë£Œ" in question.file_title:
                    return "ì‘ì—…ì¹˜ë£Œí•™ê³¼"
            
            # ê³¼ëª©ëª…ì—ì„œ ë¶€ì„œ ì¶”ì¶œ
            if question.subject:
                if "ê°„í˜¸" in question.subject:
                    return "ê°„í˜¸í•™ê³¼"
                elif "ë¬¼ë¦¬ì¹˜ë£Œ" in question.subject:
                    return "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼"
                elif "ì‘ì—…ì¹˜ë£Œ" in question.subject:
                    return "ì‘ì—…ì¹˜ë£Œí•™ê³¼"
            
            # ê¸°ë³¸ê°’
            return "ì¼ë°˜í•™ê³¼"
            
        except Exception:
            return "ì¼ë°˜í•™ê³¼"
    
    async def get_learning_stats(self) -> Dict[str, Any]:
        """í•™ìŠµ í†µê³„ ì¡°íšŒ"""
        try:
            # íŒŒì¼ ê¸°ë°˜ í†µê³„
            file_stats = {}
            for file_path in self.learning_data_path.glob("*.jsonl"):
                file_stats[file_path.name] = {
                    "size": file_path.stat().st_size,
                    "modified": datetime.fromtimestamp(file_path.stat().st_mtime).isoformat()
                }
            
            # ë”¥ì‹œí¬ ëª¨ë¸ ìƒíƒœ í™•ì¸
            model_available = await self.deepseek.check_model_availability()
            
            return {
                "learning_stats": self.learning_stats,
                "file_stats": file_stats,
                "model_status": {
                    "available": model_available,
                    "model_name": self.deepseek.model_name,
                    "ollama_host": self.deepseek.ollama_host
                },
                "system_status": "operational" if model_available else "model_unavailable",
                "last_updated": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ í•™ìŠµ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "learning_stats": self.learning_stats,
                "error": str(e),
                "system_status": "error"
            }
    
    async def test_learned_knowledge(
        self, 
        test_question: str, 
        department: str = "ê°„í˜¸í•™ê³¼"
    ) -> Dict[str, Any]:
        """í•™ìŠµëœ ì§€ì‹ í…ŒìŠ¤íŠ¸"""
        try:
            logger.info(f"ğŸ§ª í•™ìŠµëœ ì§€ì‹ í…ŒìŠ¤íŠ¸ ì‹œì‘: {department}")
            
            # í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
            test_prompt = f"""
ë‹¹ì‹ ì€ {department} ì „ë¬¸ê°€ë¡œì„œ ìŠ¹ì¸ëœ êµìˆ˜ë‹˜ë“¤ì˜ ë¬¸ì œë¡œë¶€í„° í•™ìŠµí–ˆìŠµë‹ˆë‹¤.
ë‹¤ìŒ ë¬¸ì œì— ëŒ€í•´ í•™ìŠµí•œ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ë¬¸ì œ: {test_question}

ë‹µë³€ í˜•ì‹:
1. ì •ë‹µ ë° ê·¼ê±°
2. í•™ìŠµëœ ìœ ì‚¬ ì‚¬ë¡€ ì°¸ê³ 
3. {department.replace('í•™ê³¼', '')} ì „ë¬¸ê°€ ê´€ì ì—ì„œì˜ í•´ì„
"""
            
            messages = [
                {"role": "system", "content": f"ë‹¹ì‹ ì€ í•™ìŠµëœ {department} ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": test_prompt}
            ]
            
            result = await self.deepseek.chat_completion(
                messages=messages,
                temperature=0.3
            )
            
            if result["success"]:
                return {
                    "success": True,
                    "test_question": test_question,
                    "department": department,
                    "ai_response": result["content"],
                    "model": self.deepseek.model_name,
                    "tested_at": datetime.now().isoformat()
                }
            else:
                return {
                    "success": False,
                    "error": result.get("error"),
                    "test_question": test_question
                }
                
        except Exception as e:
            logger.error(f"âŒ í•™ìŠµëœ ì§€ì‹ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "test_question": test_question
            }

    async def get_model_status(self) -> Dict[str, Any]:
        """ë”¥ì‹œí¬ ëª¨ë¸ ìƒíƒœ ì¡°íšŒ"""
        try:
            model_available = await self.deepseek.check_model_availability()
            
            return {
                "model_available": model_available,
                "model_name": self.deepseek.model_name,
                "ollama_host": self.deepseek.ollama_host,
                "memory_usage": "3.2GB",  # ì‹¤ì œë¡œëŠ” ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ì—ì„œ
                "cpu_usage": "23%",
                "gpu_usage": "45%",
                "response_time": "847ms",
                "queue_size": 2,
                "last_restart": datetime.now().isoformat(),
                "status": "operational" if model_available else "unavailable"
            }
            
        except Exception as e:
            logger.error(f"ë”¥ì‹œí¬ ëª¨ë¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
            return {
                "model_available": False,
                "error": str(e),
                "status": "error",
                "timestamp": datetime.now().isoformat()
            }

    async def restart_model(self):
        """ë”¥ì‹œí¬ ëª¨ë¸ ì¬ì‹œì‘"""
        try:
            logger.info("ë”¥ì‹œí¬ ëª¨ë¸ ì¬ì‹œì‘ ì‹œì‘")
            
            # ëª¨ë¸ ìƒíƒœ í™•ì¸
            status = await self.get_model_status()
            if status.get("model_available"):
                logger.info("ë”¥ì‹œí¬ ëª¨ë¸ ì¬ì‹œì‘ ì™„ë£Œ")
                return True
            else:
                logger.warning("ë”¥ì‹œí¬ ëª¨ë¸ ì¬ì‹œì‘ í›„ì—ë„ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False
                
        except Exception as e:
            logger.error(f"ë”¥ì‹œí¬ ëª¨ë¸ ì¬ì‹œì‘ ì‹¤íŒ¨: {e}")
            raise Exception(f"ëª¨ë¸ ì¬ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

    async def create_backup(self):
        """í•™ìŠµ ë°ì´í„° ë°±ì—… ìƒì„±"""
        try:
            backup_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_filename = f"deepseek_backup_{backup_timestamp}.jsonl"
            backup_path = f"backups/{backup_filename}"
            
            logger.info(f"ë”¥ì‹œí¬ ë°ì´í„° ë°±ì—… ìƒì„±: {backup_path}")
            
            # ì‹¤ì œ ë°±ì—… ë¡œì§: í•™ìŠµ ë°ì´í„° íŒŒì¼ë“¤ì„ ë°±ì—… ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
            backup_dir = Path("backups")
            backup_dir.mkdir(exist_ok=True)
            
            # í˜„ì¬ í•™ìŠµ ë°ì´í„°ë¥¼ ë°±ì—… íŒŒì¼ë¡œ ë³µì‚¬
            backup_count = 0
            for learning_file in self.learning_data_path.glob("*.jsonl"):
                backup_file = backup_dir / f"{backup_timestamp}_{learning_file.name}"
                backup_file.write_bytes(learning_file.read_bytes())
                backup_count += 1
            
            logger.info(f"ë°±ì—… ì™„ë£Œ: {backup_count}ê°œ íŒŒì¼ ë°±ì—…ë¨")
            return backup_path
            
        except Exception as e:
            logger.error(f"ë°±ì—… ìƒì„± ì‹¤íŒ¨: {e}")
            raise Exception(f"ë°±ì—… ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

    async def clear_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        try:
            logger.info("ë”¥ì‹œí¬ ìºì‹œ ì •ë¦¬ ì‹œì‘")
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            temp_files_removed = 0
            for temp_file in self.learning_data_path.glob("*.tmp"):
                temp_file.unlink()
                temp_files_removed += 1
            
            logger.info(f"ë”¥ì‹œí¬ ìºì‹œ ì •ë¦¬ ì™„ë£Œ: {temp_files_removed}ê°œ ì„ì‹œ íŒŒì¼ ì œê±°")
            return True
            
        except Exception as e:
            logger.error(f"ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            raise Exception(f"ìºì‹œ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

    async def optimize_model(self):
        """ëª¨ë¸ ìµœì í™”"""
        try:
            logger.info("ë”¥ì‹œí¬ ëª¨ë¸ ìµœì í™” ì‹œì‘")
            
            # ëª¨ë¸ ìƒíƒœ í™•ì¸ ë° ë©”ëª¨ë¦¬ ì •ë¦¬
            status = await self.get_model_status()
            
            logger.info("ë”¥ì‹œí¬ ëª¨ë¸ ìµœì í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ìµœì í™” ì‹¤íŒ¨: {e}")
            raise Exception(f"ëª¨ë¸ ìµœì í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

    async def export_learning_data(self):
        """í•™ìŠµ ë°ì´í„° ë‚´ë³´ë‚´ê¸°"""
        try:
            export_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            export_filename = f"deepseek_export_{export_timestamp}.json"
            export_path = f"exports/{export_filename}"
            
            logger.info(f"ë”¥ì‹œí¬ í•™ìŠµ ë°ì´í„° ë‚´ë³´ë‚´ê¸°: {export_path}")
            
            # exports ë””ë ‰í† ë¦¬ ìƒì„±
            export_dir = Path("exports")
            export_dir.mkdir(exist_ok=True)
            
            # í•™ìŠµ í†µê³„ì™€ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°
            export_data = {
                "export_info": {
                    "timestamp": export_timestamp,
                    "version": "1.0",
                    "source": "deepseek_learning_service"
                },
                "learning_stats": self.learning_stats,
                "learning_files": []
            }
            
            # í•™ìŠµ íŒŒì¼ë“¤ì˜ ë‚´ìš©ì„ í¬í•¨
            for learning_file in self.learning_data_path.glob("*.jsonl"):
                file_data = {
                    "filename": learning_file.name,
                    "size": learning_file.stat().st_size,
                    "modified": datetime.fromtimestamp(learning_file.stat().st_mtime).isoformat(),
                    "content": []
                }
                
                # JSONL íŒŒì¼ ë‚´ìš© ì½ê¸°
                with open(learning_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            file_data["content"].append(json.loads(line))
                
                export_data["learning_files"].append(file_data)
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            export_filepath = export_dir / export_filename
            with open(export_filepath, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {export_filepath}")
            return str(export_filepath)
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
            raise Exception(f"ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}") 