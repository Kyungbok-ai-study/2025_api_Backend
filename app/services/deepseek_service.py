"""
ë¡œì»¬ DeepSeek ì„œë¹„ìŠ¤
Ollamaë¥¼ í†µí•œ ë¡œì»¬ DeepSeek ëª¨ë¸ ì‹¤í–‰
OpenAI + Gemini APIë¥¼ ë¡œì»¬ DeepSeekìœ¼ë¡œ í†µí•© ëŒ€ì²´
"""
import os
import json
import logging
import asyncio
from typing import List, Dict, Any, Optional, Union
from datetime import datetime
import httpx
import base64
from pathlib import Path
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

logger = logging.getLogger(__name__)

class LocalDeepSeekService:
    """ë¡œì»¬ DeepSeek AI ì„œë¹„ìŠ¤ (Ollama ê¸°ë°˜)"""
    
    def __init__(self):
        # Ollama ì„œë²„ ì„¤ì •
        self.ollama_host = "http://localhost:11434"
        self.model_name = "deepseek-r1:8b"
        self.embedding_model = "nomic-embed-text"
        
        # HTTP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self._client = None
        self._init_client()
        
        logger.info(f"âœ… ë¡œì»¬ DeepSeek ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"ğŸ”— Ollama ì„œë²„: {self.ollama_host}")
        logger.info(f"ğŸ¤– ì‚¬ìš© ëª¨ë¸: {self.model_name}")
    
    def _init_client(self):
        """HTTP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        self._client = httpx.AsyncClient(
            base_url=self.ollama_host,
            headers={"Content-Type": "application/json"},
            timeout=120.0  # ë¡œì»¬ ëª¨ë¸ì€ ë” ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ
        )
    
    async def check_model_availability(self) -> bool:
        """ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸"""
        try:
            response = await self._client.get("/api/tags")
            if response.status_code == 200:
                models = response.json().get("models", [])
                available_models = [model["name"] for model in models]
                
                if self.model_name in available_models:
                    logger.info(f"âœ… ëª¨ë¸ {self.model_name} ì‚¬ìš© ê°€ëŠ¥")
                    return True
                else:
                    logger.warning(f"âŒ ëª¨ë¸ {self.model_name} ì—†ìŒ. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {available_models}")
                    return False
            else:
                logger.error(f"âŒ Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False
    
    async def chat_completion(
        self, 
        messages: List[Dict[str, str]], 
        temperature: float = 0.7,
        max_tokens: int = 2048,
        model: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Ollamaë¥¼ í†µí•œ ì±„íŒ… ì™„ì„±
        OpenAI ChatCompletionê³¼ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤
        """
        if not self._client:
            raise ValueError("Ollama í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            # ë©”ì‹œì§€ë¥¼ í•˜ë‚˜ì˜ í”„ë¡¬í”„íŠ¸ë¡œ ê²°í•© (Ollama í˜•ì‹)
            prompt = self._messages_to_prompt(messages)
            
            payload = {
                "model": model or self.model_name,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": temperature,
                    "num_predict": max_tokens,
                }
            }
            
            response = await self._client.post("/api/generate", json=payload)
            response.raise_for_status()
            result = response.json()
            
            return {
                "success": True,
                "content": result.get("response", ""),
                "model": model or self.model_name,
                "done": result.get("done", True)
            }
            
        except Exception as e:
            logger.error(f"ë¡œì»¬ DeepSeek ì±„íŒ… ì™„ì„± ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e),
                "content": ""
            }
    
    def _messages_to_prompt(self, messages: List[Dict[str, str]]) -> str:
        """OpenAI ë©”ì‹œì§€ í˜•ì‹ì„ ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜"""
        prompt_parts = []
        
        for message in messages:
            role = message.get("role", "user")
            content = message.get("content", "")
            
            if role == "system":
                prompt_parts.append(f"System: {content}")
            elif role == "user":
                prompt_parts.append(f"Human: {content}")
            elif role == "assistant":
                prompt_parts.append(f"Assistant: {content}")
        
        prompt_parts.append("Assistant:")
        return "\n\n".join(prompt_parts)
    
    async def create_embeddings(
        self, 
        texts: Union[str, List[str]], 
        model: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Ollamaë¥¼ í†µí•œ ì„ë² ë”© ìƒì„±
        OpenAI Embeddingê³¼ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤
        """
        if not self._client:
            raise ValueError("Ollama í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ë‹¨ì¼ í…ìŠ¤íŠ¸ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if isinstance(texts, str):
            texts = [texts]
        
        try:
            embeddings = []
            embedding_model = model or self.embedding_model
            
            for text in texts:
                payload = {
                    "model": embedding_model,
                    "prompt": text
                }
                
                response = await self._client.post("/api/embeddings", json=payload)
                response.raise_for_status()
                result = response.json()
                
                if "embedding" in result:
                    embeddings.append(result["embedding"])
                else:
                    logger.warning(f"ì„ë² ë”© ê²°ê³¼ ì—†ìŒ: {text[:50]}...")
                    # ê¸°ë³¸ ì„ë² ë”© ìƒì„± (768 ì°¨ì›)
                    embeddings.append([0.0] * 768)
            
            return {
                "success": True,
                "embeddings": embeddings,
                "model": embedding_model
            }
            
        except Exception as e:
            logger.error(f"ë¡œì»¬ DeepSeek ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")
            # ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ì„ë² ë”© ë°˜í™˜
            fallback_embeddings = [[0.0] * 768] * len(texts)
            return {
                "success": False,
                "error": str(e),
                "embeddings": fallback_embeddings
            }
    
    async def parse_document(
        self, 
        file_path: str, 
        content_type: str = "auto",
        max_pages: int = 50
    ) -> Dict[str, Any]:
        """
        ë¬¸ì„œ íŒŒì‹± (Gemini ëŒ€ì²´)
        í…ìŠ¤íŠ¸ íŒŒì¼ì€ ì§ì ‘ ì²˜ë¦¬, ì´ë¯¸ì§€ëŠ” OCR í›„ ì²˜ë¦¬
        """
        try:
            file_extension = Path(file_path).suffix.lower()
            
            # í…ìŠ¤íŠ¸ íŒŒì¼ ì§ì ‘ ì²˜ë¦¬
            if file_extension in ['.txt', '.md', '.json']:
                with open(file_path, 'r', encoding='utf-8') as f:
                    text_content = f.read()
                
                prompt = self._build_text_parse_prompt(content_type, text_content)
                messages = [{"role": "user", "content": prompt}]
                
            elif file_extension in ['.pdf', '.jpg', '.jpeg', '.png']:
                # ì´ë¯¸ì§€/PDFëŠ” OCR í›„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                extracted_text = await self._extract_text_from_image_pdf(file_path)
                
                if not extracted_text:
                    return {
                        "success": False,
                        "error": "í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨",
                        "data": []
                    }
                
                prompt = self._build_text_parse_prompt(content_type, extracted_text)
                messages = [{"role": "user", "content": prompt}]
                
            else:
                return {
                    "success": False,
                    "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_extension}",
                    "data": []
                }
            
            # DeepSeekë¡œ íŒŒì‹± ìš”ì²­
            result = await self.chat_completion(
                messages=messages,
                temperature=0.1,  # ì •í™•í•œ íŒŒì‹±ì„ ìœ„í•´ ë‚®ì€ temperature
                max_tokens=4096
            )
            
            if result["success"]:
                # JSON ì‘ë‹µ íŒŒì‹±
                parsed_data = self._parse_structured_response(result["content"], content_type)
                return {
                    "success": True,
                    "type": content_type,
                    "data": parsed_data,
                    "source_file": file_path
                }
            else:
                return {
                    "success": False,
                    "error": result["error"],
                    "data": []
                }
                
        except Exception as e:
            logger.error(f"ë¬¸ì„œ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e),
                "data": []
            }
    
    async def _extract_text_from_image_pdf(self, file_path: str) -> str:
        """ì´ë¯¸ì§€/PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (OCR)"""
        try:
            file_extension = Path(file_path).suffix.lower()
            
            if file_extension == '.pdf':
                # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
                try:
                    import PyPDF2
                    with open(file_path, 'rb') as f:
                        reader = PyPDF2.PdfReader(f)
                        text = ""
                        for page in reader.pages:
                            text += page.extract_text() + "\n"
                    return text
                except ImportError:
                    logger.warning("PyPDF2ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ, OCR ì‹œë„")
                except:
                    logger.warning("PyPDF2 í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨, OCR ì‹œë„")
            
            # ì´ë¯¸ì§€ OCR (Tesseract ì‚¬ìš©)
            try:
                import pytesseract
                from PIL import Image
                
                # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ í›„ OCR
                if file_extension == '.pdf':
                    import pdf2image
                    pages = pdf2image.convert_from_path(file_path)
                    text = ""
                    for page in pages:
                        text += pytesseract.image_to_string(page, lang='kor+eng') + "\n"
                    return text
                else:
                    # ì´ë¯¸ì§€ íŒŒì¼ ì§ì ‘ OCR
                    image = Image.open(file_path)
                    text = pytesseract.image_to_string(image, lang='kor+eng')
                    return text
                    
            except Exception as ocr_error:
                logger.error(f"OCR ì²˜ë¦¬ ì‹¤íŒ¨: {ocr_error}")
                return ""
                
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return ""
    
    def _build_text_parse_prompt(self, content_type: str, text_content: str) -> str:
        """í…ìŠ¤íŠ¸ íŒŒì‹± í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        base_schema = """
Question ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°:
- question_number: ë¬¸ì œ ë²ˆí˜¸ (1~22)
- content: ë¬¸ì œ ë‚´ìš©
- description: ë¬¸ì œ ì„¤ëª…/ì§€ë¬¸ (ë¬¸ìì—´ ë°°ì—´)
- options: {"1": "ì„ íƒì§€1", "2": "ì„ íƒì§€2", ...}
- correct_answer: ì •ë‹µ (ë¬¸ìì—´)
- subject: ê³¼ëª©ëª…
- area_name: ì˜ì—­ì´ë¦„
- difficulty: "í•˜", "ì¤‘", "ìƒ"
- year: ì—°ë„

ì¤‘ìš”: 22ë²ˆ ë¬¸ì œê¹Œì§€ë§Œ íŒŒì‹±í•˜ì„¸ìš”.
"""
        
        if content_type == "questions":
            return f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì‹œí—˜ ë¬¸ì œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

{base_schema}

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "type": "questions",
    "data": [
        {{
            "question_number": 1,
            "content": "ë¬¸ì œ ë‚´ìš©",
            "description": ["ì„¤ëª…1", "ì„¤ëª…2"],
            "options": {{"1": "ì„ íƒì§€1", "2": "ì„ íƒì§€2", "3": "ì„ íƒì§€3", "4": "ì„ íƒì§€4"}},
            "subject": "ê³¼ëª©ëª…",
            "area_name": "ì˜ì—­ëª…",
            "year": 2024
        }}
    ]
}}

í…ìŠ¤íŠ¸ ë‚´ìš©:
{text_content}
"""
        elif content_type == "answers":
            return f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì •ë‹µ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "type": "answers", 
    "data": [
        {{
            "question_number": 1,
            "correct_answer": "3",
            "year": 2024
        }}
    ]
}}

í…ìŠ¤íŠ¸ ë‚´ìš©:
{text_content}
"""
        else:  # auto
            return f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì‹œí—˜ ë¬¸ì œì¸ì§€ ì •ë‹µ íŒŒì¼ì¸ì§€ ìë™ íŒë‹¨í•˜ê³  ì ì ˆíˆ íŒŒì‹±í•´ì£¼ì„¸ìš”.

{base_schema}

ë¬¸ì œ íŒŒì¼ì¸ ê²½ìš°:
{{
    "type": "questions",
    "data": [ë¬¸ì œ ë°ì´í„° ë°°ì—´]
}}

ì •ë‹µ íŒŒì¼ì¸ ê²½ìš°:
{{
    "type": "answers",
    "data": [ì •ë‹µ ë°ì´í„° ë°°ì—´]
}}

í…ìŠ¤íŠ¸ ë‚´ìš©:
{text_content}
"""
    
    def _parse_structured_response(self, response_text: str, content_type: str) -> List[Dict[str, Any]]:
        """êµ¬ì¡°í™”ëœ ì‘ë‹µ íŒŒì‹±"""
        try:
            # JSON ì¶”ì¶œ
            text = response_text.strip()
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0]
            elif "```" in text:
                json_parts = text.split("```")
                for part in json_parts:
                    if part.strip().startswith('{') or part.strip().startswith('['):
                        text = part
                        break
            
            # JSON íŒŒì‹±
            result = json.loads(text.strip())
            
            if isinstance(result, dict) and "data" in result:
                data = result["data"]
            elif isinstance(result, list):
                data = result
            else:
                data = [result]
            
            # 22ë²ˆ ì œí•œ ì ìš©
            data = [item for item in data if item.get('question_number', 0) <= 22][:22]
            
            return data
            
        except Exception as e:
            logger.error(f"ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
            logger.error(f"íŒŒì‹± ì‹œë„ í…ìŠ¤íŠ¸: {response_text[:500]}...")
            return []
    
    async def auto_map_difficulty_domain(
        self, 
        question_content: str, 
        department: str = "ì¼ë°˜í•™ê³¼"
    ) -> Dict[str, Any]:
        """
        ìë™ ë‚œì´ë„/ë¶„ì•¼ ë§¤í•‘ (Gemini ëŒ€ì²´)
        """
        try:
            prompt = f"""
ë‹¤ìŒ ë¬¸ì œì˜ ë‚œì´ë„ì™€ ë¶„ì•¼ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

í•™ê³¼: {department}
ë¬¸ì œ: {question_content}

ë‚œì´ë„ ê¸°ì¤€:
- í•˜: ê¸°ì´ˆê°œë…, ë‹¨ìˆœì•”ê¸°
- ì¤‘: ì‘ìš©, ì´í•´, ë¶„ì„
- ìƒ: ì¢…í•©ë¶„ì„, ê³ ì°¨ì›ì‚¬ê³ , ì°½ì˜ì  ë¬¸ì œí•´ê²°

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "difficulty": "í•˜|ì¤‘|ìƒ",
    "domain": "ë¶„ì•¼ëª…",
    "confidence": 0.85,
    "reasoning": "ë¶„ì„ ê·¼ê±°"
}}
"""
            
            messages = [{"role": "user", "content": prompt}]
            result = await self.chat_completion(messages, temperature=0.1)
            
            if result["success"]:
                try:
                    # JSON ì¶”ì¶œ ì‹œë„
                    content = result["content"]
                    if "```json" in content:
                        json_text = content.split("```json")[1].split("```")[0]
                    elif "{" in content and "}" in content:
                        start = content.find("{")
                        end = content.rfind("}") + 1
                        json_text = content[start:end]
                    else:
                        json_text = content
                    
                    parsed = json.loads(json_text.strip())
                    return parsed
                except:
                    # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’
                    return {
                        "difficulty": "ì¤‘",
                        "domain": "ì¼ë°˜",
                        "confidence": 0.6,
                        "reasoning": "ìë™ ë¶„ì„ ê²°ê³¼"
                    }
            else:
                return {
                    "difficulty": "ì¤‘", 
                    "domain": "ì¼ë°˜",
                    "confidence": 0.5,
                    "reasoning": "ë¶„ì„ ì‹¤íŒ¨ë¡œ ê¸°ë³¸ê°’ ì ìš©"
                }
                
        except Exception as e:
            logger.error(f"ìë™ ë§¤í•‘ ì˜¤ë¥˜: {e}")
            return {
                "difficulty": "ì¤‘",
                "domain": "ì¼ë°˜", 
                "confidence": 0.3,
                "reasoning": f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }
    
    async def generate_explanation(
        self, 
        question: str, 
        correct_answer: str,
        options: Dict[str, str],
        department: str = "ì¼ë°˜í•™ê³¼"
    ) -> Dict[str, Any]:
        """
        AI í•´ì„¤ ìƒì„± (Gemini ëŒ€ì²´)
        """
        try:
            # í•™ê³¼ë³„ í•´ì„¤ ìŠ¤íƒ€ì¼
            style_guide = {
                "ê°„í˜¸í•™ê³¼": "í™˜ì ì•ˆì „, ê·¼ê±°ê¸°ë°˜ ê°„í˜¸, ì„ìƒì  ì ìš©ì— ì¤‘ì ",
                "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": "ê¸°ëŠ¥ íšŒë³µ, ìš´ë™í•™ì  ì›ë¦¬, ì¹˜ë£Œ íš¨ê³¼ì— ì¤‘ì ",
                "ì‘ì—…ì¹˜ë£Œí•™ê³¼": "ì¼ìƒìƒí™œ ì°¸ì—¬, ì˜ë¯¸ìˆëŠ” í™œë™, í™˜ê²½ ì ì‘ì— ì¤‘ì "
            }
            
            style = style_guide.get(department, "ì²´ê³„ì ì´ê³  ë…¼ë¦¬ì ì¸ ì„¤ëª…")
            
            prompt = f"""
ë‹¤ìŒ ë¬¸ì œì— ëŒ€í•œ ìƒì„¸í•œ í•´ì„¤ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ë¬¸ì œ: {question}
ì„ íƒì§€: {json.dumps(options, ensure_ascii=False)}
ì •ë‹µ: {correct_answer}ë²ˆ
í•™ê³¼: {department}

í•´ì„¤ ì‘ì„± ê¸°ì¤€:
- {style}
- ì •ë‹µ ê·¼ê±°ë¥¼ ëª…í™•íˆ ì œì‹œ
- ì˜¤ë‹µ ë¶„ì„ í¬í•¨
- ì‹¤ë¬´ ì ìš© ê´€ì  ì¶”ê°€
- ê´€ë ¨ í•™ìŠµ í¬ì¸íŠ¸ ì œì‹œ

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "explanation": "ìƒì„¸í•œ í•´ì„¤ ë‚´ìš©",
    "confidence": 0.85,
    "key_points": ["í•µì‹¬í¬ì¸íŠ¸1", "í•µì‹¬í¬ì¸íŠ¸2"],
    "related_topics": ["ê´€ë ¨ì£¼ì œ1", "ê´€ë ¨ì£¼ì œ2"]
}}
"""
            
            messages = [{"role": "user", "content": prompt}]
            result = await self.chat_completion(messages, temperature=0.3)
            
            if result["success"]:
                try:
                    # JSON ì¶”ì¶œ ì‹œë„
                    content = result["content"]
                    if "```json" in content:
                        json_text = content.split("```json")[1].split("```")[0]
                    elif "{" in content and "}" in content:
                        start = content.find("{")
                        end = content.rfind("}") + 1
                        json_text = content[start:end]
                    else:
                        # JSONì´ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ í•´ì„¤ë¡œ ì‚¬ìš©
                        return {
                            "success": True,
                            "explanation": content,
                            "confidence": 0.75,
                            "key_points": [],
                            "related_topics": []
                        }
                    
                    parsed = json.loads(json_text.strip())
                    return {
                        "success": True,
                        "explanation": parsed.get("explanation", content),
                        "confidence": parsed.get("confidence", 0.8),
                        "key_points": parsed.get("key_points", []),
                        "related_topics": parsed.get("related_topics", [])
                    }
                except:
                    return {
                        "success": True,
                        "explanation": result["content"],
                        "confidence": 0.75,
                        "key_points": [],
                        "related_topics": []
                    }
            else:
                return {
                    "success": False,
                    "error": result["error"]
                }
                
        except Exception as e:
            logger.error(f"í•´ì„¤ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def generate_rag_question(
        self,
        topic: str,
        context: str,
        difficulty: str = "ì¤‘",
        question_type: str = "multiple_choice"
    ) -> Dict[str, Any]:
        """
        RAG ê¸°ë°˜ ë¬¸ì œ ìƒì„± (OpenAI ëŒ€ì²´)
        """
        try:
            prompt = f"""
ë‹¤ìŒ í•™ìŠµ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ {difficulty} ë‚œì´ë„ì˜ {question_type} ë¬¸ì œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

í•™ìŠµ ìë£Œ:
{context}

ì£¼ì œ: {topic}
ë‚œì´ë„: {difficulty}
ë¬¸ì œ ìœ í˜•: {question_type}

ìš”êµ¬ì‚¬í•­:
- í•™ìŠµ ìë£Œì˜ ë‚´ìš©ì„ ì •í™•íˆ ë°˜ì˜
- ê°ê´€ì‹ì¸ ê²½ìš° 4ê°œì˜ ì„ íƒì§€ì™€ ì •ë‹µ í¬í•¨
- ë¬¸ì œì˜ ì§ˆì´ ë†’ê³  êµìœ¡ì  ê°€ì¹˜ê°€ ìˆì„ ê²ƒ

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "content": "ë¬¸ì œ ë‚´ìš©",
    "options": {{"1": "ì„ íƒì§€1", "2": "ì„ íƒì§€2", "3": "ì„ íƒì§€3", "4": "ì„ íƒì§€4"}},
    "correct_answer": "ì •ë‹µ ë²ˆí˜¸",
    "explanation": "í•´ì„¤",
    "confidence": 0.85,
    "difficulty": "{difficulty}",
    "subject": "{topic}"
}}
"""
            
            messages = [{"role": "user", "content": prompt}]
            result = await self.chat_completion(messages, temperature=0.4)
            
            if result["success"]:
                try:
                    # JSON ì¶”ì¶œ ì‹œë„
                    content = result["content"]
                    if "```json" in content:
                        json_text = content.split("```json")[1].split("```")[0]
                    elif "{" in content and "}" in content:
                        start = content.find("{")
                        end = content.rfind("}") + 1
                        json_text = content[start:end]
                    else:
                        json_text = content
                    
                    parsed = json.loads(json_text.strip())
                    return {
                        "success": True,
                        "question_data": parsed
                    }
                except:
                    return {
                        "success": False,
                        "error": "ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨"
                    }
            else:
                return {
                    "success": False,
                    "error": result["error"]
                }
                
        except Exception as e:
            logger.error(f"RAG ë¬¸ì œ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def close(self):
        """í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ"""
        if self._client:
            await self._client.aclose()

    async def classify_content(
        self,
        content: str,
        department: str = "ì¼ë°˜í•™ê³¼",
        subject: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        DeepSeekì„ ì´ìš©í•œ ì»¨í…ì¸  ë¶„ë¥˜
        - ë‚œì´ë„ (ì‰¬ì›€/ë³´í†µ/ì–´ë ¤ì›€)
        - ì»¨í…ì¸  ìœ í˜• (ì´ë¡ /ì‹¤ë¬´/ì‚¬ë¡€/ë¬¸ì œ)  
        - í‚¤ì›Œë“œ ì¶”ì¶œ
        """
        try:
            # í•™ê³¼ë³„ ë¶„ë¥˜ ê¸°ì¤€ ì„¤ì •
            classification_criteria = {
                "ê°„í˜¸í•™ê³¼": {
                    "focus_areas": ["ê¸°ë³¸ê°„í˜¸í•™", "ì„±ì¸ê°„í˜¸í•™", "ì•„ë™ê°„í˜¸í•™", "ëª¨ì„±ê°„í˜¸í•™", "ì •ì‹ ê°„í˜¸í•™", "ì§€ì—­ì‚¬íšŒê°„í˜¸í•™"],
                    "difficulty_indicators": {
                        "ì‰¬ì›€": ["ê¸°ë³¸ ê°œë…", "ì •ì˜", "ê¸°ì´ˆ ì´ë¡ ", "ê°„ë‹¨í•œ ì ˆì°¨"],
                        "ë³´í†µ": ["ì„ìƒ ì ìš©", "ê°„í˜¸ ê³¼ì •", "í™˜ì ì‚¬ì •", "ì¤‘ì¬ ê³„íš"],
                        "ì–´ë ¤ì›€": ["ë³µí•©ì  ìƒí™©", "ë¹„íŒì  ì‚¬ê³ ", "ì˜ì‚¬ê²°ì •", "ì‘ê¸‰ìƒí™©"]
                    },
                    "content_types": {
                        "ì´ë¡ ": ["ì´ë¡ ", "ê°œë…", "ì •ì˜", "ì›ë¦¬", "ì§€ì‹"],
                        "ì‹¤ë¬´": ["ìˆ ê¸°", "ì ˆì°¨", "ë°©ë²•", "í”„ë¡œí† ì½œ", "ê°€ì´ë“œë¼ì¸"],
                        "ì‚¬ë¡€": ["ì‚¬ë¡€", "ìƒí™©", "ì‹œë‚˜ë¦¬ì˜¤", "í™˜ì", "ì¼€ì´ìŠ¤"],
                        "ë¬¸ì œ": ["ë¬¸ì œ", "ì§ˆë¬¸", "í‰ê°€", "í…ŒìŠ¤íŠ¸", "í€´ì¦ˆ"]
                    }
                },
                "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": {
                    "focus_areas": ["ìš´ë™ì¹˜ë£Œ", "ë¬¼ë¦¬ì  ì¸ìì¹˜ë£Œ", "ì‹ ê²½ê³„ë¬¼ë¦¬ì¹˜ë£Œ", "ê·¼ê³¨ê²©ê³„ë¬¼ë¦¬ì¹˜ë£Œ", "í˜¸í¡ìˆœí™˜ê³„ë¬¼ë¦¬ì¹˜ë£Œ"],
                    "difficulty_indicators": {
                        "ì‰¬ì›€": ["í•´ë¶€í•™ ê¸°ì´ˆ", "ê¸°ë³¸ ìš´ë™", "ê°„ë‹¨í•œ ì¸¡ì •"],
                        "ë³´í†µ": ["ì¹˜ë£Œ ê³„íš", "ìš´ë™ í”„ë¡œê·¸ë¨", "í‰ê°€ ë°©ë²•"],
                        "ì–´ë ¤ì›€": ["ë³µí•© ì¥ì• ", "ê³ ê¸‰ ì¹˜ë£Œë²•", "ì—°êµ¬ ë¶„ì„"]
                    },
                    "content_types": {
                        "ì´ë¡ ": ["í•´ë¶€í•™", "ìƒë¦¬í•™", "ë³‘ë¦¬í•™", "ìš´ë™í•™"],
                        "ì‹¤ë¬´": ["ì¹˜ë£Œë²•", "ìš´ë™ë²•", "ì¸¡ì •ë²•", "ê¸°ê¸° ì‚¬ìš©"],
                        "ì‚¬ë¡€": ["í™˜ì ì‚¬ë¡€", "ì¹˜ë£Œ ì‚¬ë¡€", "ì¬í™œ ê³¼ì •"],
                        "ë¬¸ì œ": ["í‰ê°€", "ì§„ë‹¨", "ë¬¸ì œ í•´ê²°"]
                    }
                },
                "ì‘ì—…ì¹˜ë£Œí•™ê³¼": {
                    "focus_areas": ["ì¼ìƒìƒí™œí™œë™", "ì¸ì§€ì¬í™œ", "ì •ì‹ ì‚¬íšŒì‘ì—…ì¹˜ë£Œ", "ê°ê°í†µí•©ì¹˜ë£Œ", "ë³´ì¡°ê³µí•™"],
                    "difficulty_indicators": {
                        "ì‰¬ì›€": ["ê¸°ë³¸ í™œë™", "ë‹¨ìˆœ í‰ê°€", "ì¼ë°˜ì  ê°œë…"],
                        "ë³´í†µ": ["í™œë™ ë¶„ì„", "ì¹˜ë£Œ ê³„íš", "í‰ê°€ ë„êµ¬"],
                        "ì–´ë ¤ì›€": ["ë³µí•© ì¤‘ì¬", "í™˜ê²½ ìˆ˜ì •", "ê³ ê¸‰ í‰ê°€"]
                    },
                    "content_types": {
                        "ì´ë¡ ": ["ì´ë¡ ì  ëª¨ë¸", "ë°œë‹¬ ì´ë¡ ", "í•™ìŠµ ì´ë¡ "],
                        "ì‹¤ë¬´": ["í™œë™ ì¹˜ë£Œ", "í‰ê°€ ë°©ë²•", "ì¤‘ì¬ ê¸°ë²•"],
                        "ì‚¬ë¡€": ["ì¹˜ë£Œ ì‚¬ë¡€", "í™œë™ ë¶„ì„", "ì¤‘ì¬ ê²°ê³¼"],
                        "ë¬¸ì œ": ["í‰ê°€ ë¬¸ì œ", "ì‚¬ë¡€ ë¶„ì„", "ì˜ì‚¬ê²°ì •"]
                    }
                }
            }
            
            # ê¸°ë³¸ ë¶„ë¥˜ ê¸°ì¤€ (ì¼ë°˜í•™ê³¼ìš©)
            criteria = classification_criteria.get(department, {
                "focus_areas": ["ê¸°ì´ˆ", "ì´ë¡ ", "ì‹¤ìŠµ", "ì‘ìš©"],
                "difficulty_indicators": {
                    "ì‰¬ì›€": ["ê¸°ë³¸", "ê¸°ì´ˆ", "ì •ì˜", "ê°œë…"],
                    "ë³´í†µ": ["ì‘ìš©", "ì‹¤ìŠµ", "ë¶„ì„", "ì ìš©"],
                    "ì–´ë ¤ì›€": ["ì¢…í•©", "í‰ê°€", "ì°½ì¡°", "ë¹„íŒ"]
                },
                "content_types": {
                    "ì´ë¡ ": ["ì´ë¡ ", "ê°œë…", "ì›ë¦¬"],
                    "ì‹¤ë¬´": ["ì‹¤ìŠµ", "ë°©ë²•", "ì ˆì°¨"],
                    "ì‚¬ë¡€": ["ì‚¬ë¡€", "ì˜ˆì‹œ", "ìƒí™©"],
                    "ë¬¸ì œ": ["ë¬¸ì œ", "ì§ˆë¬¸", "í‰ê°€"]
                }
            })
            
            # DeepSeek ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
            classification_prompt = self._build_classification_prompt(
                content, department, subject, criteria
            )
            
            messages = [
                {
                    "role": "system",
                    "content": f"""ë‹¹ì‹ ì€ {department} ì „ë¬¸ êµìœ¡ ì»¨í…ì¸  ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
                    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ë‚œì´ë„, ì»¨í…ì¸  ìœ í˜•, í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì •í™•í•˜ê²Œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”."""
                },
                {
                    "role": "user", 
                    "content": classification_prompt
                }
            ]
            
            # DeepSeek ë¶„ë¥˜ ì‹¤í–‰
            response = await self.chat_completion(
                messages=messages,
                temperature=0.3,  # ì¼ê´€ì„± ìˆëŠ” ë¶„ë¥˜ë¥¼ ìœ„í•´ ë‚®ì€ temperature
                max_tokens=1024
            )
            
            if not response["success"]:
                # ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ë¶„ë¥˜ ë°˜í™˜
                return self._get_default_classification(content, department)
            
            # ì‘ë‹µ íŒŒì‹±
            classification_result = self._parse_classification_response(
                response["content"], department
            )
            
            logger.info(f"âœ… DeepSeek ì»¨í…ì¸  ë¶„ë¥˜ ì™„ë£Œ: {department}")
            return classification_result
            
        except Exception as e:
            logger.error(f"âŒ DeepSeek ì»¨í…ì¸  ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            # ì˜¤ë¥˜ì‹œ ê¸°ë³¸ ë¶„ë¥˜ ë°˜í™˜
            return self._get_default_classification(content, department)
    
    def _build_classification_prompt(
        self, 
        content: str, 
        department: str, 
        subject: Optional[str],
        criteria: Dict[str, Any]
    ) -> str:
        """ë¶„ë¥˜ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        focus_areas = ", ".join(criteria.get("focus_areas", []))
        subject_info = f" (ê³¼ëª©: {subject})" if subject else ""
        
        prompt = f"""
ë‹¤ìŒ {department}{subject_info} êµìœ¡ ì»¨í…ì¸ ë¥¼ ë¶„ì„í•˜ì—¬ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.

=== ë¶„ì„í•  ì»¨í…ì¸  ===
{content[:2000]}  # ë„ˆë¬´ ê¸´ ì»¨í…ì¸ ëŠ” ì˜ë¼ì„œ ì²˜ë¦¬

=== ë¶„ë¥˜ ê¸°ì¤€ ===
ì£¼ìš” ì˜ì—­: {focus_areas}

ë‚œì´ë„:
- ì‰¬ì›€: {', '.join(criteria['difficulty_indicators']['ì‰¬ì›€'])}
- ë³´í†µ: {', '.join(criteria['difficulty_indicators']['ë³´í†µ'])}  
- ì–´ë ¤ì›€: {', '.join(criteria['difficulty_indicators']['ì–´ë ¤ì›€'])}

ì»¨í…ì¸  ìœ í˜•:
- ì´ë¡ : {', '.join(criteria['content_types']['ì´ë¡ '])}
- ì‹¤ë¬´: {', '.join(criteria['content_types']['ì‹¤ë¬´'])}
- ì‚¬ë¡€: {', '.join(criteria['content_types']['ì‚¬ë¡€'])}
- ë¬¸ì œ: {', '.join(criteria['content_types']['ë¬¸ì œ'])}

=== ìš”ì²­ ë¶„ë¥˜ í˜•ì‹ ===
ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:

{{
    "difficulty": "ì‰¬ì›€|ë³´í†µ|ì–´ë ¤ì›€",
    "content_type": "ì´ë¡ |ì‹¤ë¬´|ì‚¬ë¡€|ë¬¸ì œ", 
    "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"],
    "confidence": 0.85,
    "reasoning": "ë¶„ë¥˜ ê·¼ê±° ì„¤ëª…"
}}

ë¶„ì„í•˜ì—¬ JSONë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”.
"""
        return prompt
    
    def _parse_classification_response(
        self, 
        response_text: str, 
        department: str
    ) -> Dict[str, Any]:
        """DeepSeek ë¶„ë¥˜ ì‘ë‹µ íŒŒì‹±"""
        try:
            # JSON ì¶”ì¶œ ì‹œë„
            import re
            
            # JSON ë¸”ë¡ ì°¾ê¸°
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                classification_data = json.loads(json_str)
                
                # ê²°ê³¼ ê²€ì¦ ë° ì •ê·œí™”
                result = {
                    "difficulty": self._normalize_difficulty(
                        classification_data.get("difficulty", "ë³´í†µ")
                    ),
                    "content_type": self._normalize_content_type(
                        classification_data.get("content_type", "ì´ë¡ ")
                    ),
                    "keywords": self._normalize_keywords(
                        classification_data.get("keywords", [])
                    ),
                    "confidence": float(classification_data.get("confidence", 0.8)),
                    "reasoning": classification_data.get("reasoning", "ìë™ ë¶„ë¥˜"),
                    "department": department,
                    "classified_at": datetime.now().isoformat()
                }
                
                return result
            
        except (json.JSONDecodeError, KeyError, ValueError) as e:
            logger.warning(f"ë¶„ë¥˜ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        # íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return self._get_default_classification("", department)
    
    def _normalize_difficulty(self, difficulty: str) -> str:
        """ë‚œì´ë„ ì •ê·œí™”"""
        difficulty_map = {
            "ì‰¬ì›€": "ì‰¬ì›€", "easy": "ì‰¬ì›€", "1": "ì‰¬ì›€", "ê¸°ì´ˆ": "ì‰¬ì›€",
            "ë³´í†µ": "ë³´í†µ", "medium": "ë³´í†µ", "2": "ë³´í†µ", "ì¤‘ê°„": "ë³´í†µ", "ì¤‘": "ë³´í†µ",
            "ì–´ë ¤ì›€": "ì–´ë ¤ì›€", "hard": "ì–´ë ¤ì›€", "3": "ì–´ë ¤ì›€", "ê³ ê¸‰": "ì–´ë ¤ì›€", "ì–´ë ¤ìš´": "ì–´ë ¤ì›€"
        }
        
        return difficulty_map.get(difficulty.lower().strip(), "ë³´í†µ")
    
    def _normalize_content_type(self, content_type: str) -> str:
        """ì»¨í…ì¸  ìœ í˜• ì •ê·œí™”"""
        type_map = {
            "ì´ë¡ ": "ì´ë¡ ", "theory": "ì´ë¡ ", "ê°œë…": "ì´ë¡ ", "ì›ë¦¬": "ì´ë¡ ",
            "ì‹¤ë¬´": "ì‹¤ë¬´", "practice": "ì‹¤ë¬´", "ì‹¤ìŠµ": "ì‹¤ë¬´", "ìˆ ê¸°": "ì‹¤ë¬´", "ë°©ë²•": "ì‹¤ë¬´",
            "ì‚¬ë¡€": "ì‚¬ë¡€", "case": "ì‚¬ë¡€", "ì˜ˆì‹œ": "ì‚¬ë¡€", "ìƒí™©": "ì‚¬ë¡€", "ì‹œë‚˜ë¦¬ì˜¤": "ì‚¬ë¡€",
            "ë¬¸ì œ": "ë¬¸ì œ", "problem": "ë¬¸ì œ", "ì§ˆë¬¸": "ë¬¸ì œ", "í‰ê°€": "ë¬¸ì œ", "í€´ì¦ˆ": "ë¬¸ì œ"
        }
        
        return type_map.get(content_type.lower().strip(), "ì´ë¡ ")
    
    def _normalize_keywords(self, keywords: List[str]) -> List[str]:
        """í‚¤ì›Œë“œ ì •ê·œí™”"""
        if not isinstance(keywords, list):
            return []
        
        # í‚¤ì›Œë“œ ì •ë¦¬ (ì¤‘ë³µ ì œê±°, ê³µë°± ì œê±°, ê¸¸ì´ ì œí•œ)
        normalized = []
        for keyword in keywords[:10]:  # ìµœëŒ€ 10ê°œ
            if isinstance(keyword, str):
                clean_keyword = keyword.strip()
                if clean_keyword and len(clean_keyword) <= 50:
                    normalized.append(clean_keyword)
        
        return list(set(normalized))  # ì¤‘ë³µ ì œê±°
    
    def _get_default_classification(self, content: str, department: str) -> Dict[str, Any]:
        """ê¸°ë³¸ ë¶„ë¥˜ ê²°ê³¼ ë°˜í™˜"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
        content_lower = content.lower()
        
        # ê¸°ë³¸ ë‚œì´ë„ íŒì •
        if any(word in content_lower for word in ["ê¸°ë³¸", "ê¸°ì´ˆ", "ì •ì˜", "ê°œë…"]):
            difficulty = "ì‰¬ì›€"
        elif any(word in content_lower for word in ["ê³ ê¸‰", "ë³µí•©", "ì‘ê¸‰", "ë¹„íŒì "]):
            difficulty = "ì–´ë ¤ì›€"
        else:
            difficulty = "ë³´í†µ"
        
        # ê¸°ë³¸ ìœ í˜• íŒì •
        if any(word in content_lower for word in ["ì‚¬ë¡€", "í™˜ì", "ìƒí™©", "ì¼€ì´ìŠ¤"]):
            content_type = "ì‚¬ë¡€"
        elif any(word in content_lower for word in ["ë°©ë²•", "ì ˆì°¨", "ìˆ ê¸°", "ì‹¤ìŠµ"]):
            content_type = "ì‹¤ë¬´"
        elif any(word in content_lower for word in ["ë¬¸ì œ", "ì§ˆë¬¸", "í‰ê°€"]):
            content_type = "ë¬¸ì œ"
        else:
            content_type = "ì´ë¡ "
        
        return {
            "difficulty": difficulty,
            "content_type": content_type,
            "keywords": [],
            "confidence": 0.6,
            "reasoning": "ê¸°ë³¸ ê·œì¹™ ê¸°ë°˜ ë¶„ë¥˜",
            "department": department,
            "classified_at": datetime.now().isoformat()
        }

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
deepseek_service = LocalDeepSeekService() 