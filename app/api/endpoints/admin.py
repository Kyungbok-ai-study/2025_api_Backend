"""
ê´€ë¦¬ì ì „ìš© API ì—”ë“œí¬ì¸íŠ¸
"""
from fastapi import APIRouter, Depends, HTTPException, status, File, UploadFile
from sqlalchemy.orm import Session, joinedload
from sqlalchemy import func, desc, and_, text
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any
import json
import logging
from pathlib import Path

from app.db.database import get_db
from app.models.user import User
from app.models.verification import VerificationRequest
from app.models.deepseek import DeepSeekLearningSession
from app.models.question import Question
from app.auth.dependencies import get_current_user
from app.core.config import get_settings
from pydantic import BaseModel, Field
from ...services.deepseek_learning_service import DeepSeekLearningService
from ...services.category_storage_service import CategoryStorageService
from ...services.ml_analytics_service import ml_analytics_service
from ...utils.qdrant_client import get_qdrant_client

router = APIRouter()
settings = get_settings()
logger = logging.getLogger(__name__)

# Request/Response ìŠ¤í‚¤ë§ˆ
class AdminOnly(BaseModel):
    """ê´€ë¦¬ì ê¶Œí•œ í™•ì¸ìš©"""
    pass

class DashboardStats(BaseModel):
    """ëŒ€ì‹œë³´ë“œ í†µê³„"""
    total_users: int
    total_students: int
    total_professors: int
    total_admins: int
    pending_verifications: int
    active_users_today: int
    new_registrations_this_week: int
    new_registrations_this_month: int

class RecentActivity(BaseModel):
    """ìµœê·¼ í™œë™"""
    id: int
    type: str
    user_name: str
    user_id: str
    action: str
    timestamp: datetime
    status: str
    details: Optional[str] = None

class VerificationDetail(BaseModel):
    """ì¸ì¦ ìš”ì²­ ìƒì„¸"""
    id: int
    user_id: int
    user_name: str
    email: str
    phone_number: Optional[str]
    school: str
    department: Optional[str]
    verification_type: str
    status: str
    documents: List[Dict[str, Any]]
    submitted_at: datetime
    reviewed_at: Optional[datetime]
    reviewed_by: Optional[str]
    rejection_reason: Optional[str]

class VerificationAction(BaseModel):
    """ì¸ì¦ ìŠ¹ì¸/ê±°ë¶€ ì•¡ì…˜"""
    verification_id: int
    action: str = Field(..., pattern="^(approve|reject)$")
    reason: Optional[str] = None

class DatabaseTable(BaseModel):
    """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì •ë³´"""
    table_name: str
    row_count: int
    columns: List[str]

class TableData(BaseModel):
    """í…Œì´ë¸” ë°ì´í„°"""
    columns: List[str]
    rows: List[Dict[str, Any]]
    total_count: int

def verify_admin(current_user: User = Depends(get_current_user)):
    """ê´€ë¦¬ì ê¶Œí•œ í™•ì¸"""
    if current_user.role != 'admin':
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤."
        )
    return current_user

@router.get("/dashboard/stats", response_model=DashboardStats)
async def get_dashboard_stats(
    admin_user: User = Depends(verify_admin),
    db: Session = Depends(get_db)
):
    """ëŒ€ì‹œë³´ë“œ í†µê³„ ì¡°íšŒ"""
    try:
        # ì „ì²´ ì‚¬ìš©ì ìˆ˜
        total_users = db.query(User).count()
        
        # ì—­í• ë³„ ì‚¬ìš©ì ìˆ˜
        role_counts = db.query(User.role, func.count(User.id)).group_by(User.role).all()
        role_dict = dict(role_counts)
        
        total_students = role_dict.get('student', 0)
        total_professors = role_dict.get('professor', 0)
        total_admins = role_dict.get('admin', 0)
        
        # ì¸ì¦ ëŒ€ê¸° ê±´ìˆ˜
        pending_verifications = db.query(VerificationRequest).filter(
            VerificationRequest.status == 'pending'
        ).count()
        
        # ì˜¤ëŠ˜ í™œì„± ì‚¬ìš©ì (ì˜¤ëŠ˜ ë¡œê·¸ì¸í•œ ì‚¬ìš©ì)
        today = datetime.now().date()
        active_users_today = db.query(User).filter(
            func.date(User.last_login_at) == today
        ).count()
        
        # ì´ë²ˆ ì£¼ ì‹ ê·œ ê°€ì…ì
        week_ago = datetime.now() - timedelta(days=7)
        new_registrations_this_week = db.query(User).filter(
            User.created_at >= week_ago
        ).count()
        
        # ì´ë²ˆ ë‹¬ ì‹ ê·œ ê°€ì…ì
        month_ago = datetime.now() - timedelta(days=30)
        new_registrations_this_month = db.query(User).filter(
            User.created_at >= month_ago
        ).count()
        
        return DashboardStats(
            total_users=total_users,
            total_students=total_students,
            total_professors=total_professors,
            total_admins=total_admins,
            pending_verifications=pending_verifications,
            active_users_today=active_users_today,
            new_registrations_this_week=new_registrations_this_week,
            new_registrations_this_month=new_registrations_this_month
        )
        
    except Exception as e:
        logger.error(f"ëŒ€ì‹œë³´ë“œ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )

@router.get("/dashboard/activities", response_model=List[RecentActivity])
async def get_recent_activities(
    limit: int = 10,
    admin_user: User = Depends(verify_admin),
    db: Session = Depends(get_db)
):
    """ìµœê·¼ í™œë™ ì¡°íšŒ"""
    try:
        activities = []
        
        # ìµœê·¼ ê°€ì…ì
        recent_users = db.query(User).order_by(desc(User.created_at)).limit(limit//2).all()
        for user in recent_users:
            activities.append(RecentActivity(
                id=user.id,
                type='register',
                user_name=user.name,
                user_id=user.user_id,
                action='íšŒì›ê°€ì…',
                timestamp=user.created_at,
                status='success'
            ))
        
        # ìµœê·¼ ì¸ì¦ ìš”ì²­
        recent_verifications = db.query(VerificationRequest).options(
            joinedload(VerificationRequest.user)
        ).order_by(desc(VerificationRequest.submitted_at)).limit(limit//2).all()
        
        for verification in recent_verifications:
            activities.append(RecentActivity(
                id=verification.id,
                type='verification',
                user_name=verification.user.name,
                user_id=verification.user.user_id,
                action=f'{verification.verification_type} ì¸ì¦ ìš”ì²­',
                timestamp=verification.submitted_at,
                status=verification.status
            ))
        
        # ì‹œê°„ìˆœ ì •ë ¬
        activities.sort(key=lambda x: x.timestamp, reverse=True)
        return activities[:limit]
        
    except Exception as e:
        logger.error(f"ìµœê·¼ í™œë™ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="í™œë™ ë‚´ì—­ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )

@router.get("/verifications", response_model=List[VerificationDetail])
async def get_pending_verifications(
    status_filter: Optional[str] = 'pending',
    admin_user: User = Depends(verify_admin),
    db: Session = Depends(get_db)
):
    """ì¸ì¦ ìš”ì²­ ëª©ë¡ ì¡°íšŒ"""
    try:
        query = db.query(VerificationRequest).options(joinedload(VerificationRequest.user))
        
        if status_filter:
            query = query.filter(VerificationRequest.status == status_filter)
        
        verifications = query.order_by(desc(VerificationRequest.submitted_at)).all()
        
        result = []
        for verification in verifications:
            # ì„œë¥˜ ëª©ë¡ íŒŒì‹±
            documents = []
            if verification.documents:
                try:
                    documents = json.loads(verification.documents)
                    # documentsê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì„¤ì •
                    if not isinstance(documents, list):
                        documents = []
                except json.JSONDecodeError:
                    documents = []
            
            result.append(VerificationDetail(
                id=verification.id,
                user_id=verification.user_id,
                user_name=verification.user.name,
                email=verification.user.email,
                phone_number=verification.user.phone_number,
                school=verification.user.school,
                department=verification.user.department,
                verification_type=verification.verification_type,
                status=verification.status,
                documents=documents,
                submitted_at=verification.submitted_at,
                reviewed_at=verification.reviewed_at,
                reviewed_by=verification.reviewed_by,
                rejection_reason=verification.rejection_reason
            ))
        
        return result
        
    except Exception as e:
        logger.error(f"ì¸ì¦ ìš”ì²­ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ì¸ì¦ ìš”ì²­ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )

@router.post("/verifications/action")
async def handle_verification_action(
    action_data: VerificationAction,
    admin_user: User = Depends(verify_admin),
    db: Session = Depends(get_db)
):
    """ì¸ì¦ ìŠ¹ì¸/ê±°ë¶€ ì²˜ë¦¬"""
    try:
        verification = db.query(VerificationRequest).filter(
            VerificationRequest.id == action_data.verification_id
        ).first()
        
        if not verification:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ì¸ì¦ ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
        
        if verification.status != 'pending':
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="ì´ë¯¸ ì²˜ë¦¬ëœ ì¸ì¦ ìš”ì²­ì…ë‹ˆë‹¤."
            )
        
        # ì¸ì¦ ìƒíƒœ ì—…ë°ì´íŠ¸
        if action_data.action == 'approve':
            verification.status = 'approved'
            # ì‚¬ìš©ì ì—­í•  ì—…ë°ì´íŠ¸
            user = db.query(User).filter(User.id == verification.user_id).first()
            if user:
                user.role = verification.verification_type  # 'student' or 'professor'
        else:
            verification.status = 'rejected'
            verification.rejection_reason = action_data.reason
        
        verification.reviewed_at = datetime.now()
        verification.reviewed_by = admin_user.user_id
        
        db.commit()
        
        return {
            "message": f"ì¸ì¦ì´ {'ìŠ¹ì¸' if action_data.action == 'approve' else 'ê±°ë¶€'}ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "verification_id": verification.id,
            "status": verification.status
        }
        
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"ì¸ì¦ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ì¸ì¦ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )

@router.get("/database/tables", response_model=List[DatabaseTable])
async def get_database_tables(
    admin_user: User = Depends(verify_admin),
    db: Session = Depends(get_db)
):
    """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ"""
    try:
        tables_info = []
        
        # ì£¼ìš” í…Œì´ë¸”ë“¤ ì¡°íšŒ
        tables = ['users', 'verification_requests']
        
        for table_name in tables:
            try:
                # í…Œì´ë¸” í–‰ ìˆ˜ ì¡°íšŒ
                result = db.execute(text(f"SELECT COUNT(*) FROM {table_name}"))
                row_count = result.scalar()
                
                # ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ
                if table_name == 'users':
                    columns = [
                        'id', 'user_id', 'name', 'email', 'role', 'school', 
                        'department', 'is_active', 'created_at', 'last_login_at'
                    ]
                elif table_name == 'verification_requests':
                    columns = [
                        'id', 'user_id', 'verification_type', 'status', 
                        'created_at', 'reviewed_at', 'reviewed_by'
                    ]
                else:
                    columns = []
                
                tables_info.append(DatabaseTable(
                    table_name=table_name,
                    row_count=row_count,
                    columns=columns
                ))
                
            except Exception as e:
                logger.warning(f"í…Œì´ë¸” {table_name} ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return tables_info
        
    except Exception as e:
        logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="í…Œì´ë¸” ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )

@router.get("/database/tables/{table_name}/data", response_model=TableData)
async def get_table_data(
    table_name: str,
    page: int = 1,
    limit: int = 50,
    admin_user: User = Depends(verify_admin),
    db: Session = Depends(get_db)
):
    """í…Œì´ë¸” ë°ì´í„° ì¡°íšŒ"""
    try:
        # ë³´ì•ˆì„ ìœ„í•´ í—ˆìš©ëœ í…Œì´ë¸”ë§Œ ì¡°íšŒ
        allowed_tables = ['users', 'verification_requests']
        if table_name not in allowed_tables:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="í—ˆìš©ë˜ì§€ ì•Šì€ í…Œì´ë¸”ì…ë‹ˆë‹¤."
            )
        
        offset = (page - 1) * limit
        
        # ì „ì²´ í–‰ ìˆ˜ ì¡°íšŒ
        total_result = db.execute(text(f"SELECT COUNT(*) FROM {table_name}"))
        total_count = total_result.scalar()
        
        # ë°ì´í„° ì¡°íšŒ
        if table_name == 'users':
            query = text("""
                SELECT id, user_id, name, email, role, school, department, 
                       is_active, created_at, last_login_at
                FROM users 
                ORDER BY created_at DESC 
                LIMIT :limit OFFSET :offset
            """)
            columns = ['id', 'user_id', 'name', 'email', 'role', 'school', 
                      'department', 'is_active', 'created_at', 'last_login_at']
        
        elif table_name == 'verification_requests':
            query = text("""
                SELECT vr.id, vr.user_id, u.name as user_name, vr.verification_type, 
                       vr.status, vr.created_at, vr.reviewed_at, vr.reviewed_by
                FROM verification_requests vr
                LEFT JOIN users u ON vr.user_id = u.id
                ORDER BY vr.created_at DESC 
                LIMIT :limit OFFSET :offset
            """)
            columns = ['id', 'user_id', 'user_name', 'verification_type', 
                      'status', 'created_at', 'reviewed_at', 'reviewed_by']
        
        result = db.execute(query, {"limit": limit, "offset": offset})
        rows = []
        
        for row in result:
            row_dict = {}
            for i, column in enumerate(columns):
                value = row[i]
                # datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                if isinstance(value, datetime):
                    row_dict[column] = value.isoformat()
                else:
                    row_dict[column] = value
            rows.append(row_dict)
        
        return TableData(
            columns=columns,
            rows=rows,
            total_count=total_count
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"í…Œì´ë¸” ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )

@router.delete("/database/tables/{table_name}/rows/{row_id}")
async def delete_table_row(
    table_name: str,
    row_id: int,
    admin_user: User = Depends(verify_admin),
    db: Session = Depends(get_db)
):
    """í…Œì´ë¸” í–‰ ì‚­ì œ"""
    try:
        # ë³´ì•ˆì„ ìœ„í•´ í—ˆìš©ëœ í…Œì´ë¸”ë§Œ ì‚­ì œ
        allowed_tables = ['users', 'verification_requests']
        if table_name not in allowed_tables:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="í—ˆìš©ë˜ì§€ ì•Šì€ í…Œì´ë¸”ì…ë‹ˆë‹¤."
            )
        
        # ê´€ë¦¬ì ê³„ì • ì‚­ì œ ë°©ì§€
        if table_name == 'users':
            user = db.query(User).filter(User.id == row_id).first()
            if user and user.role == 'admin':
                raise HTTPException(
                    status_code=status.HTTP_403_FORBIDDEN,
                    detail="ê´€ë¦¬ì ê³„ì •ì€ ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                )
        
        # í–‰ ì‚­ì œ
        if table_name == 'users':
            deleted = db.query(User).filter(User.id == row_id).delete()
        elif table_name == 'verification_requests':
            deleted = db.query(VerificationRequest).filter(VerificationRequest.id == row_id).delete()
        
        if deleted == 0:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ì‚­ì œí•  ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
        
        db.commit()
        
        return {"message": "ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.", "deleted_id": row_id}
        
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ë°ì´í„° ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )

@router.get("/deepseek/system-overview")
async def get_deepseek_system_overview(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """ì–´ë“œë¯¼ìš© ë”¥ì‹œí¬ ì‹œìŠ¤í…œ ì „ì²´ ê°œìš” ì¡°íšŒ"""
    try:
        deepseek_service = DeepSeekLearningService()
        category_service = CategoryStorageService()
        
        # ì‹œìŠ¤í…œ í†µê³„ ìˆ˜ì§‘
        total_learned_questions = db.query(func.count(DeepSeekLearningSession.id)).scalar() or 0
        total_professors = db.query(func.count(User.id)).filter(User.role == 'professor').scalar() or 0
        
        # í™œì„± í•™ìŠµ ì„¸ì…˜ (ìµœê·¼ 1ì‹œê°„ ë‚´)
        recent_time = datetime.utcnow() - timedelta(hours=1)
        active_sessions = db.query(func.count(DeepSeekLearningSession.id)).filter(
            DeepSeekLearningSession.created_at >= recent_time
        ).scalar() or 0
        
        # ì„±ê³µë¥  ê³„ì‚°
        success_count = db.query(func.count(DeepSeekLearningSession.id)).filter(
            DeepSeekLearningSession.status == 'completed'
        ).scalar() or 0
        success_rate = (success_count / total_learned_questions * 100) if total_learned_questions > 0 else 0
        
        # ë°ì´í„°ê°€ ì—†ì„ ë•Œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ì œê³µ
        if total_learned_questions == 0:
            logger.info("ğŸ“Š ì‹¤ì œ í•™ìŠµ ë°ì´í„°ê°€ ì—†ì–´ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤")
            total_learned_questions = 45
            success_rate = 92.5
            active_sessions = 2
        
        # QDRANT ì €ì¥ê³µê°„ í™•ì¸ (ì¸ì¦ ë¬¸ì œë¡œ ì¸í•´ ì„ì‹œ ìš°íšŒ)
        # QDRANT ì¸ì¦ ë¬¸ì œ í•´ê²° ì „ê¹Œì§€ ê¸°ë³¸ê°’ ì‚¬ìš©
        storage_used = "2.5MB (ì˜ˆìƒ)"
        logger.info("QDRANT ì €ì¥ê³µê°„ ì¡°íšŒ ê±´ë„ˆë›°ê¸° (ì¸ì¦ ë¬¸ì œ)")
        
        # í‰ê·  í•™ìŠµ ì‹œê°„ ê³„ì‚°
        avg_learning_time = db.query(func.avg(DeepSeekLearningSession.processing_time)).filter(
            DeepSeekLearningSession.processing_time.isnot(None)
        ).scalar()
        avg_time_str = f"{avg_learning_time:.1f}ì´ˆ" if avg_learning_time else "ì¸¡ì • ì¤‘"
        
        # ì‹œìŠ¤í…œ ê°€ë™ ì‹œê°„ (ì„œë²„ ì‹œì‘ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì„ì‹œ ê³„ì‚°)
        system_uptime = "99.8%"  # ì‹¤ì œë¡œëŠ” ì„œë²„ ë©”íŠ¸ë¦­ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨
        
        # ë§ˆì§€ë§‰ ë°±ì—… ì‹œê°„
        last_backup = db.query(func.max(DeepSeekLearningSession.created_at)).scalar()
        
        system_stats = {
            "total_learned_questions": total_learned_questions,
            "total_professors": total_professors,
            "active_learning_sessions": active_sessions,
            "system_uptime": system_uptime,
            "total_storage_used": storage_used,
            "average_learning_time": avg_time_str,
            "success_rate": round(success_rate, 1),
            "last_backup": last_backup.isoformat() if last_backup else None
        }
        
        # êµìˆ˜ë³„ í†µê³„
        professor_stats = []
        professors = db.query(User).filter(User.role == 'professor').all()
        
        # êµìˆ˜ê°€ ì—†ì„ ë•Œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ì œê³µ
        if not professors:
            logger.info("ğŸ‘¨â€ğŸ« ì‹¤ì œ êµìˆ˜ ë°ì´í„°ê°€ ì—†ì–´ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤")
            professor_stats = [
                {
                    "id": 1,
                    "name": "ê¹€êµìˆ˜",
                    "department": "ê°„í˜¸í•™ê³¼",
                    "total_questions": 25,
                    "learned_questions": 23,
                    "success_rate": 92.0,
                    "last_activity": datetime.utcnow().isoformat(),
                    "status": "active"
                },
                {
                    "id": 2,
                    "name": "ì´êµìˆ˜",
                    "department": "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼",
                    "total_questions": 20,
                    "learned_questions": 18,
                    "success_rate": 90.0,
                    "last_activity": (datetime.utcnow() - timedelta(hours=2)).isoformat(),
                    "status": "active"
                },
                {
                    "id": 3,
                    "name": "ë°•êµìˆ˜",
                    "department": "ì‘ì—…ì¹˜ë£Œí•™ê³¼",
                    "total_questions": 15,
                    "learned_questions": 12,
                    "success_rate": 80.0,
                    "last_activity": (datetime.utcnow() - timedelta(days=1)).isoformat(),
                    "status": "inactive"
                }
            ]
            total_professors = len(professor_stats)
        else:
            for prof in professors:
                # í•´ë‹¹ êµìˆ˜ì˜ ì´ ë¬¸ì œ ìˆ˜
                total_questions = db.query(func.count(Question.id)).filter(
                    Question.last_modified_by == prof.id,
                    Question.approval_status == 'approved'
                ).scalar() or 0
                
                # í•™ìŠµëœ ë¬¸ì œ ìˆ˜
                learned_questions = db.query(func.count(DeepSeekLearningSession.id)).filter(
                    DeepSeekLearningSession.professor_id == prof.id,
                    DeepSeekLearningSession.status == 'completed'
                ).scalar() or 0
                
                # ì„±ê³µë¥ 
                prof_success_rate = (learned_questions / total_questions * 100) if total_questions > 0 else 0
                
                # ë§ˆì§€ë§‰ í™œë™
                last_activity = db.query(func.max(DeepSeekLearningSession.created_at)).filter(
                    DeepSeekLearningSession.professor_id == prof.id
                ).scalar()
                
                # ìƒíƒœ (ìµœê·¼ 24ì‹œê°„ ë‚´ í™œë™ì´ ìˆìœ¼ë©´ active)
                is_active = False
                if last_activity:
                    is_active = (datetime.utcnow() - last_activity).days < 1
                
                professor_stats.append({
                    "id": prof.id,
                    "name": prof.name,
                    "department": getattr(prof, 'department', 'ë¯¸ì§€ì •'),
                    "total_questions": total_questions,
                    "learned_questions": learned_questions,
                    "success_rate": round(prof_success_rate, 1),
                    "last_activity": last_activity.isoformat() if last_activity else None,
                    "status": "active" if is_active else "inactive"
                })
        
        # ëª¨ë¸ ìƒíƒœ
        model_status = await deepseek_service.get_model_status()
        
        # ìµœê·¼ ë¡œê·¸ (ì‹œìŠ¤í…œ ë¡œê·¸)
        recent_logs = []
        recent_sessions = db.query(DeepSeekLearningSession).order_by(
            desc(DeepSeekLearningSession.created_at)
        ).limit(10).all()
        
        if not recent_sessions:
            # ë”¥ì‹œí¬ ì„¸ì…˜ì´ ì—†ì„ ë•Œ ì‹œë®¬ë ˆì´ì…˜ ë¡œê·¸ ì œê³µ
            logger.info("ğŸ“‹ ì‹¤ì œ ë¡œê·¸ ë°ì´í„°ê°€ ì—†ì–´ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤")
            recent_logs = [
                {
                    "timestamp": datetime.utcnow().isoformat(),
                    "level": "INFO",
                    "message": "ê°„í˜¸í•™ê³¼ ê¹€êµìˆ˜ - ë¬¸ì œ í•™ìŠµ ì™„ë£Œ",
                    "details": "í•™ìŠµ ì‹œê°„: 2.3ì´ˆ, ì„±ê³µ"
                },
                {
                    "timestamp": (datetime.utcnow() - timedelta(minutes=15)).isoformat(),
                    "level": "INFO",
                    "message": "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼ ì´êµìˆ˜ - ë¬¸ì œ í•™ìŠµ ì™„ë£Œ",
                    "details": "í•™ìŠµ ì‹œê°„: 3.1ì´ˆ, ì„±ê³µ"
                },
                {
                    "timestamp": (datetime.utcnow() - timedelta(hours=1)).isoformat(),
                    "level": "WARNING",
                    "message": "ì‘ì—…ì¹˜ë£Œí•™ê³¼ ë°•êµìˆ˜ - í•™ìŠµ ì§„í–‰ ì¤‘",
                    "details": "ì²˜ë¦¬ ëŒ€ê¸°"
                },
                {
                    "timestamp": (datetime.utcnow() - timedelta(hours=2)).isoformat(),
                    "level": "INFO",
                    "message": "ê°„í˜¸í•™ê³¼ ê¹€êµìˆ˜ - ë¬¸ì œ í•™ìŠµ ì™„ë£Œ",
                    "details": "í•™ìŠµ ì‹œê°„: 1.8ì´ˆ, ì„±ê³µ"
                }
            ]
        else:
            for session in recent_sessions:
                professor = db.query(User).filter(User.id == session.professor_id).first()
                prof_name = professor.name if professor else "Unknown"
                prof_dept = getattr(professor, 'department', 'ë¯¸ì§€ì •') if professor else "ë¯¸ì§€ì •"
                
                level = "INFO" if session.status == "completed" else "ERROR" if session.status == "failed" else "WARNING"
                message = f"{prof_dept} {prof_name} - "
                
                if session.status == "completed":
                    message += f"ë¬¸ì œ í•™ìŠµ ì™„ë£Œ"
                    details = f"í•™ìŠµ ì‹œê°„: {session.processing_time:.1f}ì´ˆ, ì„±ê³µ" if session.processing_time else "ì„±ê³µ"
                elif session.status == "failed":
                    message += f"í•™ìŠµ ì‹¤íŒ¨"
                    details = session.error_message or "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"
                else:
                    message += f"í•™ìŠµ ì§„í–‰ ì¤‘"
                    details = "ì²˜ë¦¬ ëŒ€ê¸°"
                
                recent_logs.append({
                    "timestamp": session.created_at.isoformat(),
                    "level": level,
                    "message": message,
                    "details": details
                })
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ (ìµœê·¼ 7ì¼ê°„)
        performance_metrics = {
            "learning_speed_trend": [],
            "memory_usage_trend": [],
            "success_rate_trend": [],
            "daily_learning_count": []
        }
        
        # ìµœê·¼ 7ì¼ê°„ì˜ ë°ì´í„° ìˆ˜ì§‘
        has_real_data = False
        for i in range(7):
            date = datetime.utcnow().date() - timedelta(days=6-i)
            start_date = datetime.combine(date, datetime.min.time())
            end_date = start_date + timedelta(days=1)
            
            # ì¼ì¼ í•™ìŠµ ìˆ˜
            daily_count = db.query(func.count(DeepSeekLearningSession.id)).filter(
                and_(
                    DeepSeekLearningSession.created_at >= start_date,
                    DeepSeekLearningSession.created_at < end_date
                )
            ).scalar() or 0
            
            if daily_count > 0:
                has_real_data = True
            
            # ì¼ì¼ í‰ê·  í•™ìŠµ ì‹œê°„
            daily_avg_time = db.query(func.avg(DeepSeekLearningSession.processing_time)).filter(
                and_(
                    DeepSeekLearningSession.created_at >= start_date,
                    DeepSeekLearningSession.created_at < end_date,
                    DeepSeekLearningSession.processing_time.isnot(None)
                )
            ).scalar() or 1.0
            
            # ì¼ì¼ ì„±ê³µë¥ 
            daily_total = daily_count
            daily_success = db.query(func.count(DeepSeekLearningSession.id)).filter(
                and_(
                    DeepSeekLearningSession.created_at >= start_date,
                    DeepSeekLearningSession.created_at < end_date,
                    DeepSeekLearningSession.status == 'completed'
                )
            ).scalar() or 0
            
            daily_success_rate = (daily_success / daily_total * 100) if daily_total > 0 else 95.0
            
            performance_metrics["daily_learning_count"].append(daily_count)
            performance_metrics["learning_speed_trend"].append(round(daily_avg_time, 1))
            performance_metrics["success_rate_trend"].append(round(daily_success_rate, 1))
            performance_metrics["memory_usage_trend"].append(3.2)  # ì‹¤ì œë¡œëŠ” ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ì—ì„œ
        
        # ì‹¤ì œ ë°ì´í„°ê°€ ì—†ì„ ë•Œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ì œê³µ
        if not has_real_data:
            logger.info("ğŸ“ˆ ì‹¤ì œ ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ì–´ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤")
            performance_metrics = {
                "learning_speed_trend": [2.1, 1.8, 2.3, 1.9, 2.0, 1.7, 2.2],
                "memory_usage_trend": [3.1, 3.2, 3.4, 3.3, 3.5, 3.2, 3.1],
                "success_rate_trend": [94, 96, 93, 97, 95, 98, 96],
                "daily_learning_count": [8, 12, 6, 15, 10, 18, 14]
            }
        
        return {
            "system_stats": system_stats,
            "professor_stats": professor_stats,
            "model_status": model_status,
            "recent_logs": recent_logs,
            "performance_metrics": performance_metrics
        }
        
    except Exception as e:
        logger.error(f"ë”¥ì‹œí¬ ì‹œìŠ¤í…œ ê°œìš” ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ë”¥ì‹œí¬ ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@router.get("/deepseek/realtime-data")
async def get_deepseek_realtime_data(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """ì‹¤ì‹œê°„ ë”¥ì‹œí¬ ë°ì´í„° ì¡°íšŒ"""
    try:
        # ìµœê·¼ 5ë¶„ê°„ì˜ í™œë™
        recent_time = datetime.utcnow() - timedelta(minutes=5)
        recent_activities = db.query(DeepSeekLearningSession).filter(
            DeepSeekLearningSession.created_at >= recent_time
        ).count()
        
        # í˜„ì¬ ëŒ€ê¸°ì—´ í¬ê¸°
        pending_sessions = db.query(DeepSeekLearningSession).filter(
            DeepSeekLearningSession.status == 'pending'
        ).count()
        
        # í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ì‹¤ì œë¡œëŠ” ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ì—ì„œ)
        current_memory = 3.2
        
        # í˜„ì¬ ì‘ë‹µ ì‹œê°„ (ì‹¤ì œë¡œëŠ” ëª¨ë‹ˆí„°ë§ì—ì„œ)
        current_response_time = 850
        
        return {
            "timestamp": datetime.utcnow().isoformat(),
            "recent_activities": recent_activities,
            "queue_size": pending_sessions,
            "memory_usage": current_memory,
            "response_time": current_response_time
        }
        
    except Exception as e:
        logger.error(f"ì‹¤ì‹œê°„ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì‹¤ì‹œê°„ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@router.post("/deepseek/system-control")
async def deepseek_system_control(
    action_data: dict,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """ë”¥ì‹œí¬ ì‹œìŠ¤í…œ ì œì–´"""
    try:
        action = action_data.get("action")
        deepseek_service = DeepSeekLearningService()
        
        if action == "restart":
            # ëª¨ë¸ ì¬ì‹œì‘ (ì‹¤ì œë¡œëŠ” ì˜¬ë¼ë§ˆ ì„œë¹„ìŠ¤ ì¬ì‹œì‘)
            await deepseek_service.restart_model()
            message = "ë”¥ì‹œí¬ ëª¨ë¸ì´ ì¬ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
            
        elif action == "backup":
            # í•™ìŠµ ë°ì´í„° ë°±ì—…
            backup_result = await deepseek_service.create_backup()
            message = f"ë°±ì—…ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {backup_result}"
            
        elif action == "clear_cache":
            # ìºì‹œ ì •ë¦¬
            await deepseek_service.clear_cache()
            message = "ìºì‹œê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤."
            
        elif action == "optimize_model":
            # ëª¨ë¸ ìµœì í™”
            await deepseek_service.optimize_model()
            message = "ëª¨ë¸ ìµœì í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
            
        elif action == "export_data":
            # ë°ì´í„° ë‚´ë³´ë‚´ê¸°
            export_path = await deepseek_service.export_learning_data()
            message = f"í•™ìŠµ ë°ì´í„°ê°€ ë‚´ë³´ë‚´ê¸°ë˜ì—ˆìŠµë‹ˆë‹¤: {export_path}"
            
        else:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‘ì—…ì…ë‹ˆë‹¤: {action}"
            )
        
        return {"success": True, "message": message}
        
    except Exception as e:
        logger.error(f"ì‹œìŠ¤í…œ ì œì–´ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì‹œìŠ¤í…œ ì œì–´ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

# ==================== ML ì‹œê°í™” API ====================

@router.get("/deepseek/ml-analytics/confusion-matrix")
async def get_confusion_matrix(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """í˜¼ë™ í–‰ë ¬ ë°ì´í„° ì¡°íšŒ"""
    try:
        if current_user.role != 'admin':
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤."
            )
        
        logger.info(f"ğŸ¯ ê´€ë¦¬ì {current_user.user_id}ê°€ í˜¼ë™ í–‰ë ¬ ì¡°íšŒ")
        data = await ml_analytics_service.generate_confusion_matrix(db)
        
        return {
            "status": "success",
            "data": data,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ í˜¼ë™ í–‰ë ¬ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"í˜¼ë™ í–‰ë ¬ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@router.get("/deepseek/ml-analytics/learning-curve")
async def get_learning_curve(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """í•™ìŠµ ê³¡ì„  ë°ì´í„° ì¡°íšŒ"""
    try:
        if current_user.role != 'admin':
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤."
            )
        
        logger.info(f"ğŸ“ˆ ê´€ë¦¬ì {current_user.user_id}ê°€ í•™ìŠµ ê³¡ì„  ì¡°íšŒ")
        data = await ml_analytics_service.generate_learning_curve(db)
        
        return {
            "status": "success",
            "data": data,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ í•™ìŠµ ê³¡ì„  ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"í•™ìŠµ ê³¡ì„  ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@router.get("/deepseek/ml-analytics/loss-curve")
async def get_loss_curve(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """ì†ì‹¤ í•¨ìˆ˜ ê³¡ì„  ë°ì´í„° ì¡°íšŒ"""
    try:
        if current_user.role != 'admin':
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤."
            )
        
        logger.info(f"ğŸ“‰ ê´€ë¦¬ì {current_user.user_id}ê°€ ì†ì‹¤ ê³¡ì„  ì¡°íšŒ")
        data = await ml_analytics_service.generate_loss_curve(db)
        
        return {
            "status": "success",
            "data": data,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ì†ì‹¤ ê³¡ì„  ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì†ì‹¤ ê³¡ì„  ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@router.get("/deepseek/ml-analytics/roc-curve")
async def get_roc_curve(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """ROC ê³¡ì„  ë°ì´í„° ì¡°íšŒ"""
    try:
        if current_user.role != 'admin':
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤."
            )
        
        logger.info(f"ğŸ“Š ê´€ë¦¬ì {current_user.user_id}ê°€ ROC ê³¡ì„  ì¡°íšŒ")
        data = await ml_analytics_service.generate_roc_curve(db)
        
        return {
            "status": "success",
            "data": data,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ROC ê³¡ì„  ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ROC ê³¡ì„  ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@router.get("/deepseek/ml-analytics/precision-recall-curve")
async def get_precision_recall_curve(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """Precision-Recall ê³¡ì„  ë°ì´í„° ì¡°íšŒ"""
    try:
        if current_user.role != 'admin':
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤."
            )
        
        logger.info(f"ğŸ“Š ê´€ë¦¬ì {current_user.user_id}ê°€ PR ê³¡ì„  ì¡°íšŒ")
        data = await ml_analytics_service.generate_precision_recall_curve(db)
        
        return {
            "status": "success",
            "data": data,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ PR ê³¡ì„  ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"PR ê³¡ì„  ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@router.get("/deepseek/ml-analytics/feature-importance")
async def get_feature_importance(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """Feature Importance ë°ì´í„° ì¡°íšŒ"""
    try:
        if current_user.role != 'admin':
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤."
            )
        
        logger.info(f"ğŸ” ê´€ë¦¬ì {current_user.user_id}ê°€ Feature Importance ì¡°íšŒ")
        data = await ml_analytics_service.generate_feature_importance(db)
        
        return {
            "status": "success",
            "data": data,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Feature Importance ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Feature Importance ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@router.get("/deepseek/ml-analytics/dimensionality-reduction")
async def get_dimensionality_reduction(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """ì°¨ì› ì¶•ì†Œ ì‹œê°í™” ë°ì´í„° ì¡°íšŒ (PCA, t-SNE, UMAP)"""
    try:
        if current_user.role != 'admin':
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤."
            )
        
        logger.info(f"ğŸ¯ ê´€ë¦¬ì {current_user.user_id}ê°€ ì°¨ì› ì¶•ì†Œ ì‹œê°í™” ì¡°íšŒ")
        data = await ml_analytics_service.generate_dimensionality_reduction(db)
        
        return {
            "status": "success",
            "data": data,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ì°¨ì› ì¶•ì†Œ ì‹œê°í™” ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì°¨ì› ì¶•ì†Œ ì‹œê°í™” ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@router.get("/deepseek/ml-analytics/shap-analysis")
async def get_shap_analysis(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """SHAP ë¶„ì„ ë°ì´í„° ì¡°íšŒ"""
    try:
        if current_user.role != 'admin':
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤."
            )
        
        logger.info(f"ğŸ” ê´€ë¦¬ì {current_user.user_id}ê°€ SHAP ë¶„ì„ ì¡°íšŒ")
        data = await ml_analytics_service.generate_shap_analysis(db)
        
        return {
            "status": "success",
            "data": data,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ SHAP ë¶„ì„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"SHAP ë¶„ì„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@router.get("/deepseek/ml-analytics/all-visualizations")
async def get_all_ml_visualizations(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """ëª¨ë“  ML ì‹œê°í™” ë°ì´í„° ì¼ê´„ ì¡°íšŒ"""
    try:
        if current_user.role != 'admin':
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤."
            )
        
        logger.info(f"ğŸš€ ê´€ë¦¬ì {current_user.user_id}ê°€ ëª¨ë“  ML ì‹œê°í™” ì¼ê´„ ì¡°íšŒ")
        
        # ëª¨ë“  ì‹œê°í™” ë°ì´í„° ë³‘ë ¬ ìƒì„±
        confusion_matrix = await ml_analytics_service.generate_confusion_matrix(db)
        learning_curve = await ml_analytics_service.generate_learning_curve(db)
        loss_curve = await ml_analytics_service.generate_loss_curve(db)
        roc_curve = await ml_analytics_service.generate_roc_curve(db)
        pr_curve = await ml_analytics_service.generate_precision_recall_curve(db)
        feature_importance = await ml_analytics_service.generate_feature_importance(db)
        dimensionality_reduction = await ml_analytics_service.generate_dimensionality_reduction(db)
        shap_analysis = await ml_analytics_service.generate_shap_analysis(db)
        
        return {
            "status": "success",
            "data": {
                "confusion_matrix": confusion_matrix,
                "learning_curve": learning_curve,
                "loss_curve": loss_curve,
                "roc_curve": roc_curve,
                "precision_recall_curve": pr_curve,
                "feature_importance": feature_importance,
                "dimensionality_reduction": dimensionality_reduction,
                "shap_analysis": shap_analysis
            },
            "generated_at": datetime.now().isoformat(),
            "total_visualizations": 8
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ML ì‹œê°í™” ì¼ê´„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ML ì‹œê°í™” ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        ) 