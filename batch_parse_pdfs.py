#!/usr/bin/env python3
"""
PDF íŒŒì¼ ì¼ê´„ íŒŒì‹± ìŠ¤í¬ë¦½íŠ¸
ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼ ë° ì‘ì—…ì¹˜ë£Œí•™ê³¼ êµ­ê°€ì‹œí—˜ ë¬¸ì œì§€ + ë‹µì•ˆì§€ íŒŒì‹±
"""

import os
import sys
import asyncio
import json
from pathlib import Path
from datetime import datetime
import logging

# Django ì„¤ì • (ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ìš©)
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# FastAPI ì•± ëª¨ë“ˆë“¤ import
from app.services.question_parser import question_parser
from app.services.question_review_service import QuestionReviewService
from app.db.database import SessionLocal
from app.models.user import User

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('batch_parse.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# íŒŒì¼ ê²½ë¡œ ì •ì˜
BASE_PATH = Path(r"C:\Users\jaewo\Desktop\2025\2025_backend\uploads\questions")
SAVE_PATH = Path(r"C:\Users\jaewo\Desktop\2025\2025_backend\data\save_parser")

# íŒŒì‹±í•  íŒŒì¼ ëª©ë¡ ì •ì˜
PARSE_FILES = {
    "ì‘ì—…ì¹˜ë£Œí•™ê³¼": {
        2020: {
            "questions": BASE_PATH / "._2020ë…„ë„ ì œ48íšŒ ì‘ì—…ì¹˜ë£Œì‚¬ êµ­ê°€ì‹œí—˜ 1êµì‹œ.pdf",
            "answers": BASE_PATH / "._2020ë…„ë„ ì œ48íšŒ ì‘ì—…ì¹˜ë£Œì‚¬ êµ­ê°€ì‹œí—˜ 1~2êµì‹œ ìµœì¢…ë‹µì•ˆ.pdf"
        },
        2021: {
            "questions": BASE_PATH / "._2021ë…„ë„ ì œ49íšŒ ì‘ì—…ì¹˜ë£Œì‚¬ êµ­ê°€ì‹œí—˜ 1êµì‹œ.pdf", 
            "answers": BASE_PATH / "._2021ë…„ë„ ì œ49íšŒ ì‘ì—…ì¹˜ë£Œì‚¬ êµ­ê°€ì‹œí—˜ 1~2êµì‹œ ìµœì¢…ë‹µì•ˆ.pdf"
        },
        2022: {
            "questions": BASE_PATH / "._2022 ì œ50íšŒ ì‘ì—…ì¹˜ë£Œì‚¬ êµ­ê°€ì‹œí—˜_1êµì‹œ(í™€ìˆ˜í˜•).pdf",
            "answers": BASE_PATH / "._(ê°€ë‹µì•ˆ) 2022 ì œ50íšŒ ì‘ì—…ì¹˜ë£Œì‚¬ êµ­ê°€ì‹œí—˜ í™€ìˆ˜í˜•.pdf"
        },
        2023: {
            "questions": BASE_PATH / "2023ë…„ë„ ì œ51íšŒ ì‘ì—…ì¹˜ë£Œì‚¬ êµ­ê°€ì‹œí—˜ 1êµì‹œ ê¸°ì¶œë¬¸ì œ.pdf",
            "answers": BASE_PATH / "2023ë…„ë„ ì œ51íšŒ ì‘ì—…ì¹˜ë£Œì‚¬ êµ­ê°€ì‹œí—˜ 1~2êµì‹œ ìµœì¢…ë‹µì•ˆ.pdf"
        },
        2024: {
            "questions": BASE_PATH / "2024ë…„ë„ ì œ52íšŒ ì‘ì—…ì¹˜ë£Œì‚¬ êµ­ê°€ì‹œí—˜ 1êµì‹œ ê¸°ì¶œë¬¸ì œ.pdf",
            "answers": BASE_PATH / "2024ë…„ë„ ì œ52íšŒ ì‘ì—…ì¹˜ë£Œì‚¬ êµ­ê°€ì‹œí—˜ 1~2êµì‹œ ìµœì¢…ë‹µì•ˆ.pdf"
        }
    },
    "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": {
        2021: {
            "questions": BASE_PATH / "2021ë…„ë„ ì œ49íšŒ ë¬¼ë¦¬ì¹˜ë£Œì‚¬ êµ­ê°€ì‹œí—˜ 1êµì‹œ ê¸°ì¶œë¬¸ì œ.pdf",
            "answers": BASE_PATH / "2021ë…„ë„ ì œ49íšŒ ë¬¼ë¦¬ì¹˜ë£Œì‚¬ êµ­ê°€ì‹œí—˜ 1~2êµì‹œ ìµœì¢…ë‹µì•ˆ.pdf"
        },
        2022: {
            "questions": BASE_PATH / "2022ë…„ë„ ì œ50íšŒ ë¬¼ë¦¬ì¹˜ë£Œì‚¬ êµ­ê°€ì‹œí—˜ 1êµì‹œ ê¸°ì¶œë¬¸ì œ.pdf",
            "answers": BASE_PATH / "2022ë…„ë„ ì œ50íšŒ ë¬¼ë¦¬ì¹˜ë£Œì‚¬ êµ­ê°€ì‹œí—˜ 1~2êµì‹œ ìµœì¢…ë‹µì•ˆ.pdf"
        },
        2023: {
            "questions": BASE_PATH / "2023ë…„ë„ ì œ51íšŒ ë¬¼ë¦¬ì¹˜ë£Œì‚¬ êµ­ê°€ì‹œí—˜ 1êµì‹œ ê¸°ì¶œë¬¸ì œ.pdf",
            "answers": BASE_PATH / "2023ë…„ë„ ì œ51íšŒ ë¬¼ë¦¬ì¹˜ë£Œì‚¬ êµ­ê°€ì‹œí—˜ 1~2êµì‹œ ìµœì¢…ë‹µì•ˆ.pdf"
        },
        2024: {
            "questions": BASE_PATH / "2024ë…„ë„ ì œ52íšŒ ë¬¼ë¦¬ì¹˜ë£Œì‚¬ êµ­ê°€ì‹œí—˜ 1êµì‹œ ê¸°ì¶œë¬¸ì œ.pdf",
            "answers": BASE_PATH / "2024ë…„ë„ ì œ52íšŒ ë¬¼ë¦¬ì¹˜ë£Œì‚¬ êµ­ê°€ì‹œí—˜ 1~2êµì‹œ ìµœì¢…ë‹µì•ˆ.pdf"
        }
    }
}

# í‰ê°€ìœ„ì› ë¶„ì„ ë°ì´í„° ê²½ë¡œ
EVALUATOR_DATA = {
    "ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼": {
        "enhanced": Path(r"C:\Users\jaewo\Desktop\2025\2025_backend\data\enhanced_evaluator_analysis.json"),
        "detailed": Path(r"C:\Users\jaewo\Desktop\2025\2025_backend\data\detailed_evaluator_analysis.json")
    },
    "ì‘ì—…ì¹˜ë£Œí•™ê³¼": {
        "enhanced": Path(r"C:\Users\jaewo\Desktop\2025\2025_backend\data\enhanced_evaluator_analysis_ot.json"),
        "detailed": Path(r"C:\Users\jaewo\Desktop\2025\2025_backend\data\detailed_evaluator_analysis_ot.json")
    }
}

class BatchPDFParser:
    """PDF íŒŒì¼ ì¼ê´„ íŒŒì‹± í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.question_review_service = QuestionReviewService()
        self.success_count = 0
        self.error_count = 0
        self.total_questions = 0
        
        # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        SAVE_PATH.mkdir(parents=True, exist_ok=True)
        
        logger.info("ğŸš€ PDF ì¼ê´„ íŒŒì‹± ì‹œì‘")
        logger.info(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {SAVE_PATH}")
    
    def create_progress_callback(self, department: str, year: int, file_type: str):
        """ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜ ìƒì„±"""
        def progress_callback(message: str, progress: float):
            logger.info(f"ğŸ“Š [{department} {year}ë…„ {file_type}] {progress:.1f}% - {message}")
        return progress_callback
    
    async def parse_single_file(self, file_path: Path, content_type: str, department: str, year: int) -> dict:
        """ë‹¨ì¼ íŒŒì¼ íŒŒì‹±"""
        if not file_path.exists():
            logger.error(f"âŒ íŒŒì¼ ì—†ìŒ: {file_path}")
            return {"success": False, "error": "íŒŒì¼ ì—†ìŒ"}
        
        try:
            logger.info(f"ğŸ“„ íŒŒì‹± ì‹œì‘: {file_path.name} ({content_type})")
            
            # ì§„í–‰ë¥  ì½œë°± ìƒì„±
            progress_callback = self.create_progress_callback(department, year, content_type)
            
            # QuestionParserë¡œ íŒŒì‹±
            result = question_parser.parse_any_file(
                file_path=str(file_path),
                content_type=content_type,
                department=department,
                progress_callback=progress_callback
            )
            
            if result.get("error"):
                logger.error(f"âŒ íŒŒì‹± ì‹¤íŒ¨: {result['error']}")
                return {"success": False, "error": result["error"]}
            
            data = result.get("data", [])
            
            # ì—°ë„ ì •ë³´ ì¶”ê°€/ë³´ì •
            for item in data:
                if not item.get("year") or item.get("year") == 0:
                    item["year"] = year
                item["department"] = department
                item["source_type"] = "êµ­ê°€ì‹œí—˜"
                item["exam_session"] = f"ì œ{year-1972+48}íšŒ" if department == "ì‘ì—…ì¹˜ë£Œí•™ê³¼" else f"ì œ{year-1972+49}íšŒ"
            
            logger.info(f"âœ… íŒŒì‹± ì™„ë£Œ: {len(data)}ê°œ í•­ëª© ({content_type})")
            return {"success": True, "data": data, "count": len(data)}
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return {"success": False, "error": str(e)}
    
    def match_questions_and_answers(self, questions_data: list, answers_data: list, department: str, year: int) -> list:
        """ë¬¸ì œì™€ ë‹µì•ˆ ë§¤ì¹­"""
        logger.info(f"ğŸ”— ë¬¸ì œ-ë‹µì•ˆ ë§¤ì¹­ ì‹œì‘: {department} {year}ë…„ (ë¬¸ì œ {len(questions_data)}ê°œ, ë‹µì•ˆ {len(answers_data)}ê°œ)")
        
        # QuestionParserì˜ ë§¤ì¹­ í•¨ìˆ˜ ì‚¬ìš©
        matched_data = question_parser.match_questions_with_answers(questions_data, answers_data)
        
        # ë§¤ì¹­ í†µê³„
        matched_count = len([item for item in matched_data if item.get("correct_answer")])
        logger.info(f"ğŸ“Š ë§¤ì¹­ ê²°ê³¼: ì´ {len(matched_data)}ê°œ ì¤‘ {matched_count}ê°œ ì •ë‹µ ë§¤ì¹­")
        
        return matched_data
    
    def load_evaluator_difficulty_mapping(self, department: str, year: int) -> dict:
        """í‰ê°€ìœ„ì› ë‚œì´ë„ ë§¤í•‘ ë°ì´í„° ë¡œë“œ"""
        try:
            enhanced_path = EVALUATOR_DATA[department]["enhanced"]
            detailed_path = EVALUATOR_DATA[department]["detailed"]
            
            difficulty_mapping = {}
            
            # Enhanced ë°ì´í„° ë¡œë“œ
            if enhanced_path.exists():
                with open(enhanced_path, 'r', encoding='utf-8') as f:
                    enhanced_data = json.load(f)
                    
                # ì—°ë„ë³„ ë°ì´í„° ì¶”ì¶œ
                year_key = str(year)
                if year_key in enhanced_data:
                    year_data = enhanced_data[year_key]
                    for q_num in range(1, 23):  # 1-22ë²ˆ ë¬¸ì œ
                        q_key = str(q_num)
                        if q_key in year_data:
                            question_info = year_data[q_key]
                            difficulty_mapping[q_num] = {
                                "difficulty": question_info.get("consensus_difficulty", "ì¤‘"),
                                "area_name": question_info.get("primary_area", "ì¼ë°˜"),
                                "topic": question_info.get("topic", ""),
                                "evaluator_source": "enhanced"
                            }
            
            # Detailed ë°ì´í„°ë¡œ ë³´ì™„
            if detailed_path.exists():
                with open(detailed_path, 'r', encoding='utf-8') as f:
                    detailed_data = json.load(f)
                    
                year_key = str(year)
                if year_key in detailed_data:
                    year_questions = detailed_data[year_key].get("questions", [])
                    for question in year_questions:
                        q_num = question.get("question_number")
                        if q_num and q_num not in difficulty_mapping:
                            difficulty_mapping[q_num] = {
                                "difficulty": question.get("difficulty", "ì¤‘"),
                                "area_name": question.get("area", "ì¼ë°˜"),
                                "topic": question.get("topic", ""),
                                "evaluator_source": "detailed"
                            }
            
            logger.info(f"ğŸ“Š í‰ê°€ìœ„ì› ë§¤í•‘ ë¡œë“œ: {department} {year}ë…„ - {len(difficulty_mapping)}ê°œ ë¬¸ì œ")
            return difficulty_mapping
            
        except Exception as e:
            logger.warning(f"âš ï¸ í‰ê°€ìœ„ì› ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}
    
    def apply_evaluator_mapping(self, matched_data: list, department: str, year: int) -> list:
        """í‰ê°€ìœ„ì› ë§¤í•‘ ì ìš©"""
        difficulty_mapping = self.load_evaluator_difficulty_mapping(department, year)
        
        enhanced_count = 0
        for item in matched_data:
            q_num = item.get("question_number")
            if q_num and q_num in difficulty_mapping:
                mapping_info = difficulty_mapping[q_num]
                
                # í‰ê°€ìœ„ì› ë°ì´í„° ìš°ì„  ì ìš©
                item["difficulty"] = mapping_info["difficulty"]
                item["area_name"] = mapping_info["area_name"]
                if mapping_info["topic"]:
                    item["topic"] = mapping_info["topic"]
                
                # ë©”íƒ€ë°ì´í„°ì— í‰ê°€ìœ„ì› ì •ë³´ ì¶”ê°€
                if "metadata" not in item:
                    item["metadata"] = {}
                item["metadata"]["evaluator_source"] = mapping_info["evaluator_source"]
                item["metadata"]["evaluator_enhanced"] = True
                
                enhanced_count += 1
        
        logger.info(f"âœ¨ í‰ê°€ìœ„ì› ë§¤í•‘ ì ìš©: {enhanced_count}ê°œ ë¬¸ì œ ê°•í™”ë¨")
        return matched_data
    
    def save_to_json(self, data: list, department: str, year: int) -> str:
        """JSON íŒŒì¼ë¡œ ì €ì¥"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{timestamp}_batch_{department}_{year}ë…„_êµ­ê°€ì‹œí—˜.json"
            file_path = SAVE_PATH / filename
            
            # ì €ì¥í•  ë°ì´í„° êµ¬ì¡°
            save_data = {
                "meta": {
                    "department": department,
                    "year": year,
                    "exam_type": "êµ­ê°€ì‹œí—˜",
                    "parsed_at": datetime.now().isoformat(),
                    "total_questions": len(data),
                    "parsing_method": "batch_script",
                    "ai_analysis_included": True,
                    "evaluator_mapping_applied": True
                },
                "questions": data
            }
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ’¾ JSON ì €ì¥ ì™„ë£Œ: {file_path}")
            return str(file_path)
            
        except Exception as e:
            logger.error(f"âŒ JSON ì €ì¥ ì‹¤íŒ¨: {e}")
            return ""
    
    async def process_department_year(self, department: str, year: int, file_info: dict):
        """íŠ¹ì • í•™ê³¼ì˜ íŠ¹ì • ì—°ë„ ì²˜ë¦¬"""
        logger.info(f"\nğŸ¯ ì²˜ë¦¬ ì‹œì‘: {department} {year}ë…„")
        
        try:
            # 1ë‹¨ê³„: ë¬¸ì œì§€ íŒŒì‹±
            questions_result = await self.parse_single_file(
                file_info["questions"], "questions", department, year
            )
            
            if not questions_result["success"]:
                logger.error(f"âŒ ë¬¸ì œì§€ íŒŒì‹± ì‹¤íŒ¨: {questions_result.get('error')}")
                self.error_count += 1
                return
            
            # 2ë‹¨ê³„: ë‹µì•ˆì§€ íŒŒì‹±
            answers_result = await self.parse_single_file(
                file_info["answers"], "answers", department, year
            )
            
            if not answers_result["success"]:
                logger.error(f"âŒ ë‹µì•ˆì§€ íŒŒì‹± ì‹¤íŒ¨: {answers_result.get('error')}")
                self.error_count += 1
                return
            
            # 3ë‹¨ê³„: ë¬¸ì œ-ë‹µì•ˆ ë§¤ì¹­
            questions_data = questions_result["data"]
            answers_data = answers_result["data"]
            
            matched_data = self.match_questions_and_answers(questions_data, answers_data, department, year)
            
            if not matched_data:
                logger.error(f"âŒ ë§¤ì¹­ ê²°ê³¼ ì—†ìŒ")
                self.error_count += 1
                return
            
            # 4ë‹¨ê³„: í‰ê°€ìœ„ì› ë§¤í•‘ ì ìš©
            enhanced_data = self.apply_evaluator_mapping(matched_data, department, year)
            
            # 5ë‹¨ê³„: JSON ì €ì¥
            json_path = self.save_to_json(enhanced_data, department, year)
            
            if json_path:
                self.success_count += 1
                self.total_questions += len(enhanced_data)
                logger.info(f"âœ… ì™„ë£Œ: {department} {year}ë…„ - {len(enhanced_data)}ê°œ ë¬¸ì œ")
            else:
                self.error_count += 1
                
        except Exception as e:
            logger.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {department} {year}ë…„ - {e}")
            self.error_count += 1
    
    async def run_batch_parsing(self):
        """ì¼ê´„ íŒŒì‹± ì‹¤í–‰"""
        logger.info(f"ğŸ“‹ ì²˜ë¦¬ ëŒ€ìƒ: {sum(len(years) for years in PARSE_FILES.values())}ê°œ ì—°ë„")
        
        # ëª¨ë“  í•™ê³¼, ì—°ë„ ìˆœì°¨ ì²˜ë¦¬
        for department, years_data in PARSE_FILES.items():
            logger.info(f"\nğŸ¥ í•™ê³¼ ì²˜ë¦¬ ì‹œì‘: {department}")
            
            for year, file_info in years_data.items():
                await self.process_department_year(department, year, file_info)
                
                # ê° ì—°ë„ ì²˜ë¦¬ í›„ ì ì‹œ ëŒ€ê¸° (API ë¶€í•˜ ë°©ì§€)
                await asyncio.sleep(2)
        
        # ìµœì¢… ê²°ê³¼
        logger.info(f"\nğŸ‰ ì¼ê´„ íŒŒì‹± ì™„ë£Œ!")
        logger.info(f"âœ… ì„±ê³µ: {self.success_count}ê°œ ì—°ë„")
        logger.info(f"âŒ ì‹¤íŒ¨: {self.error_count}ê°œ ì—°ë„") 
        logger.info(f"ğŸ“Š ì´ ë¬¸ì œ: {self.total_questions}ê°œ")
        logger.info(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {SAVE_PATH}")

def verify_files():
    """íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
    logger.info("ğŸ“‹ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ì¤‘...")
    
    missing_files = []
    total_files = 0
    
    for department, years_data in PARSE_FILES.items():
        for year, file_info in years_data.items():
            for file_type, file_path in file_info.items():
                total_files += 1
                if not file_path.exists():
                    missing_files.append(f"{department} {year}ë…„ {file_type}: {file_path}")
    
    if missing_files:
        logger.error(f"âŒ ëˆ„ë½ëœ íŒŒì¼ {len(missing_files)}ê°œ:")
        for missing in missing_files:
            logger.error(f"   - {missing}")
        return False
    
    logger.info(f"âœ… ëª¨ë“  íŒŒì¼ í™•ì¸ ì™„ë£Œ: {total_files}ê°œ íŒŒì¼")
    return True

def verify_evaluator_data():
    """í‰ê°€ìœ„ì› ë°ì´í„° íŒŒì¼ í™•ì¸"""
    logger.info("ğŸ“Š í‰ê°€ìœ„ì› ë°ì´í„° í™•ì¸ ì¤‘...")
    
    missing_data = []
    for department, data_paths in EVALUATOR_DATA.items():
        for data_type, file_path in data_paths.items():
            if not file_path.exists():
                missing_data.append(f"{department} {data_type}: {file_path}")
    
    if missing_data:
        logger.warning(f"âš ï¸ ëˆ„ë½ëœ í‰ê°€ìœ„ì› ë°ì´í„° {len(missing_data)}ê°œ:")
        for missing in missing_data:
            logger.warning(f"   - {missing}")
        logger.warning("í‰ê°€ìœ„ì› ë§¤í•‘ ì—†ì´ ì§„í–‰ë©ë‹ˆë‹¤.")
    else:
        logger.info("âœ… í‰ê°€ìœ„ì› ë°ì´í„° ëª¨ë‘ í™•ì¸ë¨")

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger.info("ğŸš€ PDF ì¼ê´„ íŒŒì‹± ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘")
    logger.info(f"ğŸ“… ì²˜ë¦¬ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not verify_files():
        logger.error("âŒ í•„ìˆ˜ íŒŒì¼ì´ ëˆ„ë½ë˜ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # í‰ê°€ìœ„ì› ë°ì´í„° í™•ì¸
    verify_evaluator_data()
    
    # ì¼ê´„ íŒŒì‹± ì‹¤í–‰
    parser = BatchPDFParser()
    await parser.run_batch_parsing()

if __name__ == "__main__":
    # ë¹„ë™ê¸° ì‹¤í–‰
    asyncio.run(main()) 