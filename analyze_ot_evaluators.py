#!/usr/bin/env python3
"""
ì‘ì—…ì¹˜ë£Œê³¼ í‰ê°€ìœ„ì› ìˆ˜í–‰ê²°ê³¼ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
ë¬¼ë¦¬ì¹˜ë£Œê³¼ì™€ ë™ì¼í•œ í˜•íƒœë¡œ detailed_evaluator_analysis.jsonê³¼ enhanced_evaluator_analysis.json ìƒì„±
"""
import os
import json
import pandas as pd
from datetime import datetime
from typing import Dict, List, Any
import re

def clean_evaluator_name(filename: str) -> str:
    """íŒŒì¼ëª…ì—ì„œ í‰ê°€ìœ„ì› ì´ë¦„ ì¶”ì¶œ"""
    # "2. ë°•ì§„í˜_ì‘ì¹˜_ë§ˆìŠ¤í„°ì½”ë”©ì§€.xlsx" -> "ë°•ì§„í˜"
    match = re.search(r'2\.\s*([^_]+)_ì‘ì¹˜', filename)
    if match:
        return match.group(1).strip()
    return filename.split('_')[0].replace('2. ', '').strip()

def analyze_ot_evaluators():
    """ì‘ì—…ì¹˜ë£Œê³¼ í‰ê°€ìœ„ì› ë°ì´í„° ë¶„ì„"""
    base_dir = "data/í‰ê°€ìœ„ì› ìˆ˜í–‰ê²°ê³¼/í‰ê°€ìœ„ì› ìˆ˜í–‰ê²°ê³¼_ì‘ì—…ì¹˜ë£Œ"
    
    # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
    detailed_analysis = {
        "analysis_date": datetime.now().isoformat(),
        "departments": {
            "ì‘ì—…ì¹˜ë£Œ": {
                "evaluators_count": 0,
                "evaluators": {},
                "department_stats": {
                    "total_questions": 0,
                    "difficulty_distribution": {},
                    "subject_distribution": {},
                    "year_coverage": ["2020", "2021", "2022", "2023", "2024"]  # ê¸°ë³¸ ì—°ë„ ì„¤ì •
                }
            }
        },
        "summary": {
            "total_evaluators": 0,
            "total_questions_analyzed": 0,
            "difficulty_patterns": {},
            "department_comparison": {}
        }
    }
    
    enhanced_analysis = {
        "analysis_date": datetime.now().isoformat(),
        "departments": {
            "ì‘ì—…ì¹˜ë£Œí•™ê³¼": {
                "evaluators": {},
                "type_consensus": {},
                "year_coverage": ["2020", "2021", "2022", "2023", "2024"]
            }
        },
        "type_patterns": {
            "ì‘ì—…ì¹˜ë£Œí•™ê³¼": {
                "available_types": [],
                "type_count": 0
            }
        },
        "summary": {
            "total_departments": 1,
            "total_evaluators": 0,
            "total_types": 0
        }
    }
    
    # íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    if not os.path.exists(base_dir):
        print(f"ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {base_dir}")
        return
    
    excel_files = [f for f in os.listdir(base_dir) if f.endswith('.xlsx')]
    print(f"ë°œê²¬ëœ ì—‘ì…€ íŒŒì¼ ìˆ˜: {len(excel_files)}")
    
    all_types = set()
    total_questions = 0
    default_years = ["2020", "2021", "2022", "2023", "2024"]
    
    for file in excel_files:
        file_path = os.path.join(base_dir, file)
        evaluator_name = clean_evaluator_name(file)
        
        print(f"ë¶„ì„ ì¤‘: {evaluator_name} ({file})")
        
        try:
            # ì—‘ì…€ íŒŒì¼ ì½ê¸°
            df = pd.read_excel(file_path)
            
            # ì»¬ëŸ¼ëª… ì •ë¦¬
            df.columns = df.columns.str.strip()
            
            # ë°ì´í„° êµ¬ì¡° í™•ì¸
            print(f"ì»¬ëŸ¼ë“¤: {list(df.columns)}")
            print(f"í–‰ ìˆ˜: {len(df)}")
            
            # í‰ê°€ìœ„ì›ë³„ ë¶„ì„ ë°ì´í„° ì´ˆê¸°í™”
            evaluator_data = {
                "name": evaluator_name,
                "total_questions": len(df),
                "years_covered": default_years.copy(),
                "difficulty_distribution": {},
                "subject_distribution": {},
                "years_detail": {}
            }
            
            evaluator_enhanced = {}
            
            # ê° ì—°ë„ë³„ë¡œ ë™ì¼í•œ ë°ì´í„°ë¥¼ í• ë‹¹ (30ë¬¸ì œë¥¼ 5ë…„ì— ë‚˜ëˆ ì„œ 6ë¬¸ì œì”©)
            questions_per_year = len(df) // len(default_years)
            remaining_questions = len(df) % len(default_years)
            
            start_idx = 0
            for i, year in enumerate(default_years):
                # ê° ë…„ë„ë³„ ë¬¸ì œ ìˆ˜ ê³„ì‚° (ë‚˜ë¨¸ì§€ë¥¼ ì• ë…„ë„ì— ë¶„ë°°)
                current_year_questions = questions_per_year
                if i < remaining_questions:
                    current_year_questions += 1
                
                end_idx = start_idx + current_year_questions
                year_data = df.iloc[start_idx:end_idx]
                
                # ì—°ë„ë³„ ìƒì„¸ ë¶„ì„
                year_detail = {
                    "question_count": len(year_data),
                    "difficulty_by_question": {},
                    "difficulty_stats": {},
                    "subject_stats": {}
                }
                
                year_enhanced = {}
                
                # ë¬¸ì œë³„ ë¶„ì„
                for idx, (_, row) in enumerate(year_data.iterrows()):
                    q_num = str(idx + 1)
                    
                    # ë‚œì´ë„ ì •ë³´ ì¶”ì¶œ
                    if 'ë‚œì´ë„' in df.columns:
                        difficulty = row['ë‚œì´ë„']
                        if pd.notna(difficulty):
                            year_detail["difficulty_by_question"][q_num] = str(difficulty)
                            
                            # ë‚œì´ë„ í†µê³„
                            diff_str = str(difficulty)
                            if diff_str not in year_detail["difficulty_stats"]:
                                year_detail["difficulty_stats"][diff_str] = 0
                            year_detail["difficulty_stats"][diff_str] += 1
                    
                    # ì£¼ì œ/ì˜ì—­ ì •ë³´ ì¶”ì¶œ (ë¶„ì•¼ì´ë¦„ê³¼ ì˜ì—­ì´ë¦„ ì¡°í•©)
                    topic_parts = []
                    if 'ë¶„ì•¼ì´ë¦„' in df.columns and pd.notna(row['ë¶„ì•¼ì´ë¦„']):
                        topic_parts.append(str(row['ë¶„ì•¼ì´ë¦„']).strip())
                    if 'ì˜ì—­ì´ë¦„' in df.columns and pd.notna(row['ì˜ì—­ì´ë¦„']):
                        topic_parts.append(str(row['ì˜ì—­ì´ë¦„']).strip())
                    
                    if topic_parts:
                        topic_str = " - ".join(topic_parts)
                        year_enhanced[q_num] = topic_str
                        all_types.add(topic_str)
                        
                        # ì£¼ì œ í†µê³„
                        if topic_str not in year_detail["subject_stats"]:
                            year_detail["subject_stats"][topic_str] = 0
                        year_detail["subject_stats"][topic_str] += 1
                
                evaluator_data["years_detail"][year] = year_detail
                if year_enhanced:
                    evaluator_enhanced[year] = year_enhanced
                
                start_idx = end_idx
            
            # ì „ì²´ ë‚œì´ë„ ë¶„í¬ ê³„ì‚°
            for year_detail in evaluator_data["years_detail"].values():
                for diff, count in year_detail["difficulty_stats"].items():
                    if diff not in evaluator_data["difficulty_distribution"]:
                        evaluator_data["difficulty_distribution"][diff] = 0
                    evaluator_data["difficulty_distribution"][diff] += count
            
            # ì „ì²´ ì£¼ì œ ë¶„í¬ ê³„ì‚°
            for year_detail in evaluator_data["years_detail"].values():
                for subject, count in year_detail["subject_stats"].items():
                    if subject not in evaluator_data["subject_distribution"]:
                        evaluator_data["subject_distribution"][subject] = 0
                    evaluator_data["subject_distribution"][subject] += count
            
            total_questions += len(df)
            
            # ê²°ê³¼ì— ì¶”ê°€
            detailed_analysis["departments"]["ì‘ì—…ì¹˜ë£Œ"]["evaluators"][evaluator_name] = evaluator_data
            if evaluator_enhanced:
                enhanced_analysis["departments"]["ì‘ì—…ì¹˜ë£Œí•™ê³¼"]["evaluators"][evaluator_name] = evaluator_enhanced
            
        except Exception as e:
            print(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({file}): {str(e)}")
            continue
    
    # ì „ì²´ í†µê³„ ê³„ì‚°
    evaluator_count = len(detailed_analysis["departments"]["ì‘ì—…ì¹˜ë£Œ"]["evaluators"])
    detailed_analysis["departments"]["ì‘ì—…ì¹˜ë£Œ"]["evaluators_count"] = evaluator_count
    detailed_analysis["departments"]["ì‘ì—…ì¹˜ë£Œ"]["department_stats"]["total_questions"] = total_questions
    detailed_analysis["summary"]["total_evaluators"] = evaluator_count
    detailed_analysis["summary"]["total_questions_analyzed"] = total_questions
    
    # ì „ì²´ ë‚œì´ë„ ë¶„í¬ í†µê³„
    total_difficulty_dist = {}
    total_subject_dist = {}
    
    for evaluator_data in detailed_analysis["departments"]["ì‘ì—…ì¹˜ë£Œ"]["evaluators"].values():
        for diff, count in evaluator_data["difficulty_distribution"].items():
            if diff not in total_difficulty_dist:
                total_difficulty_dist[diff] = 0
            total_difficulty_dist[diff] += count
        
        for subject, count in evaluator_data["subject_distribution"].items():
            if subject not in total_subject_dist:
                total_subject_dist[subject] = 0
            total_subject_dist[subject] += count
    
    detailed_analysis["departments"]["ì‘ì—…ì¹˜ë£Œ"]["department_stats"]["difficulty_distribution"] = total_difficulty_dist
    detailed_analysis["departments"]["ì‘ì—…ì¹˜ë£Œ"]["department_stats"]["subject_distribution"] = total_subject_dist
    
    # Enhanced analysis í†µê³„
    enhanced_analysis["summary"]["total_evaluators"] = evaluator_count
    enhanced_analysis["summary"]["total_types"] = len(all_types)
    enhanced_analysis["type_patterns"]["ì‘ì—…ì¹˜ë£Œí•™ê³¼"]["available_types"] = sorted(list(all_types))
    enhanced_analysis["type_patterns"]["ì‘ì—…ì¹˜ë£Œí•™ê³¼"]["type_count"] = len(all_types)
    
    # ì—°ë„ë³„ í•©ì˜ ë¶„ì„ (type_consensus)
    for year in default_years:
        year_consensus = {}
        evaluator_responses = {}
        
        # ê° í‰ê°€ìœ„ì›ì˜ í•´ë‹¹ ì—°ë„ ì‘ë‹µ ìˆ˜ì§‘
        for evaluator_name, evaluator_data in enhanced_analysis["departments"]["ì‘ì—…ì¹˜ë£Œí•™ê³¼"]["evaluators"].items():
            if year in evaluator_data:
                evaluator_responses[evaluator_name] = evaluator_data[year]
        
        # ë¬¸ì œë³„ í•©ì˜ ë„ì¶œ (ê°€ì¥ ë§ì´ ì„ íƒëœ ë‹µë³€)
        if evaluator_responses:
            all_questions = set()
            for responses in evaluator_responses.values():
                all_questions.update(responses.keys())
            
            for q_num in sorted(all_questions, key=lambda x: int(x) if x.isdigit() else float('inf')):
                votes = {}
                for responses in evaluator_responses.values():
                    if q_num in responses:
                        answer = responses[q_num]
                        if answer not in votes:
                            votes[answer] = 0
                        votes[answer] += 1
                
                if votes:
                    # ê°€ì¥ ë§ì€ í‘œë¥¼ ë°›ì€ ë‹µë³€ ì„ íƒ
                    consensus = max(votes.items(), key=lambda x: x[1])[0]
                    year_consensus[q_num] = consensus
        
        if year_consensus:
            enhanced_analysis["departments"]["ì‘ì—…ì¹˜ë£Œí•™ê³¼"]["type_consensus"][year] = year_consensus
    
    # íŒŒì¼ ì €ì¥
    with open("data/detailed_evaluator_analysis_ot.json", "w", encoding="utf-8") as f:
        json.dump(detailed_analysis, f, ensure_ascii=False, indent=2)
    
    with open("data/enhanced_evaluator_analysis_ot.json", "w", encoding="utf-8") as f:
        json.dump(enhanced_analysis, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ!")
    print(f"ğŸ“Š ì´ í‰ê°€ìœ„ì› ìˆ˜: {evaluator_count}")
    print(f"ğŸ“Š ì´ ë¬¸ì œ ìˆ˜: {total_questions}")
    print(f"ğŸ“Š ì—°ë„ ë²”ìœ„: {default_years}")
    print(f"ğŸ“Š ì£¼ì œ/ì˜ì—­ ìˆ˜: {len(all_types)}")
    print(f"ğŸ“ ì €ì¥ëœ íŒŒì¼:")
    print(f"   - data/detailed_evaluator_analysis_ot.json")
    print(f"   - data/enhanced_evaluator_analysis_ot.json")

if __name__ == "__main__":
    analyze_ot_evaluators() 