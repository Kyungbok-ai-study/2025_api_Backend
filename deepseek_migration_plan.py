#!/usr/bin/env python3
"""
ë¡œì»¬ DeepSeek ë§ˆì´ê·¸ë ˆì´ì…˜ í”Œëœ
OpenAI + Gemini â†’ ë¡œì»¬ DeepSeek (Ollama ê¸°ë°˜)
"""
import os
import subprocess
import json
import logging
from pathlib import Path

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DeepSeekMigrationPlan:
    """ë¡œì»¬ DeepSeek ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš"""
    
    def __init__(self):
        self.backend_dir = Path(__file__).parent
        self.requirements_file = self.backend_dir / "requirements_deepseek.txt"
        
    def step1_install_ollama(self):
        """1ë‹¨ê³„: Ollama ì„¤ì¹˜"""
        logger.info("ğŸš€ 1ë‹¨ê³„: Ollama ì„¤ì¹˜")
        
        print("""
=== Ollama ì„¤ì¹˜ ë°©ë²• ===

Windows (PowerShell ê´€ë¦¬ì ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰):
1. ë°©ë²•1: ì„¤ì¹˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
   - https://ollama.com/download/windows ì—ì„œ ì„¤ì¹˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
   - ì‹¤í–‰í•˜ì—¬ ì„¤ì¹˜

2. ë°©ë²•2: winget ì‚¬ìš©
   winget install Ollama.Ollama

3. ë°©ë²•3: ìˆ˜ë™ ì„¤ì¹˜
   - GitHubì—ì„œ ollama-windows-amd64.zip ë‹¤ìš´ë¡œë“œ
   - ì••ì¶• í•´ì œ í›„ PATHì— ì¶”ê°€

ì„¤ì¹˜ í›„ í™•ì¸:
   ollama --version

=== DeepSeek ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ===
ì„¤ì¹˜ ì™„ë£Œ í›„ ë‹¤ìŒ ëª…ë ¹ì–´ ì‹¤í–‰:

# DeepSeek R1 7B (ì¶”ì²œ)
ollama pull deepseek-r1:7b

# ë˜ëŠ” ë” ì‘ì€ ëª¨ë¸
ollama pull deepseek-r1:1.5b

# ì„ë² ë”© ëª¨ë¸
ollama pull nomic-embed-text

ì„œë²„ ì‹œì‘:
ollama serve
        """)
        
        # Ollama ìƒíƒœ í™•ì¸
        try:
            result = subprocess.run(["ollama", "--version"], 
                                    capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                logger.info(f"âœ… Ollama ì„¤ì¹˜ í™•ì¸ë¨: {result.stdout.strip()}")
                return True
            else:
                logger.warning("âŒ Ollamaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return False
        except Exception as e:
            logger.warning(f"âŒ Ollama í™•ì¸ ì‹¤íŒ¨: {e}")
            return False
    
    def step2_check_models(self):
        """2ë‹¨ê³„: ëª¨ë¸ ì„¤ì¹˜ í™•ì¸"""
        logger.info("ğŸ” 2ë‹¨ê³„: DeepSeek ëª¨ë¸ í™•ì¸")
        
        try:
            result = subprocess.run(["ollama", "list"], 
                                    capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                models = result.stdout
                logger.info(f"ì„¤ì¹˜ëœ ëª¨ë¸ ëª©ë¡:\n{models}")
                
                # í•„ìˆ˜ ëª¨ë¸ í™•ì¸
                required_models = ["deepseek-r1", "nomic-embed-text"]
                missing_models = []
                
                for model in required_models:
                    if model not in models:
                        missing_models.append(model)
                
                if missing_models:
                    logger.warning(f"âŒ ëˆ„ë½ëœ ëª¨ë¸: {missing_models}")
                    print("\në‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
                    for model in missing_models:
                        if "deepseek" in model:
                            print(f"ollama pull deepseek-r1:7b")
                        else:
                            print(f"ollama pull {model}")
                    return False
                else:
                    logger.info("âœ… ëª¨ë“  í•„ìˆ˜ ëª¨ë¸ ì„¤ì¹˜ ì™„ë£Œ")
                    return True
            else:
                logger.error("âŒ Ollama ì„œë²„ê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'ollama serve' ì‹¤í–‰í•˜ì„¸ìš”.")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False
    
    def step3_update_dependencies(self):
        """3ë‹¨ê³„: ì¢…ì†ì„± ì—…ë°ì´íŠ¸"""
        logger.info("ğŸ“¦ 3ë‹¨ê³„: ì¶”ê°€ ì¢…ì†ì„± ì„¤ì¹˜")
        
        # DeepSeekìš© ì¶”ê°€ íŒ¨í‚¤ì§€
        deepseek_requirements = [
            "# ë¡œì»¬ DeepSeek ë§ˆì´ê·¸ë ˆì´ì…˜ìš©",
            "httpx>=0.24.0",
            "pytesseract>=0.3.10",  # OCR
            "pdf2image>=1.16.3",   # PDF to image
            "Pillow>=10.0.0",      # ì´ë¯¸ì§€ ì²˜ë¦¬
        ]
        
        try:
            with open(self.requirements_file, 'w', encoding='utf-8') as f:
                f.write('\n'.join(deepseek_requirements))
            
            logger.info(f"âœ… requirements_deepseek.txt ìƒì„± ì™„ë£Œ")
            
            print(f"""
ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì¶”ê°€ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:
pip install -r {self.requirements_file}

OCR ê¸°ëŠ¥ì„ ìœ„í•´ Tesseractë„ ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤:
Windows: https://github.com/UB-Mannheim/tesseract/wiki
ì„¤ì¹˜ í›„ PATHì— ì¶”ê°€í•˜ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ TESSERACT_CMD ì„¤ì •
            """)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì¢…ì†ì„± íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def step4_update_env_config(self):
        """4ë‹¨ê³„: í™˜ê²½ ì„¤ì • ì—…ë°ì´íŠ¸"""
        logger.info("âš™ï¸ 4ë‹¨ê³„: í™˜ê²½ ì„¤ì • ì—…ë°ì´íŠ¸")
        
        env_file = self.backend_dir / "env.ini"
        
        # DeepSeek ì„¤ì • ì¶”ê°€
        deepseek_config = """

# ë¡œì»¬ DeepSeek ì„¤ì • (ë§ˆì´ê·¸ë ˆì´ì…˜)
OLLAMA_HOST=http://localhost:11434
DEEPSEEK_MODEL_NAME=deepseek-r1:7b
DEEPSEEK_EMBEDDING_MODEL=nomic-embed-text

# ë§ˆì´ê·¸ë ˆì´ì…˜ ëª¨ë“œ (ì ì§„ì  ì „í™˜)
USE_LOCAL_DEEPSEEK=true
FALLBACK_TO_OPENAI=true
FALLBACK_TO_GEMINI=true

# OCR ì„¤ì • (ì„ íƒì‚¬í•­)
TESSERACT_CMD=tesseract
"""
        
        try:
            with open(env_file, 'a', encoding='utf-8') as f:
                f.write(deepseek_config)
            
            logger.info("âœ… env.iniì— DeepSeek ì„¤ì • ì¶”ê°€ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ í™˜ê²½ ì„¤ì • ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def run_full_migration(self):
        """ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
        logger.info("ğŸš€ ë¡œì»¬ DeepSeek ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
        
        steps = [
            ("Ollama ì„¤ì¹˜", self.step1_install_ollama),
            ("ëª¨ë¸ í™•ì¸", self.step2_check_models),
            ("ì¢…ì†ì„± ì—…ë°ì´íŠ¸", self.step3_update_dependencies),
            ("í™˜ê²½ ì„¤ì •", self.step4_update_env_config),
        ]
        
        results = []
        
        for step_name, step_func in steps:
            print(f"\n{'='*50}")
            print(f"ğŸ”„ {step_name} ì‹¤í–‰ ì¤‘...")
            print(f"{'='*50}")
            
            try:
                success = step_func()
                results.append((step_name, success))
                
                if success:
                    print(f"âœ… {step_name} ì™„ë£Œ")
                else:
                    print(f"âŒ {step_name} ì‹¤íŒ¨")
                    
            except Exception as e:
                logger.error(f"âŒ {step_name} ì˜¤ë¥˜: {e}")
                results.append((step_name, False))
        
        # ê²°ê³¼ ìš”ì•½
        print(f"\n{'='*50}")
        print("ğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ ìš”ì•½")
        print(f"{'='*50}")
        
        success_count = sum(1 for _, success in results if success)
        total_count = len(results)
        
        for step_name, success in results:
            status = "âœ…" if success else "âŒ"
            print(f"{status} {step_name}")
        
        print(f"\nì™„ë£Œìœ¨: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)")
        
        if success_count == total_count:
            print("\nğŸ‰ ë¡œì»¬ DeepSeek ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤€ë¹„ ì™„ë£Œ!")
            print("\në‹¤ìŒ ë‹¨ê³„:")
            print("1. ollama serve ì‹¤í–‰")
            print("2. python -m app.services.deepseek_service í…ŒìŠ¤íŠ¸")
            print("3. USE_LOCAL_DEEPSEEK=true ì„¤ì •ìœ¼ë¡œ ì„œë²„ ì¬ì‹œì‘")
        else:
            print("\nâš ï¸ ì¼ë¶€ ë‹¨ê³„ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìœ„ì˜ ì§€ì‹œì‚¬í•­ì„ ë”°ë¼ ìˆ˜ë™ìœ¼ë¡œ ì™„ë£Œí•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    migrator = DeepSeekMigrationPlan()
    migrator.run_full_migration() 